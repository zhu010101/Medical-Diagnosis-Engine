{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-14T01:27:06.890849Z",
     "iopub.status.busy": "2024-12-14T01:27:06.890448Z",
     "iopub.status.idle": "2024-12-14T01:27:06.894078Z",
     "shell.execute_reply": "2024-12-14T01:27:06.893547Z",
     "shell.execute_reply.started": "2024-12-14T01:27:06.890823Z"
    }
   },
   "source": [
    "# Install Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-14T01:24:25.674684Z",
     "iopub.status.busy": "2024-12-14T01:24:25.674321Z",
     "iopub.status.idle": "2024-12-14T01:24:27.565600Z",
     "shell.execute_reply": "2024-12-14T01:24:27.565111Z",
     "shell.execute_reply.started": "2024-12-14T01:24:25.674667Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('attempt to write a readonly database')).History will not be written to the database.\n",
      "Collecting https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.4/en_core_sci_sm-0.5.4.tar.gz\n",
      "  Using cached https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.4/en_core_sci_sm-0.5.4.tar.gz (14.8 MB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: spacy in /opt/anaconda3/envs/NLP_project/lib/python3.12/site-packages (3.7.5)\n",
      "Requirement already satisfied: scispacy in /opt/anaconda3/envs/NLP_project/lib/python3.12/site-packages (0.5.5)\n",
      "Requirement already satisfied: negspacy in /opt/anaconda3/envs/NLP_project/lib/python3.12/site-packages (1.0.4)\n",
      "Requirement already satisfied: matplotlib in /opt/anaconda3/envs/NLP_project/lib/python3.12/site-packages (3.9.2)\n",
      "Requirement already satisfied: scikit-learn in /opt/anaconda3/envs/NLP_project/lib/python3.12/site-packages (1.5.2)\n",
      "Requirement already satisfied: numpy<2.0 in /opt/anaconda3/envs/NLP_project/lib/python3.12/site-packages (1.26.4)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /opt/anaconda3/envs/NLP_project/lib/python3.12/site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/anaconda3/envs/NLP_project/lib/python3.12/site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/anaconda3/envs/NLP_project/lib/python3.12/site-packages (from spacy) (1.0.11)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/anaconda3/envs/NLP_project/lib/python3.12/site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/anaconda3/envs/NLP_project/lib/python3.12/site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /opt/anaconda3/envs/NLP_project/lib/python3.12/site-packages (from spacy) (8.2.5)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /opt/anaconda3/envs/NLP_project/lib/python3.12/site-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/anaconda3/envs/NLP_project/lib/python3.12/site-packages (from spacy) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/anaconda3/envs/NLP_project/lib/python3.12/site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /opt/anaconda3/envs/NLP_project/lib/python3.12/site-packages (from spacy) (0.3.4)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /opt/anaconda3/envs/NLP_project/lib/python3.12/site-packages (from spacy) (0.9.4)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/anaconda3/envs/NLP_project/lib/python3.12/site-packages (from spacy) (4.67.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/anaconda3/envs/NLP_project/lib/python3.12/site-packages (from spacy) (2.32.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /opt/anaconda3/envs/NLP_project/lib/python3.12/site-packages (from spacy) (2.10.3)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/envs/NLP_project/lib/python3.12/site-packages (from spacy) (3.1.4)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/envs/NLP_project/lib/python3.12/site-packages (from spacy) (75.1.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/envs/NLP_project/lib/python3.12/site-packages (from spacy) (24.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/anaconda3/envs/NLP_project/lib/python3.12/site-packages (from spacy) (3.5.0)\n",
      "Requirement already satisfied: scipy in /opt/anaconda3/envs/NLP_project/lib/python3.12/site-packages (from scispacy) (1.14.1)\n",
      "Requirement already satisfied: conllu in /opt/anaconda3/envs/NLP_project/lib/python3.12/site-packages (from scispacy) (6.0.0)\n",
      "Requirement already satisfied: joblib in /opt/anaconda3/envs/NLP_project/lib/python3.12/site-packages (from scispacy) (1.4.2)\n",
      "Requirement already satisfied: pysbd in /opt/anaconda3/envs/NLP_project/lib/python3.12/site-packages (from scispacy) (0.3.4)\n",
      "Requirement already satisfied: nmslib-metabrainz==2.1.3 in /opt/anaconda3/envs/NLP_project/lib/python3.12/site-packages (from scispacy) (2.1.3)\n",
      "Requirement already satisfied: pybind11>=2.2.3 in /opt/anaconda3/envs/NLP_project/lib/python3.12/site-packages (from nmslib-metabrainz==2.1.3->scispacy) (2.13.6)\n",
      "Requirement already satisfied: psutil in /opt/anaconda3/envs/NLP_project/lib/python3.12/site-packages (from nmslib-metabrainz==2.1.3->scispacy) (5.9.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/anaconda3/envs/NLP_project/lib/python3.12/site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/anaconda3/envs/NLP_project/lib/python3.12/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/anaconda3/envs/NLP_project/lib/python3.12/site-packages (from matplotlib) (4.55.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/anaconda3/envs/NLP_project/lib/python3.12/site-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: pillow>=8 in /opt/anaconda3/envs/NLP_project/lib/python3.12/site-packages (from matplotlib) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/anaconda3/envs/NLP_project/lib/python3.12/site-packages (from matplotlib) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/anaconda3/envs/NLP_project/lib/python3.12/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/anaconda3/envs/NLP_project/lib/python3.12/site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: language-data>=1.2 in /opt/anaconda3/envs/NLP_project/lib/python3.12/site-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/anaconda3/envs/NLP_project/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in /opt/anaconda3/envs/NLP_project/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.27.1)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in /opt/anaconda3/envs/NLP_project/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.12.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/envs/NLP_project/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/envs/NLP_project/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/envs/NLP_project/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/envs/NLP_project/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/envs/NLP_project/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.8.30)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /opt/anaconda3/envs/NLP_project/lib/python3.12/site-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/anaconda3/envs/NLP_project/lib/python3.12/site-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.5)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /opt/anaconda3/envs/NLP_project/lib/python3.12/site-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.7)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /opt/anaconda3/envs/NLP_project/lib/python3.12/site-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.16.0)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /opt/anaconda3/envs/NLP_project/lib/python3.12/site-packages (from weasel<0.5.0,>=0.1.0->spacy) (6.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/envs/NLP_project/lib/python3.12/site-packages (from jinja2->spacy) (2.1.3)\n",
      "Requirement already satisfied: marisa-trie>=1.1.0 in /opt/anaconda3/envs/NLP_project/lib/python3.12/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install spacy scispacy negspacy matplotlib scikit-learn \"numpy<2.0\" https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.4/en_core_sci_sm-0.5.4.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-14T01:24:28.211091Z",
     "iopub.status.busy": "2024-12-14T01:24:28.210535Z",
     "iopub.status.idle": "2024-12-14T01:24:31.236219Z",
     "shell.execute_reply": "2024-12-14T01:24:31.235671Z",
     "shell.execute_reply.started": "2024-12-14T01:24:28.211044Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in /opt/anaconda3/envs/NLP_project/lib/python3.12/site-packages (3.7.5)\n",
      "Collecting spacy\n",
      "  Downloading spacy-3.8.3-cp312-cp312-macosx_11_0_arm64.whl.metadata (27 kB)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /opt/anaconda3/envs/NLP_project/lib/python3.12/site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/anaconda3/envs/NLP_project/lib/python3.12/site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/anaconda3/envs/NLP_project/lib/python3.12/site-packages (from spacy) (1.0.11)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/anaconda3/envs/NLP_project/lib/python3.12/site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/anaconda3/envs/NLP_project/lib/python3.12/site-packages (from spacy) (3.0.9)\n",
      "Collecting thinc<8.4.0,>=8.3.0 (from spacy)\n",
      "  Using cached thinc-8.3.2-cp312-cp312-macosx_11_0_arm64.whl.metadata (15 kB)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /opt/anaconda3/envs/NLP_project/lib/python3.12/site-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/anaconda3/envs/NLP_project/lib/python3.12/site-packages (from spacy) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/anaconda3/envs/NLP_project/lib/python3.12/site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /opt/anaconda3/envs/NLP_project/lib/python3.12/site-packages (from spacy) (0.3.4)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /opt/anaconda3/envs/NLP_project/lib/python3.12/site-packages (from spacy) (0.9.4)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/anaconda3/envs/NLP_project/lib/python3.12/site-packages (from spacy) (4.67.1)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /opt/anaconda3/envs/NLP_project/lib/python3.12/site-packages (from spacy) (1.26.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/anaconda3/envs/NLP_project/lib/python3.12/site-packages (from spacy) (2.32.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /opt/anaconda3/envs/NLP_project/lib/python3.12/site-packages (from spacy) (2.10.3)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/envs/NLP_project/lib/python3.12/site-packages (from spacy) (3.1.4)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/envs/NLP_project/lib/python3.12/site-packages (from spacy) (75.1.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/envs/NLP_project/lib/python3.12/site-packages (from spacy) (24.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/anaconda3/envs/NLP_project/lib/python3.12/site-packages (from spacy) (3.5.0)\n",
      "Requirement already satisfied: language-data>=1.2 in /opt/anaconda3/envs/NLP_project/lib/python3.12/site-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/anaconda3/envs/NLP_project/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in /opt/anaconda3/envs/NLP_project/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.27.1)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in /opt/anaconda3/envs/NLP_project/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/envs/NLP_project/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/envs/NLP_project/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/envs/NLP_project/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/envs/NLP_project/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.8.30)\n",
      "Collecting blis<1.1.0,>=1.0.0 (from thinc<8.4.0,>=8.3.0->spacy)\n",
      "  Downloading blis-1.0.2-cp312-cp312-macosx_11_0_arm64.whl.metadata (7.6 kB)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/anaconda3/envs/NLP_project/lib/python3.12/site-packages (from thinc<8.4.0,>=8.3.0->spacy) (0.1.5)\n",
      "Collecting numpy>=1.19.0 (from spacy)\n",
      "  Using cached numpy-2.0.2-cp312-cp312-macosx_14_0_arm64.whl.metadata (60 kB)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /opt/anaconda3/envs/NLP_project/lib/python3.12/site-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.7)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /opt/anaconda3/envs/NLP_project/lib/python3.12/site-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.16.0)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /opt/anaconda3/envs/NLP_project/lib/python3.12/site-packages (from weasel<0.5.0,>=0.1.0->spacy) (6.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/envs/NLP_project/lib/python3.12/site-packages (from jinja2->spacy) (2.1.3)\n",
      "Requirement already satisfied: marisa-trie>=1.1.0 in /opt/anaconda3/envs/NLP_project/lib/python3.12/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
      "Downloading spacy-3.8.3-cp312-cp312-macosx_11_0_arm64.whl (6.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m54.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached thinc-8.3.2-cp312-cp312-macosx_11_0_arm64.whl (761 kB)\n",
      "Using cached numpy-2.0.2-cp312-cp312-macosx_14_0_arm64.whl (5.0 MB)\n",
      "Downloading blis-1.0.2-cp312-cp312-macosx_11_0_arm64.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m40.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: numpy, blis, thinc, spacy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.26.4\n",
      "    Uninstalling numpy-1.26.4:\n",
      "      Successfully uninstalled numpy-1.26.4\n",
      "  Attempting uninstall: blis\n",
      "    Found existing installation: blis 0.7.11\n",
      "    Uninstalling blis-0.7.11:\n",
      "      Successfully uninstalled blis-0.7.11\n",
      "  Attempting uninstall: thinc\n",
      "    Found existing installation: thinc 8.2.5\n",
      "    Uninstalling thinc-8.2.5:\n",
      "      Successfully uninstalled thinc-8.2.5\n",
      "  Attempting uninstall: spacy\n",
      "    Found existing installation: spacy 3.7.5\n",
      "    Uninstalling spacy-3.7.5:\n",
      "      Successfully uninstalled spacy-3.7.5\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "en-ner-bc5cdr-md 0.5.4 requires spacy<3.8.0,>=3.7.4, but you have spacy 3.8.3 which is incompatible.\n",
      "en-core-sci-sm 0.5.4 requires spacy<3.8.0,>=3.7.4, but you have spacy 3.8.3 which is incompatible.\n",
      "scispacy 0.5.5 requires spacy<3.8.0,>=3.7.0, but you have spacy 3.8.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed blis-1.0.2 numpy-2.0.2 spacy-3.8.3 thinc-8.3.2\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "izBOGs2IaaCW"
   },
   "source": [
    "# Load Dataset\n",
    "MIMIC-IV Dataset from PhysioNet (https://physionet.org)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-14T01:23:37.895972Z",
     "iopub.status.busy": "2024-12-14T01:23:37.895478Z",
     "iopub.status.idle": "2024-12-14T01:23:37.900479Z",
     "shell.execute_reply": "2024-12-14T01:23:37.899856Z",
     "shell.execute_reply.started": "2024-12-14T01:23:37.895952Z"
    },
    "id": "xH3PX5kHaaCW",
    "outputId": "126e4ab0-2e21-488f-daca-bdeb23a11c9d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['poe_detail.csv', 'provider.csv', 'train_top50.csv', 'pharmacy.csv', 'emar.csv', 'microbiologyevents.csv', 'extracted_sections.csv', 'labevents.csv', 'admissions.csv', 'd_labitems.csv', 'prescriptions.csv', 'procedures_icd.csv', 'poe.csv', 'extracted_sections_with_diseases.csv', 'combined_hadm_id.csv', 'extracted_sections_sampled_300000.csv', 'd_hcpcs.csv', 'omr.csv', 'transfers.csv', 'diagnoses_icd.csv', 'services.csv', 'hcpcsevents.csv', 'drgcodes.csv', 'filtered_hadm_id.csv', 'extracted_sections_sampled.csv', 'patients.csv', 'test_top50.csv', 'extracted_sections_drop_empty.csv', 'd_icd_diagnoses.csv', 'd_icd_procedures.csv', 'df_sampled.csv', 'emar_detail.csv']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Specify the folder path\n",
    "folder_path = '/Users/benjamintan/Downloads/mimic-iv-3.1/hosp'\n",
    "\n",
    "# List all CSV files\n",
    "csv_files = [f for f in os.listdir(folder_path) if f.endswith('.csv')]\n",
    "\n",
    "# Print the CSV file names\n",
    "print(csv_files)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-14T01:23:26.080496Z",
     "iopub.status.busy": "2024-12-14T01:23:26.080201Z",
     "iopub.status.idle": "2024-12-14T01:23:26.083810Z",
     "shell.execute_reply": "2024-12-14T01:23:26.083229Z",
     "shell.execute_reply.started": "2024-12-14T01:23:26.080478Z"
    }
   },
   "source": [
    "## Checking the Column names and its frequency across each CSV files within the hosp folder in MIMIC-IV dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-14T01:23:39.856532Z",
     "iopub.status.busy": "2024-12-14T01:23:39.856265Z",
     "iopub.status.idle": "2024-12-14T01:23:40.266909Z",
     "shell.execute_reply": "2024-12-14T01:23:40.266694Z",
     "shell.execute_reply.started": "2024-12-14T01:23:39.856514Z"
    },
    "id": "NQlbWDJ_aaCX",
    "outputId": "e8134482-58fe-41ed-df4e-01cfd3c1e964",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in poe_detail.csv: ['poe_id', 'poe_seq', 'subject_id', 'field_name', 'field_value']\n",
      "Columns in provider.csv: ['provider_id']\n",
      "Columns in train_top50.csv: ['hadm_id', 'extracted_diseases', 'icd_code', 'long_title']\n",
      "Columns in pharmacy.csv: ['subject_id', 'hadm_id', 'pharmacy_id', 'poe_id', 'starttime', 'stoptime', 'medication', 'proc_type', 'status', 'entertime', 'verifiedtime', 'route', 'frequency', 'disp_sched', 'infusion_type', 'sliding_scale', 'lockout_interval', 'basal_rate', 'one_hr_max', 'doses_per_24_hrs', 'duration', 'duration_interval', 'expiration_value', 'expiration_unit', 'expirationdate', 'dispensation', 'fill_quantity']\n",
      "Columns in emar.csv: ['subject_id', 'hadm_id', 'emar_id', 'emar_seq', 'poe_id', 'pharmacy_id', 'enter_provider_id', 'charttime', 'medication', 'event_txt', 'scheduletime', 'storetime']\n",
      "Columns in microbiologyevents.csv: ['microevent_id', 'subject_id', 'hadm_id', 'micro_specimen_id', 'order_provider_id', 'chartdate', 'charttime', 'spec_itemid', 'spec_type_desc', 'test_seq', 'storedate', 'storetime', 'test_itemid', 'test_name', 'org_itemid', 'org_name', 'isolate_num', 'quantity', 'ab_itemid', 'ab_name', 'dilution_text', 'dilution_comparison', 'dilution_value', 'interpretation', 'comments']\n",
      "Columns in extracted_sections.csv: ['hadm_id', 'admission_type', 'admit_provider_id', 'admission_location', 'marital_status', 'race', 'seq_num', 'icd_code', 'icd_version', 'note_id', 'subject_id', 'note_type', 'note_seq', 'History of Present Illness', 'Past Medical History', 'Physical Exam']\n",
      "Columns in labevents.csv: ['labevent_id', 'subject_id', 'hadm_id', 'specimen_id', 'itemid', 'order_provider_id', 'charttime', 'storetime', 'value', 'valuenum', 'valueuom', 'ref_range_lower', 'ref_range_upper', 'flag', 'priority', 'comments']\n",
      "Columns in admissions.csv: ['subject_id', 'hadm_id', 'admittime', 'dischtime', 'deathtime', 'admission_type', 'admit_provider_id', 'admission_location', 'discharge_location', 'insurance', 'language', 'marital_status', 'race', 'edregtime', 'edouttime', 'hospital_expire_flag']\n",
      "Columns in d_labitems.csv: ['itemid', 'label', 'fluid', 'category']\n",
      "Columns in prescriptions.csv: ['subject_id', 'hadm_id', 'pharmacy_id', 'poe_id', 'poe_seq', 'order_provider_id', 'starttime', 'stoptime', 'drug_type', 'drug', 'formulary_drug_cd', 'gsn', 'ndc', 'prod_strength', 'form_rx', 'dose_val_rx', 'dose_unit_rx', 'form_val_disp', 'form_unit_disp', 'doses_per_24_hrs', 'route']\n",
      "Columns in procedures_icd.csv: ['subject_id', 'hadm_id', 'seq_num', 'chartdate', 'icd_code', 'icd_version']\n",
      "Columns in poe.csv: ['poe_id', 'poe_seq', 'subject_id', 'hadm_id', 'ordertime', 'order_type', 'order_subtype', 'transaction_type', 'discontinue_of_poe_id', 'discontinued_by_poe_id', 'order_provider_id', 'order_status']\n",
      "Columns in extracted_sections_with_diseases.csv: ['hadm_id', 'admission_type', 'icd_code', 'icd_version', 'long_title', 'clinical_notes', 'extracted_diseases']\n",
      "Columns in combined_hadm_id.csv: ['subject_id_x', 'hadm_id', 'admittime', 'dischtime', 'deathtime', 'admission_type', 'admit_provider_id', 'admission_location', 'discharge_location', 'insurance', 'language', 'marital_status', 'race', 'edregtime', 'edouttime', 'hospital_expire_flag', 'subject_id_y', 'seq_num', 'icd_code', 'icd_version', 'note_id', 'subject_id', 'note_type', 'note_seq', 'charttime', 'storetime', 'text']\n",
      "Columns in extracted_sections_sampled_300000.csv: ['hadm_id', 'admission_type', 'admit_provider_id', 'admission_location', 'marital_status', 'race', 'seq_num', 'icd_code', 'icd_version', 'note_id', 'subject_id', 'note_type', 'note_seq', 'History of Present Illness', 'Past Medical History', 'Physical Exam']\n",
      "Columns in d_hcpcs.csv: ['code', 'category', 'long_description', 'short_description']\n",
      "Columns in omr.csv: ['subject_id', 'chartdate', 'seq_num', 'result_name', 'result_value']\n",
      "Columns in transfers.csv: ['subject_id', 'hadm_id', 'transfer_id', 'eventtype', 'careunit', 'intime', 'outtime']\n",
      "Columns in diagnoses_icd.csv: ['subject_id', 'hadm_id', 'seq_num', 'icd_code', 'icd_version']\n",
      "Columns in services.csv: ['subject_id', 'hadm_id', 'transfertime', 'prev_service', 'curr_service']\n",
      "Columns in hcpcsevents.csv: ['subject_id', 'hadm_id', 'chartdate', 'hcpcs_cd', 'seq_num', 'short_description']\n",
      "Columns in drgcodes.csv: ['subject_id', 'hadm_id', 'drg_type', 'drg_code', 'description', 'drg_severity', 'drg_mortality']\n",
      "Columns in filtered_hadm_id.csv: ['hadm_id', 'admission_type', 'admit_provider_id', 'admission_location', 'marital_status', 'race', 'seq_num', 'icd_code', 'icd_version', 'note_id', 'subject_id', 'note_type', 'note_seq', 'text']\n",
      "Columns in extracted_sections_sampled.csv: ['hadm_id', 'admission_type', 'admit_provider_id', 'admission_location', 'marital_status', 'race', 'seq_num', 'icd_code', 'icd_version', 'note_id', 'subject_id', 'note_type', 'note_seq', 'History of Present Illness', 'Past Medical History', 'Physical Exam']\n",
      "Columns in patients.csv: ['subject_id', 'gender', 'anchor_age', 'anchor_year', 'anchor_year_group', 'dod']\n",
      "Columns in test_top50.csv: ['hadm_id', 'extracted_diseases', 'icd_code', 'long_title']\n",
      "Columns in extracted_sections_drop_empty.csv: ['hadm_id', 'admission_type', 'admit_provider_id', 'admission_location', 'marital_status', 'race', 'seq_num', 'icd_code', 'icd_version', 'note_id', 'subject_id', 'note_type', 'note_seq', 'History of Present Illness', 'Past Medical History', 'Physical Exam']\n",
      "Columns in d_icd_diagnoses.csv: ['icd_code', 'icd_version', 'long_title']\n",
      "Columns in d_icd_procedures.csv: ['icd_code', 'icd_version', 'long_title']\n",
      "Columns in df_sampled.csv: ['hadm_id', 'admission_type', 'icd_code', 'icd_version', 'long_title', 'clinical_notes']\n",
      "Columns in emar_detail.csv: ['subject_id', 'emar_id', 'emar_seq', 'parent_field_ordinal', 'administration_type', 'pharmacy_id', 'barcode_type', 'reason_for_no_barcode', 'complete_dose_not_given', 'dose_due', 'dose_due_unit', 'dose_given', 'dose_given_unit', 'will_remainder_of_dose_be_given', 'product_amount_given', 'product_unit', 'product_code', 'product_description', 'product_description_other', 'prior_infusion_rate', 'infusion_rate', 'infusion_rate_adjustment', 'infusion_rate_adjustment_amount', 'infusion_rate_unit', 'route', 'infusion_complete', 'completion_interval', 'new_iv_bag_hung', 'continued_infusion_in_other_location', 'restart_interval', 'side', 'site', 'non_formulary_visual_verification']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "for file in csv_files:\n",
    "    file_path = os.path.join(folder_path, file)  # Create the full file path\n",
    "    try:\n",
    "        df = pd.read_csv(file_path, nrows=5)  # Load only the first 5 rows for inspection\n",
    "        print(f\"Columns in {file}: {df.columns.tolist()}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to read {file}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1nHmh7a-aaCX",
    "outputId": "e9ed25ee-b6c5-4100-f3f3-cd05f996e6be",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns and their frequencies across files:\n",
      "subject_id: 17\n",
      "hadm_id: 13\n",
      "poe_id: 5\n",
      "pharmacy_id: 4\n",
      "order_provider_id: 4\n",
      "chartdate: 4\n",
      "seq_num: 4\n",
      "icd_code: 4\n",
      "icd_version: 4\n",
      "poe_seq: 3\n",
      "route: 3\n",
      "charttime: 3\n",
      "storetime: 3\n",
      "starttime: 2\n",
      "stoptime: 2\n",
      "medication: 2\n",
      "doses_per_24_hrs: 2\n",
      "emar_id: 2\n",
      "emar_seq: 2\n",
      "comments: 2\n",
      "itemid: 2\n",
      "category: 2\n",
      "short_description: 2\n",
      "long_title: 2\n",
      "field_name: 1\n",
      "field_value: 1\n",
      "provider_id: 1\n",
      "proc_type: 1\n",
      "status: 1\n",
      "entertime: 1\n",
      "verifiedtime: 1\n",
      "frequency: 1\n",
      "disp_sched: 1\n",
      "infusion_type: 1\n",
      "sliding_scale: 1\n",
      "lockout_interval: 1\n",
      "basal_rate: 1\n",
      "one_hr_max: 1\n",
      "duration: 1\n",
      "duration_interval: 1\n",
      "expiration_value: 1\n",
      "expiration_unit: 1\n",
      "expirationdate: 1\n",
      "dispensation: 1\n",
      "fill_quantity: 1\n",
      "enter_provider_id: 1\n",
      "event_txt: 1\n",
      "scheduletime: 1\n",
      "microevent_id: 1\n",
      "micro_specimen_id: 1\n",
      "spec_itemid: 1\n",
      "spec_type_desc: 1\n",
      "test_seq: 1\n",
      "storedate: 1\n",
      "test_itemid: 1\n",
      "test_name: 1\n",
      "org_itemid: 1\n",
      "org_name: 1\n",
      "isolate_num: 1\n",
      "quantity: 1\n",
      "ab_itemid: 1\n",
      "ab_name: 1\n",
      "dilution_text: 1\n",
      "dilution_comparison: 1\n",
      "dilution_value: 1\n",
      "interpretation: 1\n",
      "labevent_id: 1\n",
      "specimen_id: 1\n",
      "value: 1\n",
      "valuenum: 1\n",
      "valueuom: 1\n",
      "ref_range_lower: 1\n",
      "ref_range_upper: 1\n",
      "flag: 1\n",
      "priority: 1\n",
      "admittime: 1\n",
      "dischtime: 1\n",
      "deathtime: 1\n",
      "admission_type: 1\n",
      "admit_provider_id: 1\n",
      "admission_location: 1\n",
      "discharge_location: 1\n",
      "insurance: 1\n",
      "language: 1\n",
      "marital_status: 1\n",
      "race: 1\n",
      "edregtime: 1\n",
      "edouttime: 1\n",
      "hospital_expire_flag: 1\n",
      "label: 1\n",
      "fluid: 1\n",
      "drug_type: 1\n",
      "drug: 1\n",
      "formulary_drug_cd: 1\n",
      "gsn: 1\n",
      "ndc: 1\n",
      "prod_strength: 1\n",
      "form_rx: 1\n",
      "dose_val_rx: 1\n",
      "dose_unit_rx: 1\n",
      "form_val_disp: 1\n",
      "form_unit_disp: 1\n",
      "ordertime: 1\n",
      "order_type: 1\n",
      "order_subtype: 1\n",
      "transaction_type: 1\n",
      "discontinue_of_poe_id: 1\n",
      "discontinued_by_poe_id: 1\n",
      "order_status: 1\n",
      "code: 1\n",
      "long_description: 1\n",
      "result_name: 1\n",
      "result_value: 1\n",
      "transfer_id: 1\n",
      "eventtype: 1\n",
      "careunit: 1\n",
      "intime: 1\n",
      "outtime: 1\n",
      "transfertime: 1\n",
      "prev_service: 1\n",
      "curr_service: 1\n",
      "hcpcs_cd: 1\n",
      "drg_type: 1\n",
      "drg_code: 1\n",
      "description: 1\n",
      "drg_severity: 1\n",
      "drg_mortality: 1\n",
      "gender: 1\n",
      "anchor_age: 1\n",
      "anchor_year: 1\n",
      "anchor_year_group: 1\n",
      "dod: 1\n",
      "parent_field_ordinal: 1\n",
      "administration_type: 1\n",
      "barcode_type: 1\n",
      "reason_for_no_barcode: 1\n",
      "complete_dose_not_given: 1\n",
      "dose_due: 1\n",
      "dose_due_unit: 1\n",
      "dose_given: 1\n",
      "dose_given_unit: 1\n",
      "will_remainder_of_dose_be_given: 1\n",
      "product_amount_given: 1\n",
      "product_unit: 1\n",
      "product_code: 1\n",
      "product_description: 1\n",
      "product_description_other: 1\n",
      "prior_infusion_rate: 1\n",
      "infusion_rate: 1\n",
      "infusion_rate_adjustment: 1\n",
      "infusion_rate_adjustment_amount: 1\n",
      "infusion_rate_unit: 1\n",
      "infusion_complete: 1\n",
      "completion_interval: 1\n",
      "new_iv_bag_hung: 1\n",
      "continued_infusion_in_other_location: 1\n",
      "restart_interval: 1\n",
      "side: 1\n",
      "site: 1\n",
      "non_formulary_visual_verification: 1\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Specify the folder path\n",
    "folder_path = '/Users/benjamintan/Downloads/mimic-iv-3.1/hosp'\n",
    "\n",
    "# List all CSV files\n",
    "csv_files = [f for f in os.listdir(folder_path) if f.endswith('.csv')]\n",
    "\n",
    "# Dictionary to store columns for each file\n",
    "column_counts = Counter()\n",
    "\n",
    "# Count the occurrence of each column across all files\n",
    "for file in csv_files:\n",
    "    file_path = os.path.join(folder_path, file)  # Full path to the file\n",
    "    try:\n",
    "        df = pd.read_csv(file_path, nrows=0)  # Only read the header\n",
    "        column_counts.update(df.columns)  # Update the counter with columns\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to read {file}: {e}\")\n",
    "\n",
    "# Find the most common columns\n",
    "most_common_columns = column_counts.most_common()\n",
    "\n",
    "# Print the columns and their frequencies\n",
    "print(\"Columns and their frequencies across files:\")\n",
    "for column, count in most_common_columns:\n",
    "    print(f\"{column}: {count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nxcxTkmPaaCX",
    "outputId": "7b7bfbfc-0a12-424e-faee-689958ada2bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files containing 'hadm_id': ['/Users/benjamintan/Downloads/mimic-iv-3.1/hosp/pharmacy.csv', '/Users/benjamintan/Downloads/mimic-iv-3.1/hosp/emar.csv', '/Users/benjamintan/Downloads/mimic-iv-3.1/hosp/microbiologyevents.csv', '/Users/benjamintan/Downloads/mimic-iv-3.1/hosp/labevents.csv', '/Users/benjamintan/Downloads/mimic-iv-3.1/hosp/admissions.csv', '/Users/benjamintan/Downloads/mimic-iv-3.1/hosp/prescriptions.csv', '/Users/benjamintan/Downloads/mimic-iv-3.1/hosp/procedures_icd.csv', '/Users/benjamintan/Downloads/mimic-iv-3.1/hosp/poe.csv', '/Users/benjamintan/Downloads/mimic-iv-3.1/hosp/transfers.csv', '/Users/benjamintan/Downloads/mimic-iv-3.1/hosp/diagnoses_icd.csv', '/Users/benjamintan/Downloads/mimic-iv-3.1/hosp/services.csv', '/Users/benjamintan/Downloads/mimic-iv-3.1/hosp/hcpcsevents.csv', '/Users/benjamintan/Downloads/mimic-iv-3.1/hosp/drgcodes.csv']\n"
     ]
    }
   ],
   "source": [
    "# Filter files that contain the 'hadm_id' column\n",
    "valid_files = []\n",
    "for file in csv_files:\n",
    "    file_path = os.path.join(folder_path, file)  # Full path to the file\n",
    "    try:\n",
    "        df = pd.read_csv(file_path, nrows=0)  # Only read the header\n",
    "        if 'hadm_id' in df.columns:  # Check for 'hadm_id'\n",
    "            valid_files.append(file_path)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to read {file}: {e}\")\n",
    "\n",
    "# Print valid files\n",
    "print(f\"Files containing 'hadm_id': {valid_files}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TB7yZ7qBaaCX",
    "outputId": "1f5fa75d-ee32-4956-be8d-fd5004121d2e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined file: /Users/benjamintan/Downloads/mimic-iv-3.1/hosp/admissions.csv\n",
      "Combined file: /Users/benjamintan/Downloads/mimic-iv-3.1/hosp/diagnoses_icd.csv\n",
      "Combined file: /Users/benjamintan/Downloads/mimic-iv-3.1/note/discharge.csv\n",
      "Combined file saved to /Users/benjamintan/Downloads/mimic-iv-3.1/hosp/combined_hadm_id.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# File paths to combine\n",
    "file_paths = [\n",
    "    '/Users/benjamintan/Downloads/mimic-iv-3.1/hosp/admissions.csv',\n",
    "    #'/Users/benjamintan/Downloads/mimic-iv-3.1/hosp/pharmacy.csv',\n",
    "    #'/Users/benjamintan/Downloads/mimic-iv-3.1/hosp/prescriptions.csv',\n",
    "    #'/Users/benjamintan/Downloads/mimic-iv-3.1/hosp/procedures_icd.csv',\n",
    "    '/Users/benjamintan/Downloads/mimic-iv-3.1/hosp/diagnoses_icd.csv',\n",
    "    '/Users/benjamintan/Downloads/mimic-iv-3.1/note/discharge.csv'\n",
    "]\n",
    "\n",
    "# Initialize combined DataFrame\n",
    "combined_df = None\n",
    "\n",
    "# Combine files with 'hadm_id'\n",
    "for file_path in file_paths:\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)  # Read the file\n",
    "        if 'hadm_id' in df.columns:  # Check for 'hadm_id'\n",
    "            if combined_df is None:\n",
    "                combined_df = df  # Initialize combined DataFrame\n",
    "            else:\n",
    "                combined_df = pd.merge(combined_df, df, on='hadm_id', how='outer')  # Merge on 'hadm_id'\n",
    "            print(f\"Combined file: {file_path}\")\n",
    "        else:\n",
    "            print(f\"Skipping {file_path}: 'hadm_id' not found.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to process {file_path}: {e}\")\n",
    "\n",
    "# Save the combined DataFrame to a new CSV file\n",
    "output_path = '/Users/benjamintan/Downloads/mimic-iv-3.1/hosp/combined_hadm_id.csv'\n",
    "if combined_df is not None:\n",
    "    combined_df.to_csv(output_path, index=False)\n",
    "    print(f\"Combined file saved to {output_path}\")\n",
    "else:\n",
    "    print(\"No files were combined.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-14T02:18:59.425696Z",
     "iopub.status.busy": "2024-12-14T02:18:59.425190Z",
     "iopub.status.idle": "2024-12-14T02:19:46.799117Z",
     "shell.execute_reply": "2024-12-14T02:19:46.798703Z",
     "shell.execute_reply.started": "2024-12-14T02:18:59.425645Z"
    },
    "id": "xiw7V1xIaaCX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Filtered DataFrame (Top 20 ICD Codes):\n",
      "     hadm_id     admission_type icd_code  icd_version  \\\n",
      "44  23052089           EW EMER.     E785         10.0   \n",
      "57  22927623     EU OBSERVATION     K219         10.0   \n",
      "59  22927623     EU OBSERVATION     F419         10.0   \n",
      "62  22927623     EU OBSERVATION   Z87891         10.0   \n",
      "67  27988844  OBSERVATION ADMIT     K219         10.0   \n",
      "\n",
      "                                           long_title  \\\n",
      "44                        Hyperlipidemia, unspecified   \n",
      "57  Gastro-esophageal reflux disease without esoph...   \n",
      "59                      Anxiety disorder, unspecified   \n",
      "62            Personal history of nicotine dependence   \n",
      "67  Gastro-esophageal reflux disease without esoph...   \n",
      "\n",
      "                                       clinical_notes  \n",
      "44  Visual hallucinations\\n \\nMajor Surgical or In...  \n",
      "57  dysphagia \\n \\nMajor Surgical or Invasive Proc...  \n",
      "59  dysphagia \\n \\nMajor Surgical or Invasive Proc...  \n",
      "62  dysphagia \\n \\nMajor Surgical or Invasive Proc...  \n",
      "67                        Relevant section not found.  \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "# Define the function to extract relevant content\n",
    "def extract_relevant_content(text):\n",
    "    \"\"\"\n",
    "    Extracts relevant sections: Chief Complaint, Major Surgical or Invasive Procedure, \n",
    "    History of Present Illness, Past Medical History, Social History, and Family History from the text.\n",
    "    \"\"\"\n",
    "    # Use regex to find the content between the specified headers\n",
    "    match = re.search(r\"Chief Complaint:(.*?)(?=Pertinent Results:)\", text, re.DOTALL)\n",
    "    \n",
    "    if match:\n",
    "        relevant_content = match.group(1).strip()  # Extract the matched content and remove extra spaces\n",
    "        return relevant_content\n",
    "    else:\n",
    "        return \"Relevant section not found.\"\n",
    "\n",
    "# Load the datasets\n",
    "diagnoses_icd = pd.read_csv('diagnoses_icd.csv')\n",
    "d_icd_diagnoses = pd.read_csv('d_icd_diagnoses.csv')\n",
    "admissions = pd.read_csv('admissions.csv')\n",
    "discharge = pd.read_csv('/Users/benjamintan/Downloads/mimic-iv-3.1/note/discharge.csv')\n",
    "\n",
    "# Extract the relevant text from the `text` column in `discharge.csv`\n",
    "discharge['clinical_notes'] = discharge['text'].apply(extract_relevant_content)\n",
    "\n",
    "# Merge the diagnoses with their descriptions\n",
    "diagnoses = diagnoses_icd.merge(d_icd_diagnoses, on=['icd_code', 'icd_version'], how='left')\n",
    "\n",
    "# Merge the admissions and diagnoses datasets\n",
    "df = admissions.merge(diagnoses, on=['subject_id', 'hadm_id'], how='left')\n",
    "\n",
    "# Merge the resulting dataframe with the discharge notes\n",
    "df = df.merge(discharge[['hadm_id', 'clinical_notes']], on='hadm_id', how='left')\n",
    "\n",
    "# Drop rows where there is no relevant text and icd_code\n",
    "df = df.dropna(subset=['clinical_notes'])\n",
    "df = df.dropna(subset=['icd_code'])\n",
    "\n",
    "# Only keep rows where icd_version = 10\n",
    "df = df[df['icd_version'] == 10]\n",
    "\n",
    "# Only keep relevant columns \n",
    "df = df[['hadm_id', 'admission_type', 'icd_code', 'icd_version', 'long_title', 'clinical_notes']]\n",
    "\n",
    "# Step 1: Find the top 50 most frequent icd_code\n",
    "top_20_icd_codes = (\n",
    "    df['icd_code']\n",
    "    .value_counts()  # Count occurrences of each icd_code\n",
    "    .nlargest(20)    # Efficiently take the top 20 largest values\n",
    "    .index           # Extract the indices (the top 20 icd_codes themselves)\n",
    ")\n",
    "\n",
    "# Step 2: Filter the DataFrame to only include rows with the top 50 icd_code\n",
    "df = df[df['icd_code'].isin(top_20_icd_codes)]\n",
    "\n",
    "# Step 3: Export the results to CSV (optional)\n",
    "df.to_csv('filtered_top_20_icd_codes.csv', index=False)\n",
    "\n",
    "# Step 4: Display outputs (optional)\n",
    "print(\"\\nFiltered DataFrame (Top 20 ICD Codes):\")\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-14T02:07:45.313495Z",
     "iopub.status.busy": "2024-12-14T02:07:45.312489Z",
     "iopub.status.idle": "2024-12-14T02:07:45.317042Z",
     "shell.execute_reply": "2024-12-14T02:07:45.316476Z",
     "shell.execute_reply.started": "2024-12-14T02:07:45.313454Z"
    }
   },
   "source": [
    "## Check for each icd_code frequency to ensure large enough dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-14T02:19:46.800233Z",
     "iopub.status.busy": "2024-12-14T02:19:46.800136Z",
     "iopub.status.idle": "2024-12-14T02:19:46.814472Z",
     "shell.execute_reply": "2024-12-14T02:19:46.813989Z",
     "shell.execute_reply.started": "2024-12-14T02:19:46.800225Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ICD Code Frequencies:\n",
      "   icd_code  frequency\n",
      "0      E785      44040\n",
      "1       I10      43571\n",
      "2    Z87891      36296\n",
      "3      K219      30801\n",
      "4      F329      23228\n",
      "5     I2510      22608\n",
      "6      N179      19705\n",
      "7      F419      19152\n",
      "8     Z7901      15321\n",
      "9      Z794      15276\n",
      "10     E039      15253\n",
      "11     E119      13572\n",
      "12    G4733      12658\n",
      "13     D649      12467\n",
      "14     E669      12145\n",
      "15    I4891      12034\n",
      "16   F17210      11619\n",
      "17     Y929      11548\n",
      "18      Z66      10743\n",
      "19   J45909      10614\n"
     ]
    }
   ],
   "source": [
    "# Count each icd_code's frequency\n",
    "icd_code_frequencies = (\n",
    "    df['icd_code']\n",
    "    .value_counts()  # Count occurrences of each icd_code\n",
    "    .reset_index()   # Convert the result into a DataFrame\n",
    ")\n",
    "\n",
    "# Rename columns for readability\n",
    "icd_code_frequencies.columns = ['icd_code', 'frequency']\n",
    "\n",
    "# Export the frequency data to a CSV file (optional)\n",
    "icd_code_frequencies.to_csv('icd_code_frequencies.csv', index=False)\n",
    "\n",
    "# Display the frequencies (optional)\n",
    "print(\"ICD Code Frequencies:\")\n",
    "print(icd_code_frequencies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downsizing of dataset while maintaining a balanced representation of each code to ensure that all icd_code values are equally represented, reducing data bias while within our compute power.\n",
    "Cap the frequency of each icd_code at 10,000 and Randomly selecting rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-14T02:58:19.631564Z",
     "iopub.status.busy": "2024-12-14T02:58:19.631121Z",
     "iopub.status.idle": "2024-12-14T02:58:25.001050Z",
     "shell.execute_reply": "2024-12-14T02:58:25.000811Z",
     "shell.execute_reply.started": "2024-12-14T02:58:19.631542Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7j/4c1jprp94wb1yjdvj314vdt80000gn/T/ipykernel_16475/1024877108.py:9: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda x: x.sample(n=min(len(x), max_frequency), random_state=42))  # Randomly sample up to 10,000 rows\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original number of rows: 392651\n",
      "Reduced number of rows: 200000\n",
      "          hadm_id      admission_type icd_code  icd_version  \\\n",
      "5928282  27536269  DIRECT OBSERVATION     D649         10.0   \n",
      "4845468  24763988            ELECTIVE     D649         10.0   \n",
      "1147691  24794962            EW EMER.     D649         10.0   \n",
      "5100234  27808245              URGENT     D649         10.0   \n",
      "5120304  27286115        DIRECT EMER.     D649         10.0   \n",
      "\n",
      "                  long_title  \\\n",
      "5928282  Anemia, unspecified   \n",
      "4845468  Anemia, unspecified   \n",
      "1147691  Anemia, unspecified   \n",
      "5100234  Anemia, unspecified   \n",
      "5120304  Anemia, unspecified   \n",
      "\n",
      "                                            clinical_notes  \n",
      "5928282  heavy uterine bleeding\\n \\nMajor Surgical or I...  \n",
      "4845468  admit for oxaliplatin desens/administration\\n ...  \n",
      "1147691  fever, positive cryptococcal antigen\\n \\nMajor...  \n",
      "5100234  \"Not good\"\\n \\nMajor Surgical or Invasive Proc...  \n",
      "5120304  ___\\n \\nMajor Surgical or Invasive Procedure:\\...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Set the maximum number of rows per ICD code\n",
    "max_frequency = 10000\n",
    "\n",
    "# Reduce rows for each ICD code\n",
    "df_reduced = (\n",
    "    df.groupby('icd_code', group_keys=False)  # Group by ICD code\n",
    "    .apply(lambda x: x.sample(n=min(len(x), max_frequency), random_state=42))  # Randomly sample up to 10,000 rows\n",
    ")\n",
    "\n",
    "# Export the reduced DataFrame to a CSV file (optional)\n",
    "df_reduced.to_csv('reduced_data.csv', index=False)\n",
    "\n",
    "# Display the size of the new dataset and a sample (optional)\n",
    "print(f\"Original number of rows: {len(df)}\")\n",
    "print(f\"Reduced number of rows: {len(df_reduced)}\")\n",
    "print(df_reduced.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop empty rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-14T03:00:38.290588Z",
     "iopub.status.busy": "2024-12-14T03:00:38.290125Z",
     "iopub.status.idle": "2024-12-14T03:00:43.542786Z",
     "shell.execute_reply": "2024-12-14T03:00:43.542565Z",
     "shell.execute_reply.started": "2024-12-14T03:00:38.290559Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned DataFrame (no empty rows):\n",
      "          hadm_id      admission_type icd_code  icd_version  \\\n",
      "5928282  27536269  DIRECT OBSERVATION     D649         10.0   \n",
      "4845468  24763988            ELECTIVE     D649         10.0   \n",
      "1147691  24794962            EW EMER.     D649         10.0   \n",
      "5100234  27808245              URGENT     D649         10.0   \n",
      "5120304  27286115        DIRECT EMER.     D649         10.0   \n",
      "\n",
      "                  long_title  \\\n",
      "5928282  Anemia, unspecified   \n",
      "4845468  Anemia, unspecified   \n",
      "1147691  Anemia, unspecified   \n",
      "5100234  Anemia, unspecified   \n",
      "5120304  Anemia, unspecified   \n",
      "\n",
      "                                            clinical_notes  \n",
      "5928282  heavy uterine bleeding\\n \\nMajor Surgical or I...  \n",
      "4845468  admit for oxaliplatin desens/administration\\n ...  \n",
      "1147691  fever, positive cryptococcal antigen\\n \\nMajor...  \n",
      "5100234  \"Not good\"\\n \\nMajor Surgical or Invasive Proc...  \n",
      "5120304  ___\\n \\nMajor Surgical or Invasive Procedure:\\...  \n"
     ]
    }
   ],
   "source": [
    "# Drop rows with any empty or NaN values\n",
    "df_reduced = df_reduced.dropna()\n",
    "\n",
    "# Export the cleaned DataFrame to a CSV file (optional)\n",
    "df_reduced.to_csv('cleaned_reduced_data.csv', index=False)\n",
    "\n",
    "# Display the first few rows of the cleaned DataFrame (optional)\n",
    "print(\"Cleaned DataFrame (no empty rows):\")\n",
    "print(df_reduced.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NER Feature Extraction (of disease) then feed the features into ClinicalBert, SVM for training to predict ICD code\n",
    "Using ScispaCy, NegspaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-14T03:03:02.464549Z",
     "iopub.status.busy": "2024-12-14T03:03:02.464261Z",
     "iopub.status.idle": "2024-12-14T03:03:13.657354Z",
     "shell.execute_reply": "2024-12-14T03:03:13.657043Z",
     "shell.execute_reply.started": "2024-12-14T03:03:02.464529Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV Columns: ['hadm_id', 'admission_type', 'icd_code', 'icd_version', 'long_title', 'clinical_notes']\n",
      "\n",
      "Negation Analysis:\n",
      "Negated Entities: ['ideation', 'perceptual disturbance', 'hallucination', 'paranoid ideation', 'seizure', 'epilepsy', 'normoactive bs \\n present', 'rash', 'edema', 'agitation/retardation', 'denie delusion', 'psychomotor agitation/ retardation', 'denie delusion']\n",
      "\n",
      "Detailed Negation Information:\n",
      "Entity: ideation (Type: DISEASE)\n",
      "Context: \n",
      "  denie homicidal ideation , deny perceptual\n",
      "Negation Type: direct\n",
      "\n",
      "Entity: perceptual disturbance (Type: DISEASE)\n",
      "Context: ideation , deny perceptual disturbance c/w\n",
      "Negation Type: direct\n",
      "\n",
      "Entity: hallucination (Type: DISEASE)\n",
      "Context: disturbance c/w \n",
      "  hallucination , deny paranoid\n",
      "Negation Type: direct\n",
      "\n",
      "Entity: paranoid ideation (Type: DISEASE)\n",
      "Context: \n",
      "  hallucination , deny paranoid ideation .\n",
      "Negation Type: direct\n",
      "\n",
      "Entity: seizure (Type: DISEASE)\n",
      "Context: _ - unknown type  \n",
      "   no seizure or epilepsy in the\n",
      "Negation Type: direct\n",
      "\n",
      "Entity: epilepsy (Type: DISEASE)\n",
      "Context: type  \n",
      "   no seizure or epilepsy in the family  \n",
      " \n",
      " \n",
      " \n",
      "Negation Type: direct\n",
      "\n",
      "Entity: normoactive bs \n",
      " present (Type: DISEASE)\n",
      "Context: tender , not distend , normoactive bs \n",
      "  present\n",
      "Negation Type: direct\n",
      "\n",
      "Entity: rash (Type: DISEASE)\n",
      "Context: r  \n",
      "   skin : WWP , no rash , no ble edema \n",
      "\n",
      "  mental\n",
      "Negation Type: direct\n",
      "\n",
      "Entity: edema (Type: DISEASE)\n",
      "Context: WWP , no rash , no ble edema \n",
      "\n",
      "  mental Status :\n",
      "Negation Type: direct\n",
      "\n",
      "Entity: agitation/retardation (Type: DISEASE)\n",
      "Context: , no psychomotor \n",
      "  agitation/retardation , eps\n",
      "Negation Type: direct\n",
      "\n",
      "Entity: denie delusion (Type: DISEASE)\n",
      "Context: denie delusion or ah/vh/hi\n",
      "Negation Type: direct\n",
      "\n",
      "Entity: psychomotor agitation/ retardation (Type: DISEASE)\n",
      "Context: ) , attentive , without psychomotor agitation/ retardation\n",
      "Negation Type: direct\n",
      "\n",
      "Entity: denie delusion (Type: DISEASE)\n",
      "Context: denie delusion or ah/vh \n",
      " \n",
      "Negation Type: direct\n",
      "\n",
      "\n",
      "Detected Entities:\n",
      "psychiatric (Type: DISEASE)\n",
      "htn (Type: DISEASE)\n",
      "hypothyroidism (Type: DISEASE)\n",
      "s/p papillary thyroid \n",
      " carcinoma resection (Type: DISEASE)\n",
      "obesity (Type: DISEASE)\n",
      "depression (Type: DISEASE)\n",
      "depressed mood (Type: DISEASE)\n",
      "depressed (Type: DISEASE)\n",
      "ideation (Type: NEG_ENTITY)\n",
      "perceptual disturbance (Type: NEG_ENTITY)\n",
      "hallucination (Type: NEG_ENTITY)\n",
      "paranoid ideation (Type: NEG_ENTITY)\n",
      "stroke (Type: DISEASE)\n",
      "obesity (Type: DISEASE)\n",
      "hyperparathyroidism (Type: DISEASE)\n",
      "Glaucoma (Type: DISEASE)\n",
      "diabetic retinopathy (Type: DISEASE)\n",
      "diabetic neuropathy (Type: DISEASE)\n",
      "depression (Type: DISEASE)\n",
      "Anemia (Type: DISEASE)\n",
      "apnea (Type: DISEASE)\n",
      "htn (Type: DISEASE)\n",
      "hypothyroidism (Type: DISEASE)\n",
      "s/p papillary thyroid carcinoma (Type: DISEASE)\n",
      "gout (Type: DISEASE)\n",
      "asthma (Type: DISEASE)\n",
      "ptsd (Type: DISEASE)\n",
      "cardiac disorder (Type: DISEASE)\n",
      "stroke (Type: DISEASE)\n",
      "seizure (Type: NEG_ENTITY)\n",
      "epilepsy (Type: NEG_ENTITY)\n",
      "normoactive bs \n",
      " present (Type: NEG_ENTITY)\n",
      "rash (Type: NEG_ENTITY)\n",
      "edema (Type: NEG_ENTITY)\n",
      "agitation/retardation (Type: NEG_ENTITY)\n",
      "tremor (Type: DISEASE)\n",
      "Depressed (Type: DISEASE)\n",
      "denie delusion (Type: NEG_ENTITY)\n",
      "psychomotor agitation/ retardation (Type: NEG_ENTITY)\n",
      "tremor (Type: DISEASE)\n",
      "denie delusion (Type: NEG_ENTITY)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><!DOCTYPE html>\n",
       "<html lang=\"en\">\n",
       "    <head>\n",
       "        <title>displaCy</title>\n",
       "    </head>\n",
       "\n",
       "    <body style=\"font-size: 16px; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol'; padding: 4rem 2rem; direction: ltr\">\n",
       "<figure style=\"margin-bottom: 6rem\">\n",
       "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">&quot; not good &quot; <br> <br> major surgical or Invasive Procedure : <br> none <br><br> <br> history of Present Illness : <br> per Dr. _ _ _ consultation note on _ _ _ : <br> &quot; we be ask to perform a \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(180deg, #1ABC9C, #DAF7A6); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    psychiatric\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DISEASE</span>\n",
       "</mark>\n",
       " evaluation/provide <br> management recommendation for this _ _ _ year old woman w/ \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(180deg, #1ABC9C, #DAF7A6); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    htn\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DISEASE</span>\n",
       "</mark>\n",
       " , <br> ckd , chf , dm , hx dvt/pe , \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(180deg, #1ABC9C, #DAF7A6); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    hypothyroidism\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DISEASE</span>\n",
       "</mark>\n",
       " ( \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(180deg, #1ABC9C, #DAF7A6); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    s/p papillary thyroid \n",
       " carcinoma resection\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DISEASE</span>\n",
       "</mark>\n",
       " ) , \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(180deg, #1ABC9C, #DAF7A6); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    obesity\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DISEASE</span>\n",
       "</mark>\n",
       " , hx cva x3 ( _ _ _ ) , <br> \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(180deg, #1ABC9C, #DAF7A6); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    depression\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DISEASE</span>\n",
       "</mark>\n",
       " , complex developmental trauma/ptsd , who present to <br> the _ _ _ with complaint of worsen \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(180deg, #1ABC9C, #DAF7A6); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    depressed mood\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DISEASE</span>\n",
       "</mark>\n",
       " and suicidal <br> thought . <br><br> she be a very limited historian and minimally engage . she <br> state she feel &quot; terrible &quot; , and have be \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(180deg, #1ABC9C, #DAF7A6); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    depressed\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DISEASE</span>\n",
       "</mark>\n",
       " since her <br> brother pass away about two week ago and be not able to make <br> the service in _ _ _ . she say &quot; I want to die with he &quot; and <br> that she still feel this way currently and then ask to be leave <br> alone . <br><br> she say she be not sleep or eat well , but also respond <br> with &quot; I do not know &quot; to many direct question . she currently <br> denie homicidal \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(90deg, #E74C3C, #ff6600); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    ideation\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NEG_ENTITY</span>\n",
       "</mark>\n",
       " , deny \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(90deg, #E74C3C, #ff6600); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    perceptual disturbance\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NEG_ENTITY</span>\n",
       "</mark>\n",
       " c/w <br> \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(90deg, #E74C3C, #ff6600); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    hallucination\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NEG_ENTITY</span>\n",
       "</mark>\n",
       " , deny \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(90deg, #E74C3C, #ff6600); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    paranoid ideation\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NEG_ENTITY</span>\n",
       "</mark>\n",
       " . she deny recent <br> substance use . <br><br> she be evaluate by psychiatry on _ _ _ , at that time state <br> she &quot; promise God &quot; she would not try to take her own life . today <br> she tell I she be no long spiritual or identify with her <br> faith . <br><br> spoke w/ _ _ _ _ _ _ , last meet _ _ _ , she <br> direct I to other _ _ _ clinician who have <br> work <br> with the patient more recently , include her pcp . &quot; <br> <br> past medical history : <br> prior \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(180deg, #1ABC9C, #DAF7A6); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    stroke\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DISEASE</span>\n",
       "</mark>\n",
       " : residual leave side weakness . <br> \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(180deg, #1ABC9C, #DAF7A6); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    obesity\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DISEASE</span>\n",
       "</mark>\n",
       " <br> \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(180deg, #1ABC9C, #DAF7A6); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    hyperparathyroidism\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DISEASE</span>\n",
       "</mark>\n",
       " <br> oa <br> Asthma <br> hld <br> pvd <br> \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(180deg, #1ABC9C, #DAF7A6); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Glaucoma\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DISEASE</span>\n",
       "</mark>\n",
       " <br> \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(180deg, #1ABC9C, #DAF7A6); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    diabetic retinopathy\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DISEASE</span>\n",
       "</mark>\n",
       " <br> pe/dvt x2 <br> cad <br> chf <br> dm2 <br> ckd ( stage 4 ) <br> \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(180deg, #1ABC9C, #DAF7A6); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    diabetic neuropathy\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DISEASE</span>\n",
       "</mark>\n",
       " <br> \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(180deg, #1ABC9C, #DAF7A6); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    depression\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DISEASE</span>\n",
       "</mark>\n",
       " <br> \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(180deg, #1ABC9C, #DAF7A6); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Anemia\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DISEASE</span>\n",
       "</mark>\n",
       " <br> Speep \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(180deg, #1ABC9C, #DAF7A6); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    apnea\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DISEASE</span>\n",
       "</mark>\n",
       " <br> \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(180deg, #1ABC9C, #DAF7A6); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    htn\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DISEASE</span>\n",
       "</mark>\n",
       " <br> \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(180deg, #1ABC9C, #DAF7A6); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    hypothyroidism\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DISEASE</span>\n",
       "</mark>\n",
       " ( \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(180deg, #1ABC9C, #DAF7A6); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    s/p papillary thyroid carcinoma\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DISEASE</span>\n",
       "</mark>\n",
       " resection ) <br> \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(180deg, #1ABC9C, #DAF7A6); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    gout\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DISEASE</span>\n",
       "</mark>\n",
       " <br> gerd <br> \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(180deg, #1ABC9C, #DAF7A6); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    asthma\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DISEASE</span>\n",
       "</mark>\n",
       " <br> \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(180deg, #1ABC9C, #DAF7A6); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    ptsd\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DISEASE</span>\n",
       "</mark>\n",
       " with dissociative episode <br><br> <br> Social history : <br> _ _ _ <br> Family history : <br> Father _ _ _ from \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(180deg, #1ABC9C, #DAF7A6); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    cardiac disorder\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DISEASE</span>\n",
       "</mark>\n",
       " at _ _ _  <br>  maternal Aunt _ _ _  <br>  mother _ _ _ \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(180deg, #1ABC9C, #DAF7A6); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    stroke\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DISEASE</span>\n",
       "</mark>\n",
       "  <br>  Paternal Grandfather _ _ _ - unknown type  <br>  paternal uncle _ _ _ - unknown type  <br>  no \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(90deg, #E74C3C, #ff6600); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    seizure\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NEG_ENTITY</span>\n",
       "</mark>\n",
       " or \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(90deg, #E74C3C, #ff6600); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    epilepsy\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NEG_ENTITY</span>\n",
       "</mark>\n",
       " in the family  <br> <br> <br> Physical Exam : <br> admission : <br> _ _ _ _ _ _ _ _ _ _ <br> exam : <br> * vs - 1607 : t 98.3 , bp 179/81 , hr 62 , o2 100 % ra <br>       1753 :          bp 154/76 , hr 62 , o2 99 %   ra , rr 16 <br><br> Physical Examination : <br> GENERAL : well appear woman , in nad , rest comfortably in <br> chair <br>  heent : nc/at , mm slightly dry , EOMI , perrla <br>  NECK : supple , trachea midline , no carotid bruit  <br>  cardiac : rrr no m/r/g appreciated <br>  lung : ctab no w/r/r  <br>  abdomen : soft , not tender , not distend , \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(90deg, #E74C3C, #ff6600); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    normoactive bs \n",
       " present\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NEG_ENTITY</span>\n",
       "</mark>\n",
       " in all 4 quadrant <br>  extremities : wwp , well heal scar over bilateral knee  <br>  neurologic : cn _ _ _ intact with exception of r &gt; l sensation of <br> light touch on face ( baseline per patient report ) , strength be <br> _ _ _ for elbow flexor and extensor , grip be 4+/5 on left <br> compare to _ _ _ on right , sensation to light touch be intact on <br> BUE but she feel the right hand feel funny to touch , sensation <br> to left leg be slightly reduce throughout compare to right , <br> hip <br> flexor on l be _ _ _ compare to _ _ _ on r , knee flexor and <br> extensor _ _ _ bilaterally , ankle flexor on l _ _ _ compare to <br> _ _ _ <br> on r  <br>  skin : WWP , no \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(90deg, #E74C3C, #ff6600); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    rash\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NEG_ENTITY</span>\n",
       "</mark>\n",
       " , no ble \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(90deg, #E74C3C, #ff6600); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    edema\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NEG_ENTITY</span>\n",
       "</mark>\n",
       " <br><br> mental Status : <br> * appearance : age appear aa woman , nad , ambulate with <br> walker , <br> on interview seat comfortably , appropriately dress in <br> hospital gown , fair hygiene , well keep on examination <br> * behavior : cooperative and appropriate , good eye-contact <br> ( appropriate , direct ) , attentive , no psychomotor <br> \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(90deg, #E74C3C, #ff6600); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    agitation/retardation\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NEG_ENTITY</span>\n",
       "</mark>\n",
       " , eps , or \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(180deg, #1ABC9C, #DAF7A6); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    tremor\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DISEASE</span>\n",
       "</mark>\n",
       " <br> * mood and affect : &quot; \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(180deg, #1ABC9C, #DAF7A6); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Depressed\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DISEASE</span>\n",
       "</mark>\n",
       " , &quot; affect : at time euthymic but <br> regard brother 's passing appear sadden , intermittently <br> dramatic , reactive <br> * thought process : linear , mostly coherent , goal-directed , no <br> loa , <br> ruminative <br> * Thought Content : Denies active SI . \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(90deg, #E74C3C, #ff6600); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    denie delusion\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NEG_ENTITY</span>\n",
       "</mark>\n",
       " or ah/vh/hi <br><br> * Judgment and insight : limited/fair <br> cognition : <br> * attention : Attentive <br> * Orientation , and executive function : awake , alert and orient <br> to person , month , and year . able to list moyb without <br> difficulty . <br> * calculation : $ 1.75 = 7 quarter <br> * abstraction : apple/orange = &quot; fruit &quot; <br> * proverb : &quot; grass be always greener on the other side &quot; and &quot; do not <br> judge a book by its cover &quot; - &quot; I do not agree with these as <br> saying &quot; <br> * memory : _ _ _ registration , _ _ _ recall with categorical cue <br> * fund of knowledge : name _ _ _ president    <br> * speech : slow to normal rate , regular rhythm , normal volume , <br> spontaneous <br> * language : fluent in _ _ _ without paraphasic error <br> _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br> Discharge Mental Status Exam : <br> * appearance : age appear aa woman , nad , sit comfortably , <br> appropriately dress in hospital gown , fair hygiene , well keep <br> on examination <br> * behavior : pleasant , cooperative , good eye-contact ( appropriate , <br> direct ) , attentive , without \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(90deg, #E74C3C, #ff6600); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    psychomotor agitation/ retardation\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NEG_ENTITY</span>\n",
       "</mark>\n",
       " , <br> eps , or \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(180deg, #1ABC9C, #DAF7A6); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    tremor\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DISEASE</span>\n",
       "</mark>\n",
       " <br> * mood and affect : &quot; good , &quot; affect : more euthymic <br> * thought process : reality orient , goal-directed <br> * Thought Content : Denies si/hi . \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(90deg, #E74C3C, #ff6600); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    denie delusion\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NEG_ENTITY</span>\n",
       "</mark>\n",
       " or ah/vh <br> * Judgment and insight : fair <br> Cognition : <br> * attention : Attentive <br> * Orientation , and executive function : awake , alert and orient <br> to person , month , and year . <br> * speech : spontaneous , normal rate , volume and tone <br> * language : fluent in _ _ _ without paraphasic error</div>\n",
       "</figure>\n",
       "</body>\n",
       "</html></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Visualization saved to: ner_visualizations/ner_visualization_row_3.html\n",
      "\n",
      "Open the HTML file at: ner_visualizations/ner_visualization_row_3.html\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "import scispacy\n",
    "from spacy import displacy\n",
    "from spacy.matcher import PhraseMatcher\n",
    "from spacy.tokens import Span\n",
    "import os\n",
    "\n",
    "def lemmatize(note, nlp):\n",
    "    \"\"\"Lemmatize the input text to capture different word forms\"\"\"\n",
    "    doc = nlp(note)\n",
    "    lemNote = [wd.lemma_ for wd in doc]\n",
    "    return \" \".join(lemNote)\n",
    "\n",
    "def get_entity_options():\n",
    "    \"\"\"Define visualization options for Named Entities\"\"\"\n",
    "    entities = [\"DISEASE\", \"CHEMICAL\", \"NEG_ENTITY\"]\n",
    "    colors = {\n",
    "        'DISEASE': 'linear-gradient(180deg, #1ABC9C, #DAF7A6)', \n",
    "        'CHEMICAL': 'linear-gradient(90deg, #3498DB, #fc9ce7)', \n",
    "        \"NEG_ENTITY\": 'linear-gradient(90deg, #E74C3C, #ff6600)'\n",
    "    }\n",
    "    return {\"ents\": entities, \"colors\": colors}\n",
    "\n",
    "def custom_neg_handling(doc):\n",
    "    \"\"\"\n",
    "    Enhanced negation detection with comprehensive context analysis\n",
    "    \n",
    "    Args:\n",
    "        doc (spacy.tokens.Doc): Processed spaCy document\n",
    "    \n",
    "    Returns:\n",
    "        dict: A dictionary with detailed negation information\n",
    "    \"\"\"\n",
    "    # Comprehensive negation terms and patterns\n",
    "    negation_terms = {\n",
    "        'direct': [\n",
    "            'no', 'not', 'never', 'neither', 'none', \n",
    "            'absence', 'absent', 'denied', 'deny', 'denie',\n",
    "            'rule out', 'ruled out', 'without', 'hasn\\'t', \n",
    "            'haven\\'t', 'didn\\'t', 'don\\'t', 'cannot', \n",
    "            'can\\'t', 'no evidence', 'negates', 'negative'\n",
    "        ],\n",
    "        'pre_modifiers': [\n",
    "            'unlikely', 'improbable', 'doubtful', \n",
    "            'unconfirmed', 'unconvinced'\n",
    "        ],\n",
    "        'post_modifiers': [\n",
    "            'free', 'clear', 'resolved', 'eliminated'\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    negation_results = {\n",
    "        'negated_entities': [],\n",
    "        'detailed_negations': []\n",
    "    }\n",
    "    \n",
    "    # Iterate through sentences\n",
    "    for sent in doc.sents:\n",
    "        for ent in sent.ents:\n",
    "            # Wider context window for negation detection\n",
    "            context_window = 25  # characters before and after the entity\n",
    "            \n",
    "            # Extract context tokens\n",
    "            context_tokens = [\n",
    "                token for token in sent \n",
    "                if abs(token.idx - ent.start_char) < context_window\n",
    "            ]\n",
    "            \n",
    "            # Convert context to lowercase for easier matching\n",
    "            context_lower = [token.lower_ for token in context_tokens]\n",
    "            \n",
    "            # Check for direct negation terms\n",
    "            is_negated = any(neg in context_lower for neg in negation_terms['direct'])\n",
    "            \n",
    "            # Check for pre and post negation modifiers\n",
    "            pre_neg = any(mod in context_lower[:3] for mod in negation_terms['pre_modifiers'])\n",
    "            post_neg = any(mod in context_lower[-3:] for mod in negation_terms['post_modifiers'])\n",
    "            \n",
    "            # Detailed negation analysis\n",
    "            if is_negated or pre_neg or post_neg:\n",
    "                negation_details = {\n",
    "                    'entity': ent.text,\n",
    "                    'type': ent.label_,\n",
    "                    'context': ' '.join([token.text for token in context_tokens]),\n",
    "                    'negation_type': 'direct' if is_negated else 'modified'\n",
    "                }\n",
    "                \n",
    "                negation_results['negated_entities'].append(ent.text)\n",
    "                negation_results['detailed_negations'].append(negation_details)\n",
    "    \n",
    "    return negation_results\n",
    "\n",
    "def print_negation_analysis(negation_results):\n",
    "    \"\"\"\n",
    "    Print a detailed analysis of negated entities\n",
    "    \n",
    "    Args:\n",
    "        negation_results (dict): Negation analysis results\n",
    "    \"\"\"\n",
    "    print(\"\\nNegation Analysis:\")\n",
    "    if not negation_results['negated_entities']:\n",
    "        print(\"No negated entities found.\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Negated Entities: {negation_results['negated_entities']}\")\n",
    "    print(\"\\nDetailed Negation Information:\")\n",
    "    for neg in negation_results['detailed_negations']:\n",
    "        print(f\"Entity: {neg['entity']} (Type: {neg['type']})\")\n",
    "        print(f\"Context: {neg['context']}\")\n",
    "        print(f\"Negation Type: {neg['negation_type']}\\n\")\n",
    "\n",
    "def process_single_note(file_path, row_index, output_dir='ner_visualizations'):\n",
    "    \"\"\"\n",
    "    Process and visualize a single note from the CSV with enhanced output\n",
    "    \n",
    "    Args:\n",
    "        file_path (str): Path to CSV file\n",
    "        row_index (int): Index of the row to process\n",
    "        output_dir (str): Directory to save visualization output\n",
    "    \"\"\"\n",
    "    # Load scispaCy models\n",
    "    try:\n",
    "        nlp0 = spacy.load(\"en_core_sci_sm\")\n",
    "        nlp1 = spacy.load(\"en_ner_bc5cdr_md\")\n",
    "    except OSError as e:\n",
    "        print(f\"Error loading spaCy models: {e}\")\n",
    "        print(\"Make sure you have installed the models using:\")\n",
    "        print(\"python -m spacy download en_core_sci_sm\")\n",
    "        print(\"python -m spacy download en_ner_bc5cdr_md\")\n",
    "        raise\n",
    "\n",
    "    # Create output directory if it doesn't exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Load the CSV file\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Check if the row index is valid\n",
    "    if row_index >= len(df):\n",
    "        raise IndexError(f\"Row index {row_index} is out of bounds for the given CSV file.\")\n",
    "    \n",
    "    # Extract the note text\n",
    "    if 'clinical_notes' not in df.columns:\n",
    "        raise KeyError(\"The column 'clinical_notes' is not present in the CSV file.\")\n",
    "    \n",
    "    clinical_notes = df.loc[row_index, 'clinical_notes']\n",
    "    if pd.isna(clinical_notes):\n",
    "        raise ValueError(f\"The clinical notes at row {row_index} are missing or empty.\")\n",
    "    \n",
    "    # Lemmatize the text\n",
    "    lemmatized_text = lemmatize(clinical_notes, nlp0)\n",
    "    \n",
    "    # Prepare visualization options\n",
    "    options = get_entity_options()\n",
    "    \n",
    "    # Process the note with NER\n",
    "    doc = nlp1(lemmatized_text)\n",
    "    \n",
    "    # Get negated entities\n",
    "    neg_results = custom_neg_handling(doc)\n",
    "    \n",
    "    # Print negation analysis\n",
    "    print_negation_analysis(neg_results)\n",
    "    \n",
    "    # Modify entities to include negation\n",
    "    negated_entities = neg_results['negated_entities']\n",
    "    neg_entity_label = \"NEG_ENTITY\"\n",
    "\n",
    "    if neg_entity_label not in doc.vocab.strings:\n",
    "        doc.vocab.strings.add(neg_entity_label)\n",
    "    \n",
    "    # Create a new list of entities to replace the existing ones\n",
    "    modified_entities = []\n",
    "    for ent in doc.ents:\n",
    "        if ent.text in negated_entities:\n",
    "            # Create a new span with NEG_ENTITY label\n",
    "            new_ent = Span(doc, ent.start, ent.end, label=doc.vocab.strings[\"NEG_ENTITY\"])\n",
    "            modified_entities.append(new_ent)\n",
    "        else:\n",
    "            modified_entities.append(ent)\n",
    "    \n",
    "    # Replace the document's entities\n",
    "    doc.ents = tuple(modified_entities)\n",
    "    \n",
    "    # Diagnostic print for entities\n",
    "    print(\"\\nDetected Entities:\")\n",
    "    for ent in doc.ents:\n",
    "        print(f\"{ent.text} (Type: {ent.label_})\")\n",
    "\n",
    "    # Prepare the HTML visualization with explicit parameters\n",
    "    try:\n",
    "        html = displacy.render(doc, style='ent', options=options, page=True)\n",
    "        \n",
    "        # Ensure html is a string \n",
    "        if not isinstance(html, str):\n",
    "            html = str(html)\n",
    "        \n",
    "        # Generate output file path\n",
    "        output_file = os.path.join(output_dir, f'ner_visualization_row_{row_index}.html')\n",
    "        \n",
    "        # Write the visualization to an HTML file\n",
    "        with open(output_file, 'w', encoding='utf-8') as f:\n",
    "            f.write(html)\n",
    "        \n",
    "        print(f\"\\nVisualization saved to: {output_file}\")\n",
    "        \n",
    "        return doc, output_file\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating HTML visualization: {e}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "# Diagnostic function to check CSV contents\n",
    "def preview_csv(file_path, num_rows=5):\n",
    "    \"\"\"\n",
    "    Preview the contents of the CSV file\n",
    "    \n",
    "    Args:\n",
    "        file_path (str): Path to the CSV file\n",
    "        num_rows (int): Number of rows to preview\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(file_path)\n",
    "    print(\"CSV Columns:\", list(df.columns))\n",
    "\n",
    "# Example usage with error handling\n",
    "def main():\n",
    "    try:\n",
    "        # First, preview the CSV to understand its structure\n",
    "        preview_csv('cleaned_reduced_data.csv')\n",
    "        \n",
    "        # Then attempt to process a specific row\n",
    "        doc, output_file = process_single_note('cleaned_reduced_data.csv', 3)\n",
    "        print(f\"\\nOpen the HTML file at: {output_file}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-14T03:03:35.814456Z",
     "iopub.status.busy": "2024-12-14T03:03:35.814013Z",
     "iopub.status.idle": "2024-12-14T17:38:45.959617Z",
     "shell.execute_reply": "2024-12-14T17:38:45.959361Z",
     "shell.execute_reply.started": "2024-12-14T03:03:35.814435Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 200000 rows...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200000/200000 [14:34:56<00:00,  3.81it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed CSV saved to: cleaned_reduced_data_with_diseases.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "import scispacy\n",
    "import os\n",
    "from tqdm import tqdm  # For progress tracking\n",
    "\n",
    "def extract_diseases_from_note(note, nlp0, nlp1):\n",
    "    \"\"\"\n",
    "    Extract diseases from a medical note using NER with negation handling.\n",
    "\n",
    "    Args:\n",
    "        note (str): Medical note text\n",
    "        nlp0 (spacy.language.Language): Lemmatization model\n",
    "        nlp1 (spacy.language.Language): NER model\n",
    "\n",
    "    Returns:\n",
    "        list: List of unique disease entities\n",
    "    \"\"\"\n",
    "    # Lemmatize the text\n",
    "    lemmatized_text = lemmatize(note, nlp0)\n",
    "    \n",
    "    # Process the note with NER\n",
    "    doc = nlp1(lemmatized_text)\n",
    "\n",
    "    # Add NEG_ENTITY label to StringStore\n",
    "    neg_entity_label = \"NEG_ENTITY\"\n",
    "    if neg_entity_label not in doc.vocab.strings:\n",
    "        doc.vocab.strings.add(neg_entity_label)\n",
    "\n",
    "    # Detect negated entities\n",
    "    neg_results = custom_neg_handling(doc)\n",
    "\n",
    "    # Extract unique diseases excluding negated entities\n",
    "    negated_entities = neg_results['negated_entities']\n",
    "    diseases = set(ent.text for ent in doc.ents if ent.label_ == 'DISEASE' and ent.text not in negated_entities)\n",
    "\n",
    "    return list(diseases)\n",
    "\n",
    "def lemmatize(note, nlp):\n",
    "    \"\"\"Lemmatize the input text\"\"\"\n",
    "    doc = nlp(note)\n",
    "    return \" \".join([wd.lemma_ for wd in doc])\n",
    "\n",
    "def custom_neg_handling(doc):\n",
    "    \"\"\"\n",
    "    Perform custom negation detection on a spaCy document.\n",
    "\n",
    "    Args:\n",
    "        doc (spacy.tokens.Doc): Processed spaCy document.\n",
    "\n",
    "    Returns:\n",
    "        dict: Dictionary with negated entities and detailed negation information.\n",
    "    \"\"\"\n",
    "    negation_terms = {\n",
    "        'direct': [\n",
    "            'no', 'not', 'never', 'neither', 'none', \n",
    "            'absence', 'absent', 'denied', 'deny', 'denie',\n",
    "            'rule out', 'ruled out', 'without', 'hasn\\'t', \n",
    "            'haven\\'t', 'didn\\'t', 'don\\'t', 'cannot', \n",
    "            'can\\'t', 'no evidence', 'negates', 'negative'\n",
    "        ],\n",
    "        'pre_modifiers': [\n",
    "            'unlikely', 'improbable', 'doubtful', \n",
    "            'unconfirmed', 'unconvinced'\n",
    "        ],\n",
    "        'post_modifiers': [\n",
    "            'free', 'clear', 'resolved', 'eliminated'\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    negation_results = {\n",
    "        'negated_entities': [],\n",
    "        'detailed_negations': []\n",
    "    }\n",
    "    \n",
    "    for ent in doc.ents:\n",
    "        context_window = 25\n",
    "        context_tokens = [\n",
    "            token.text.lower() for token in doc[max(0, ent.start - 5): min(len(doc), ent.end + 5)]\n",
    "        ]\n",
    "        if any(term in context_tokens for term in negation_terms):\n",
    "            negation_results['negated_entities'].append(ent.text)\n",
    "\n",
    "    return negation_results\n",
    "\n",
    "def process_csv_with_ner(input_file, output_file):\n",
    "    \"\"\"\n",
    "    Process entire CSV file and extract diseases for each row.\n",
    "\n",
    "    Args:\n",
    "        input_file (str): Path to input CSV.\n",
    "        output_file (str): Path to output CSV.\n",
    "    \"\"\"\n",
    "    # Load scispaCy models\n",
    "    try:\n",
    "        nlp0 = spacy.load(\"en_core_sci_sm\")\n",
    "        nlp1 = spacy.load(\"en_ner_bc5cdr_md\")\n",
    "    except OSError as e:\n",
    "        print(f\"Error loading spaCy models: {e}\")\n",
    "        raise\n",
    "\n",
    "    # Load the CSV file\n",
    "    df = pd.read_csv(input_file)\n",
    "    \n",
    "    # Add new column for extracted diseases\n",
    "    df['extracted_diseases'] = None\n",
    "\n",
    "    print(f\"Processing {len(df)} rows...\")\n",
    "    for index, row in tqdm(df.iterrows(), total=len(df)):\n",
    "        try:\n",
    "            clinical_notes = row['clinical_notes']  # Correctly reference the clinical_notes column\n",
    "          \n",
    "            # Extract diseases\n",
    "            diseases = extract_diseases_from_note(clinical_notes, nlp0, nlp1)\n",
    "            \n",
    "            # Save diseases to the new column\n",
    "            df.at[index, 'extracted_diseases'] = '; '.join(diseases) if diseases else None\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing row {index}: {e}\")\n",
    "    \n",
    "    # Save updated CSV\n",
    "    df.to_csv(output_file, index=False)\n",
    "    print(f\"\\nProcessed CSV saved to: {output_file}\")\n",
    "\n",
    "def main():\n",
    "    try:\n",
    "        input_file = 'cleaned_reduced_data.csv'\n",
    "        output_file = 'cleaned_reduced_data_with_diseases.csv'\n",
    "        \n",
    "        process_csv_with_ner(input_file, output_file)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using BlueBert Transformer from Huggingface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Default BlueBert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-15T03:27:16.775233Z",
     "iopub.status.busy": "2024-12-15T03:27:16.774700Z",
     "iopub.status.idle": "2024-12-15T03:27:16.780380Z",
     "shell.execute_reply": "2024-12-15T03:27:16.779606Z",
     "shell.execute_reply.started": "2024-12-15T03:27:16.775200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.5.1\n",
      "MPS available: True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# Verify Metal Performance Shaders (MPS) Availability on MacBook Pro (M3 Max)\n",
    "\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "print(\"MPS available:\", torch.backends.mps.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-15T13:40:58.957458Z",
     "iopub.status.busy": "2024-12-15T13:40:58.956871Z",
     "iopub.status.idle": "2024-12-15T17:45:17.684655Z",
     "shell.execute_reply": "2024-12-15T17:45:17.684132Z",
     "shell.execute_reply.started": "2024-12-15T13:40:58.957433Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 10000/10000 [49:48<00:00,  3.35batch/s, loss=2.21]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss: 2.7410358791828155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|██████████| 10000/10000 [50:12<00:00,  3.32batch/s, loss=2.4]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Loss: 2.6616400730013847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|██████████| 10000/10000 [45:28<00:00,  3.66batch/s, loss=2.82]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Loss: 2.596599576830864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|██████████| 10000/10000 [46:00<00:00,  3.62batch/s, loss=2.7]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 Loss: 2.5129036761760712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|██████████| 10000/10000 [48:12<00:00,  3.46batch/s, loss=2.41] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 Loss: 2.408880945169926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 2500/2500 [04:00<00:00, 10.39batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.135225\n",
      "Classification Report (default_bluebert):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        D649       0.08      0.06      0.07      1996\n",
      "        E039       0.16      0.19      0.17      1986\n",
      "        E119       0.15      0.19      0.17      1933\n",
      "        E669       0.13      0.09      0.11      2069\n",
      "        E785       0.12      0.04      0.06      2017\n",
      "      F17210       0.17      0.21      0.19      1971\n",
      "        F329       0.12      0.05      0.07      2009\n",
      "        F419       0.15      0.07      0.09      2012\n",
      "       G4733       0.16      0.22      0.18      1973\n",
      "         I10       0.10      0.08      0.09      2027\n",
      "       I2510       0.13      0.18      0.15      2016\n",
      "       I4891       0.15      0.16      0.16      1916\n",
      "      J45909       0.18      0.18      0.18      1954\n",
      "        K219       0.11      0.02      0.04      2024\n",
      "        N179       0.09      0.06      0.07      2006\n",
      "        Y929       0.09      0.21      0.12      2015\n",
      "         Z66       0.14      0.20      0.17      2020\n",
      "       Z7901       0.17      0.23      0.19      2066\n",
      "        Z794       0.16      0.23      0.19      2022\n",
      "      Z87891       0.06      0.02      0.03      1968\n",
      "\n",
      "    accuracy                           0.14     40000\n",
      "   macro avg       0.13      0.14      0.12     40000\n",
      "weighted avg       0.13      0.14      0.12     40000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'BlueBERTForSequenceClassification' object has no attribute 'save_pretrained'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[82], line 133\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28mprint\u001b[39m(classification_report(true_labels, predictions, target_names\u001b[38;5;241m=\u001b[39mid_to_icd\u001b[38;5;241m.\u001b[39mvalues()))\n\u001b[1;32m    132\u001b[0m \u001b[38;5;66;03m# Save the fine-tuned model\u001b[39;00m\n\u001b[0;32m--> 133\u001b[0m model\u001b[38;5;241m.\u001b[39msave_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./default_bluebert\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    134\u001b[0m tokenizer\u001b[38;5;241m.\u001b[39msave_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./default_bluebert\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/NLP_project/lib/python3.12/site-packages/torch/nn/modules/module.py:1931\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1929\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[1;32m   1930\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1931\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m   1932\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1933\u001b[0m )\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'BlueBERTForSequenceClassification' object has no attribute 'save_pretrained'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Detect device\n",
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"cleaned_reduced_data_with_diseases.csv\")\n",
    "df = df[['clinical_notes', 'icd_code']].rename(columns={'clinical_notes': 'text', 'icd_code': 'label'})\n",
    "\n",
    "# Map ICD codes to numeric labels\n",
    "icd_to_id = {code: idx for idx, code in enumerate(df['label'].unique())}\n",
    "id_to_icd = {v: k for k, v in icd_to_id.items()}\n",
    "df['label'] = df['label'].map(icd_to_id)\n",
    "\n",
    "# Split into training and validation sets\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    df['text'], df['label'], test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"menadsa/S-BlueBERT\")\n",
    "\n",
    "# Create a PyTorch Dataset class\n",
    "class ClinicalNotesDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_len=128):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts.iloc[idx]\n",
    "        label = self.labels.iloc[idx]\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            max_length=self.max_len,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        return {\n",
    "            \"input_ids\": encoding[\"input_ids\"].squeeze(),\n",
    "            \"attention_mask\": encoding[\"attention_mask\"].squeeze(),\n",
    "            \"labels\": torch.tensor(label, dtype=torch.long),\n",
    "        }\n",
    "\n",
    "# Prepare datasets\n",
    "train_dataset = ClinicalNotesDataset(train_texts, train_labels, tokenizer)\n",
    "val_dataset = ClinicalNotesDataset(val_texts, val_labels, tokenizer)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16)\n",
    "\n",
    "# Load the base BlueBERT model\n",
    "base_model = AutoModel.from_pretrained(\"menadsa/S-BlueBERT\")\n",
    "\n",
    "# Define a custom model with a classification head\n",
    "class BlueBERTForSequenceClassification(nn.Module):\n",
    "    def __init__(self, base_model, num_labels):\n",
    "        super(BlueBERTForSequenceClassification, self).__init__()\n",
    "        self.base_model = base_model\n",
    "        self.classifier = nn.Linear(base_model.config.hidden_size, num_labels)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, labels=None):\n",
    "        outputs = self.base_model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = outputs[1]  # Pooled output\n",
    "        logits = self.classifier(pooled_output)\n",
    "        return logits\n",
    "\n",
    "num_labels = len(icd_to_id)\n",
    "model = BlueBERTForSequenceClassification(base_model, num_labels).to(device)\n",
    "\n",
    "# Define optimizer and loss function\n",
    "optimizer = optim.AdamW(model.parameters(), lr=2e-5)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Training loop with tqdm\n",
    "epochs = 5\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{epochs}\", unit=\"batch\")\n",
    "    for batch in progress_bar:\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        labels = batch[\"labels\"].to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        loss = criterion(outputs, labels)\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        progress_bar.set_postfix({\"loss\": loss.item()})\n",
    "    print(f\"Epoch {epoch + 1} Loss: {total_loss / len(train_loader)}\")\n",
    "\n",
    "# Validation loop with tqdm\n",
    "model.eval()\n",
    "predictions, true_labels = [], []\n",
    "progress_bar = tqdm(val_loader, desc=\"Evaluating\", unit=\"batch\")\n",
    "with torch.no_grad():\n",
    "    for batch in progress_bar:\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        labels = batch[\"labels\"].to(device)\n",
    "\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs\n",
    "        predictions.extend(torch.argmax(logits, dim=-1).cpu().numpy())\n",
    "        true_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "accuracy = accuracy_score(true_labels, predictions)\n",
    "print(f\"Validation Accuracy: {accuracy}\")\n",
    "print(\"Classification Report (default_bluebert):\")\n",
    "print(classification_report(true_labels, predictions, target_names=id_to_icd.values()))\n",
    "\n",
    "# Save the fine-tuned model\n",
    "model.save_pretrained(\"./default_bluebert\")\n",
    "tokenizer.save_pretrained(\"./default_bluebert\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T00:34:34.025752Z",
     "iopub.status.busy": "2024-12-16T00:34:34.025191Z",
     "iopub.status.idle": "2024-12-16T00:34:35.216105Z",
     "shell.execute_reply": "2024-12-16T00:34:35.215869Z",
     "shell.execute_reply.started": "2024-12-16T00:34:34.025731Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./default_bluebert/tokenizer_config.json',\n",
       " './default_bluebert/special_tokens_map.json',\n",
       " './default_bluebert/vocab.txt',\n",
       " './default_bluebert/added_tokens.json',\n",
       " './default_bluebert/tokenizer.json')"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Due to AttributeError: 'BlueBERTForSequenceClassification' object has no attribute 'save_pretrained'\n",
    "# Save the fine-tuned model (PyTorch state_dict)\n",
    "torch.save(model.state_dict(), \"./default_bluebert.pth\")\n",
    "\n",
    "# Save the tokenizer (Hugging Face tokenizer)\n",
    "tokenizer.save_pretrained(\"./default_bluebert\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tuning BlueBert "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T00:37:40.734951Z",
     "iopub.status.busy": "2024-12-16T00:37:40.734184Z",
     "iopub.status.idle": "2024-12-16T02:48:08.286441Z",
     "shell.execute_reply": "2024-12-16T02:48:08.286103Z",
     "shell.execute_reply.started": "2024-12-16T00:37:40.734906Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-Tuning Epoch 1/3: 100%|██████████| 10000/10000 [42:23<00:00,  3.93batch/s, loss=2.2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-Tuning Epoch 1 Loss: 2.2953016469597816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-Tuning Epoch 2/3: 100%|██████████| 10000/10000 [43:01<00:00,  3.87batch/s, loss=1.95]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-Tuning Epoch 2 Loss: 2.186794139111042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-Tuning Epoch 3/3: 100%|██████████| 10000/10000 [45:01<00:00,  3.70batch/s, loss=2.2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-Tuning Epoch 3 Loss: 2.082736420094967\n",
      "Fine-tuned model and tokenizer saved successfully.\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Split training and validation sets\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    df['text'], df['label'], test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Create training and validation datasets\n",
    "train_dataset = ClinicalNotesDataset(train_texts, train_labels, tokenizer)\n",
    "val_dataset = ClinicalNotesDataset(val_texts, val_labels, tokenizer)\n",
    "\n",
    "# Prepare DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16)\n",
    "\n",
    "# Define optimizer and loss function for fine-tuning\n",
    "optimizer = optim.AdamW(model.parameters(), lr=2e-5)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Training loop with tqdm for fine-tuning\n",
    "epochs = 3  # Set the number of epochs\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    progress_bar = tqdm(train_loader, desc=f\"Fine-Tuning Epoch {epoch + 1}/{epochs}\", unit=\"batch\")\n",
    "    for batch in progress_bar:\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        labels = batch[\"labels\"].to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        loss = criterion(outputs, labels)\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update progress bar with current loss\n",
    "        progress_bar.set_postfix({\"loss\": loss.item()})\n",
    "    print(f\"Fine-Tuning Epoch {epoch + 1} Loss: {total_loss / len(train_loader)}\")\n",
    "\n",
    "# Save the fine-tuned model using torch\n",
    "torch.save(model.state_dict(), \"./fine_tuned_bluebert.pth\")\n",
    "\n",
    "# Save the tokenizer using Hugging Face's save_pretrained\n",
    "tokenizer.save_pretrained(\"./fine_tuned_bluebert\")\n",
    "\n",
    "print(\"Fine-tuned model and tokenizer saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate fine-tuned BlueBert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T03:00:53.723541Z",
     "iopub.status.busy": "2024-12-16T03:00:53.722772Z",
     "iopub.status.idle": "2024-12-16T03:04:38.532184Z",
     "shell.execute_reply": "2024-12-16T03:04:38.531922Z",
     "shell.execute_reply.started": "2024-12-16T03:00:53.723493Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Fine-Tuned BlueBERT: 100%|██████████| 2500/2500 [03:44<00:00, 11.12batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy (fine_tuned_bluebert): 0.0826\n",
      "Classification Report (fine_tuned_bluebert):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        D649       0.06      0.03      0.04      1996\n",
      "        E039       0.09      0.08      0.09      1986\n",
      "        E119       0.10      0.11      0.10      1933\n",
      "        E669       0.06      0.03      0.04      2069\n",
      "        E785       0.06      0.04      0.05      2017\n",
      "      F17210       0.12      0.12      0.12      1971\n",
      "        F329       0.05      0.04      0.04      2009\n",
      "        F419       0.09      0.06      0.07      2012\n",
      "       G4733       0.07      0.20      0.11      1973\n",
      "         I10       0.05      0.05      0.05      2027\n",
      "       I2510       0.09      0.11      0.10      2016\n",
      "       I4891       0.10      0.16      0.13      1916\n",
      "      J45909       0.12      0.10      0.11      1954\n",
      "        K219       0.06      0.03      0.04      2024\n",
      "        N179       0.05      0.04      0.04      2006\n",
      "        Y929       0.09      0.08      0.08      2015\n",
      "         Z66       0.08      0.12      0.10      2020\n",
      "       Z7901       0.11      0.11      0.11      2066\n",
      "        Z794       0.10      0.13      0.11      2022\n",
      "      Z87891       0.03      0.02      0.02      1968\n",
      "\n",
      "    accuracy                           0.08     40000\n",
      "   macro avg       0.08      0.08      0.08     40000\n",
      "weighted avg       0.08      0.08      0.08     40000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Ensure the fine-tuned model is in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Prepare the DataLoader for the validation set\n",
    "val_loader = DataLoader(val_dataset, batch_size=16)\n",
    "\n",
    "# Initialize lists to store predictions and true labels\n",
    "predictions, true_labels = [], []\n",
    "\n",
    "# Perform evaluation with progress tracking using tqdm\n",
    "with torch.no_grad():  # Disable gradient computation\n",
    "    for batch in tqdm(val_loader, desc=\"Evaluating Fine-Tuned BlueBERT\", unit=\"batch\"):\n",
    "        # Move batch data to device (MPS/CPU)\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        labels = batch[\"labels\"].to(device)\n",
    "        \n",
    "        # Get model outputs\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs  # Direct logits from the model\n",
    "\n",
    "        # Store predictions and true labels\n",
    "        predictions.extend(torch.argmax(logits, dim=-1).cpu().numpy())\n",
    "        true_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# Calculate accuracy and other evaluation metrics\n",
    "accuracy = accuracy_score(true_labels, predictions)\n",
    "print(\"Validation Accuracy (fine_tuned_bluebert):\", accuracy)\n",
    "print(\"Classification Report (fine_tuned_bluebert):\")\n",
    "print(classification_report(true_labels, predictions, target_names=id_to_icd.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running on ClinicalBert (Default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T03:45:06.878421Z",
     "iopub.status.busy": "2024-12-16T03:45:06.877038Z",
     "iopub.status.idle": "2024-12-16T03:49:16.418250Z",
     "shell.execute_reply": "2024-12-16T03:49:16.417960Z",
     "shell.execute_reply.started": "2024-12-16T03:45:06.878352Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at emilyalsentzer/Bio_ClinicalBERT and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Evaluating Default ClinicalBERT: 100%|██████████| 2500/2500 [03:52<00:00, 10.75batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy (default_clinicalbert): 0.049375\n",
      "Classification Report (default_clinicalbert):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        D649       0.00      0.00      0.00      1996\n",
      "        E039       0.00      0.00      0.00      1986\n",
      "        E119       0.00      0.00      0.00      1933\n",
      "        E669       0.00      0.00      0.00      2069\n",
      "        E785       0.00      0.00      0.00      2017\n",
      "      F17210       0.05      0.97      0.09      1971\n",
      "        F329       0.04      0.02      0.03      2009\n",
      "        F419       0.00      0.00      0.00      2012\n",
      "       G4733       0.00      0.00      0.00      1973\n",
      "         I10       0.00      0.00      0.00      2027\n",
      "       I2510       0.00      0.00      0.00      2016\n",
      "       I4891       0.00      0.00      0.00      1916\n",
      "      J45909       0.00      0.00      0.00      1954\n",
      "        K219       0.03      0.00      0.01      2024\n",
      "        N179       0.00      0.00      0.00      2006\n",
      "        Y929       0.00      0.00      0.00      2015\n",
      "         Z66       0.00      0.00      0.00      2020\n",
      "       Z7901       0.00      0.00      0.00      2066\n",
      "        Z794       0.00      0.00      0.00      2022\n",
      "      Z87891       0.00      0.00      0.00      1968\n",
      "\n",
      "    accuracy                           0.05     40000\n",
      "   macro avg       0.01      0.05      0.01     40000\n",
      "weighted avg       0.01      0.05      0.01     40000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/NLP_project/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/envs/NLP_project/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/envs/NLP_project/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Detect device\n",
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"cleaned_reduced_data_with_diseases.csv\")\n",
    "df = df[['clinical_notes', 'icd_code']].rename(columns={'clinical_notes': 'text', 'icd_code': 'label'})\n",
    "\n",
    "# Map ICD codes to numeric labels\n",
    "icd_to_id = {code: idx for idx, code in enumerate(df['label'].unique())}\n",
    "id_to_icd = {v: k for k, v in icd_to_id.items()}\n",
    "df['label'] = df['label'].map(icd_to_id)\n",
    "\n",
    "# Split into training and validation sets\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    df['text'], df['label'], test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\")\n",
    "\n",
    "# Create a PyTorch Dataset class\n",
    "class ClinicalNotesDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_len=128):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts.iloc[idx]\n",
    "        label = self.labels.iloc[idx]\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            max_length=self.max_len,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        return {\n",
    "            \"input_ids\": encoding[\"input_ids\"].squeeze(),\n",
    "            \"attention_mask\": encoding[\"attention_mask\"].squeeze(),\n",
    "            \"labels\": torch.tensor(label, dtype=torch.long),\n",
    "        }\n",
    "\n",
    "# Prepare datasets\n",
    "train_dataset = ClinicalNotesDataset(train_texts, train_labels, tokenizer)\n",
    "val_dataset = ClinicalNotesDataset(val_texts, val_labels, tokenizer)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16)\n",
    "\n",
    "# Load the default ClinicalBERT model for classification\n",
    "model_default_clinicalbert = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"emilyalsentzer/Bio_ClinicalBERT\", num_labels=len(icd_to_id)\n",
    ").to(device)\n",
    "\n",
    "# Define loss function for evaluation\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Validation loop with tqdm\n",
    "model_default_clinicalbert.eval()\n",
    "predictions, true_labels = [], []\n",
    "progress_bar = tqdm(val_loader, desc=\"Evaluating Default ClinicalBERT\", unit=\"batch\")\n",
    "with torch.no_grad():\n",
    "    for batch in progress_bar:\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        labels = batch[\"labels\"].to(device)\n",
    "\n",
    "        # Get model outputs\n",
    "        outputs = model_default_clinicalbert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "\n",
    "        # Store predictions and true labels\n",
    "        predictions.extend(torch.argmax(logits, dim=-1).cpu().numpy())\n",
    "        true_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# Calculate accuracy and other evaluation metrics\n",
    "accuracy = accuracy_score(true_labels, predictions)\n",
    "print(\"Validation Accuracy (default_clinicalbert):\", accuracy)\n",
    "print(\"Classification Report (default_clinicalbert):\")\n",
    "print(classification_report(true_labels, predictions, target_names=id_to_icd.values()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tuning & Evaluation of ClinicalBert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T03:54:33.984897Z",
     "iopub.status.busy": "2024-12-16T03:54:33.984238Z",
     "iopub.status.idle": "2024-12-16T07:00:25.871738Z",
     "shell.execute_reply": "2024-12-16T07:00:25.871369Z",
     "shell.execute_reply.started": "2024-12-16T03:54:33.984858Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at emilyalsentzer/Bio_ClinicalBERT and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/anaconda3/envs/NLP_project/lib/python3.12/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fine-Tuning ClinicalBERT Epoch 1/3: 100%|██████████| 10000/10000 [56:38<00:00,  2.94batch/s, loss=2.82] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss: 2.7857396632194518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-Tuning ClinicalBERT Epoch 2/3: 100%|██████████| 10000/10000 [54:09<00:00,  3.08batch/s, loss=2.73]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Loss: 2.6867960906267165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-Tuning ClinicalBERT Epoch 3/3: 100%|██████████| 10000/10000 [1:09:20<00:00,  2.40batch/s, loss=2.79]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Loss: 2.6148888517379762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Fine-Tuned ClinicalBERT: 100%|██████████| 2500/2500 [05:16<00:00,  7.91batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy (fine_tuned_clinicalbert): 0.169325\n",
      "Classification Report (fine_tuned_clinicalbert):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        D649       0.11      0.03      0.04      1996\n",
      "        E039       0.22      0.16      0.18      1986\n",
      "        E119       0.18      0.24      0.20      1933\n",
      "        E669       0.10      0.23      0.14      2069\n",
      "        E785       0.15      0.04      0.07      2017\n",
      "      F17210       0.21      0.24      0.23      1971\n",
      "        F329       0.16      0.07      0.09      2009\n",
      "        F419       0.20      0.12      0.15      2012\n",
      "       G4733       0.20      0.20      0.20      1973\n",
      "         I10       0.15      0.08      0.10      2027\n",
      "       I2510       0.16      0.23      0.19      2016\n",
      "       I4891       0.16      0.29      0.21      1916\n",
      "      J45909       0.23      0.19      0.21      1954\n",
      "        K219       0.15      0.04      0.07      2024\n",
      "        N179       0.13      0.09      0.11      2006\n",
      "        Y929       0.17      0.22      0.19      2015\n",
      "         Z66       0.17      0.27      0.21      2020\n",
      "       Z7901       0.19      0.29      0.23      2066\n",
      "        Z794       0.19      0.32      0.24      2022\n",
      "      Z87891       0.11      0.02      0.04      1968\n",
      "\n",
      "    accuracy                           0.17     40000\n",
      "   macro avg       0.17      0.17      0.16     40000\n",
      "weighted avg       0.17      0.17      0.16     40000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AdamW, get_scheduler\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Detect device\n",
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"cleaned_reduced_data_with_diseases.csv\")\n",
    "df = df[['clinical_notes', 'icd_code']].rename(columns={'clinical_notes': 'text', 'icd_code': 'label'})\n",
    "\n",
    "# Map ICD codes to numeric labels\n",
    "icd_to_id = {code: idx for idx, code in enumerate(df['label'].unique())}\n",
    "id_to_icd = {v: k for k, v in icd_to_id.items()}\n",
    "df['label'] = df['label'].map(icd_to_id)\n",
    "\n",
    "# Split into training and validation sets\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    df['text'], df['label'], test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\")\n",
    "\n",
    "# Create a PyTorch Dataset class\n",
    "class ClinicalNotesDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_len=128):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts.iloc[idx]\n",
    "        label = self.labels.iloc[idx]\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            max_length=self.max_len,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        return {\n",
    "            \"input_ids\": encoding[\"input_ids\"].squeeze(),\n",
    "            \"attention_mask\": encoding[\"attention_mask\"].squeeze(),\n",
    "            \"labels\": torch.tensor(label, dtype=torch.long),\n",
    "        }\n",
    "\n",
    "# Prepare datasets\n",
    "train_dataset = ClinicalNotesDataset(train_texts, train_labels, tokenizer)\n",
    "val_dataset = ClinicalNotesDataset(val_texts, val_labels, tokenizer)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16)\n",
    "\n",
    "# Load the ClinicalBERT model for fine-tuning\n",
    "model_finetuned_clinicalbert = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"emilyalsentzer/Bio_ClinicalBERT\", num_labels=len(icd_to_id)\n",
    ").to(device)\n",
    "\n",
    "# Define optimizer and scheduler\n",
    "optimizer = AdamW(model_finetuned_clinicalbert.parameters(), lr=2e-5)\n",
    "num_training_steps = len(train_loader) * 3  # 3 epochs\n",
    "lr_scheduler = get_scheduler(\"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=num_training_steps)\n",
    "\n",
    "# Fine-tuning loop with tqdm\n",
    "epochs = 3\n",
    "for epoch in range(epochs):\n",
    "    model_finetuned_clinicalbert.train()\n",
    "    total_loss = 0\n",
    "    progress_bar = tqdm(train_loader, desc=f\"Fine-Tuning ClinicalBERT Epoch {epoch + 1}/{epochs}\", unit=\"batch\")\n",
    "    for batch in progress_bar:\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        labels = batch[\"labels\"].to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model_finetuned_clinicalbert(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "\n",
    "        # Update progress bar\n",
    "        progress_bar.set_postfix({\"loss\": loss.item()})\n",
    "    print(f\"Epoch {epoch + 1} Loss: {total_loss / len(train_loader)}\")\n",
    "\n",
    "# Save the fine-tuned model\n",
    "model_finetuned_clinicalbert.save_pretrained(\"./fine_tuned_clinicalbert\")\n",
    "tokenizer.save_pretrained(\"./fine_tuned_clinicalbert\")\n",
    "\n",
    "# Evaluation loop with tqdm\n",
    "model_finetuned_clinicalbert.eval()\n",
    "predictions, true_labels = [], []\n",
    "progress_bar = tqdm(val_loader, desc=\"Evaluating Fine-Tuned ClinicalBERT\", unit=\"batch\")\n",
    "with torch.no_grad():\n",
    "    for batch in progress_bar:\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        labels = batch[\"labels\"].to(device)\n",
    "\n",
    "        # Get model outputs\n",
    "        outputs = model_finetuned_clinicalbert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "\n",
    "        # Store predictions and true labels\n",
    "        predictions.extend(torch.argmax(logits, dim=-1).cpu().numpy())\n",
    "        true_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# Calculate accuracy and other evaluation metrics\n",
    "accuracy = accuracy_score(true_labels, predictions)\n",
    "print(\"Validation Accuracy (fine_tuned_clinicalbert):\", accuracy)\n",
    "print(\"Classification Report (fine_tuned_clinicalbert):\")\n",
    "print(classification_report(true_labels, predictions, target_names=id_to_icd.values()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Consolidating \"icd_code\" from the same \"hadm_id\" into a single row for fine-tuning and evaluation of ClinicalBert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T13:37:34.356765Z",
     "iopub.status.busy": "2024-12-16T13:37:34.356044Z",
     "iopub.status.idle": "2024-12-16T13:37:40.976905Z",
     "shell.execute_reply": "2024-12-16T13:37:40.976663Z",
     "shell.execute_reply.started": "2024-12-16T13:37:34.356722Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    hadm_id                 icd_code  \\\n",
      "0  20000034             Z794, Z87891   \n",
      "1  20000094  E669, I2510, I4891, Z66   \n",
      "2  20000147               F329, Z794   \n",
      "3  20000239         D649, F329, Z794   \n",
      "4  20000254                     K219   \n",
      "\n",
      "                                      clinical_notes  \\\n",
      "0                        Relevant section not found.   \n",
      "1  Cardiogenic shock\\n \\nMajor Surgical or Invasi...   \n",
      "2  chest pain \\n \\nMajor Surgical or Invasive Pro...   \n",
      "3  Chest pain, abdominal pain\\n \\nMajor Surgical ...   \n",
      "4  abdominal pain\\n \\nMajor Surgical or Invasive ...   \n",
      "\n",
      "                                  extracted_diseases  \n",
      "0                                               None  \n",
      "1  transaminitis; somnolent; tachyarrhythmia; cat...  \n",
      "2  Hypercholesterolemia; chest pain; Depression; ...  \n",
      "3  vomit; depression; respiratory distress; tende...  \n",
      "4  hypoactive bowel; jaundice; nausea ,; tenderne...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"cleaned_reduced_data_with_diseases.csv\")\n",
    "\n",
    "# Consolidate ICD codes for each hadm_id\n",
    "df_consolidated = df.groupby(\"hadm_id\").agg({\n",
    "    \"icd_code\": lambda x: list(x),  # Combine all ICD codes into a list\n",
    "    \"clinical_notes\": \"first\",      # Keep the first occurrence of clinical_notes\n",
    "    \"extracted_diseases\": \"first\"   # Keep the first occurrence of diseases\n",
    "}).reset_index()\n",
    "\n",
    "# Optionally convert the list of ICD codes to a concatenated string (if required)\n",
    "df_consolidated[\"icd_code\"] = df_consolidated[\"icd_code\"].apply(lambda x: \", \".join(map(str, x)))\n",
    "\n",
    "# Save the consolidated DataFrame (optional)\n",
    "df_consolidated.to_csv(\"[consolidated_hadm_id]cleaned_reduced_data_with_diseases.csv\", index=False)\n",
    "\n",
    "# Display the consolidated dataset\n",
    "print(df_consolidated.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T13:38:01.030446Z",
     "iopub.status.busy": "2024-12-16T13:38:01.029844Z",
     "iopub.status.idle": "2024-12-16T13:38:01.075009Z",
     "shell.execute_reply": "2024-12-16T13:38:01.074603Z",
     "shell.execute_reply.started": "2024-12-16T13:38:01.030397Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 93192 entries, 0 to 93191\n",
      "Data columns (total 4 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   hadm_id             93192 non-null  int64 \n",
      " 1   icd_code            93192 non-null  object\n",
      " 2   clinical_notes      93192 non-null  object\n",
      " 3   extracted_diseases  85802 non-null  object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 2.8+ MB\n"
     ]
    }
   ],
   "source": [
    "df_consolidated.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T13:47:34.666997Z",
     "iopub.status.busy": "2024-12-16T13:47:34.666382Z",
     "iopub.status.idle": "2024-12-16T15:06:50.845896Z",
     "shell.execute_reply": "2024-12-16T15:06:50.845542Z",
     "shell.execute_reply.started": "2024-12-16T13:47:34.666954Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at emilyalsentzer/Bio_ClinicalBERT and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/anaconda3/envs/NLP_project/lib/python3.12/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fine-Tuning ClinicalBERT Epoch 1/3: 100%|██████████| 4660/4660 [25:35<00:00,  3.04batch/s, loss=0.266]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss: 0.31965600779447945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-Tuning ClinicalBERT Epoch 2/3: 100%|██████████| 4660/4660 [25:50<00:00,  3.01batch/s, loss=0.271]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Loss: 0.3011092764209524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-Tuning ClinicalBERT Epoch 3/3: 100%|██████████| 4660/4660 [25:53<00:00,  3.00batch/s, loss=0.329]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Loss: 0.29326456352556723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Fine-Tuned ClinicalBERT: 100%|██████████| 1165/1165 [01:52<00:00, 10.40batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy (fine_tuned_clinicalbert): 0.04892966360856269\n",
      "Classification Report (fine_tuned_clinicalbert):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        D649       0.00      0.00      0.00      1979\n",
      "        E039       0.64      0.21      0.32      1975\n",
      "        E119       0.51      0.19      0.27      1951\n",
      "        E669       0.59      0.06      0.10      2036\n",
      "        E785       0.00      0.00      0.00      2046\n",
      "      F17210       0.59      0.15      0.24      2037\n",
      "        F329       0.34      0.03      0.05      1993\n",
      "        F419       0.58      0.07      0.13      1946\n",
      "       G4733       0.71      0.23      0.34      1982\n",
      "         I10       0.00      0.00      0.00      2031\n",
      "       I2510       0.46      0.08      0.14      2034\n",
      "       I4891       0.52      0.38      0.44      1975\n",
      "      J45909       0.77      0.20      0.32      2005\n",
      "        K219       0.00      0.00      0.00      1957\n",
      "        N179       0.45      0.01      0.02      2002\n",
      "        Y929       0.52      0.04      0.08      2000\n",
      "         Z66       0.54      0.18      0.27      2017\n",
      "       Z7901       0.60      0.33      0.43      2032\n",
      "        Z794       0.57      0.29      0.38      1989\n",
      "      Z87891       0.00      0.00      0.00      1949\n",
      "\n",
      "   micro avg       0.58      0.12      0.20     39936\n",
      "   macro avg       0.42      0.12      0.18     39936\n",
      "weighted avg       0.42      0.12      0.18     39936\n",
      " samples avg       0.22      0.13      0.15     39936\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/opt/anaconda3/envs/NLP_project/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/envs/NLP_project/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.nn import BCEWithLogitsLoss\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AdamW, get_scheduler\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Detect device\n",
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Load the consolidated dataset\n",
    "df_consolidated = pd.read_csv(\"[consolidated_hadm_id]cleaned_reduced_data_with_diseases.csv\")\n",
    "\n",
    "# Step 1: Split ICD codes into lists\n",
    "df_consolidated[\"icd_code\"] = df_consolidated[\"icd_code\"].str.split(\", \")\n",
    "\n",
    "# Step 2: Multi-label binarization\n",
    "mlb = MultiLabelBinarizer()\n",
    "binary_labels = mlb.fit_transform(df_consolidated[\"icd_code\"])\n",
    "\n",
    "# Step 3: Train-test split\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    df_consolidated['clinical_notes'].reset_index(drop=True),  # Reset index for texts\n",
    "    binary_labels,  # Use binary_labels as NumPy array\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Step 4: Dataset class\n",
    "class ClinicalNotesDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_len=128):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts.iloc[idx]  # Access text using pandas indexing\n",
    "        label = torch.tensor(self.labels[idx], dtype=torch.float32)  # Access labels using NumPy indexing\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            max_length=self.max_len,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        return {\n",
    "            \"input_ids\": encoding[\"input_ids\"].squeeze(),\n",
    "            \"attention_mask\": encoding[\"attention_mask\"].squeeze(),\n",
    "            \"labels\": label,\n",
    "        }\n",
    "\n",
    "# Step 5: Tokenizer and dataset preparation\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\")\n",
    "\n",
    "train_dataset = ClinicalNotesDataset(train_texts, train_labels, tokenizer)\n",
    "val_dataset = ClinicalNotesDataset(val_texts, val_labels, tokenizer)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16)\n",
    "\n",
    "# Step 6: Load ClinicalBERT model\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"emilyalsentzer/Bio_ClinicalBERT\", num_labels=len(mlb.classes_)\n",
    ").to(device)\n",
    "\n",
    "# Step 7: Optimizer and scheduler\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "num_training_steps = len(train_loader) * 3  # 3 epochs\n",
    "lr_scheduler = get_scheduler(\"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=num_training_steps)\n",
    "\n",
    "# Step 8: Loss function\n",
    "criterion = BCEWithLogitsLoss()\n",
    "\n",
    "# Step 9: Training loop\n",
    "epochs = 3\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    progress_bar = tqdm(train_loader, desc=f\"Fine-Tuning ClinicalBERT Epoch {epoch + 1}/{epochs}\", unit=\"batch\")\n",
    "    for batch in progress_bar:\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        labels = batch[\"labels\"].to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "\n",
    "        # Handle output format\n",
    "        logits = outputs.logits if hasattr(outputs, \"logits\") else outputs\n",
    "\n",
    "        # Calculate loss\n",
    "        loss = criterion(logits, labels)\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "\n",
    "        # Update progress bar\n",
    "        progress_bar.set_postfix({\"loss\": loss.item()})\n",
    "    print(f\"Epoch {epoch + 1} Loss: {total_loss / len(train_loader)}\")\n",
    "\n",
    "# Step 10: Save the fine-tuned model\n",
    "model.save_pretrained(\"./fine_tuned_clinicalbert\")\n",
    "tokenizer.save_pretrained(\"./fine_tuned_clinicalbert\")\n",
    "\n",
    "# Step 11: Evaluation\n",
    "model.eval()\n",
    "predictions, true_labels = [], []\n",
    "progress_bar = tqdm(val_loader, desc=\"Evaluating Fine-Tuned ClinicalBERT\", unit=\"batch\")\n",
    "with torch.no_grad():\n",
    "    for batch in progress_bar:\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        labels = batch[\"labels\"].to(device)\n",
    "\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits if hasattr(outputs, \"logits\") else outputs\n",
    "        preds = torch.sigmoid(logits).cpu().numpy() > 0.5  # Threshold at 0.5\n",
    "\n",
    "        predictions.extend(preds)\n",
    "        true_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# Step 12: Metrics for multi-label classification\n",
    "accuracy = accuracy_score(true_labels, predictions)\n",
    "print(\"Validation Accuracy (fine_tuned_clinicalbert):\", accuracy)\n",
    "print(\"Classification Report (fine_tuned_clinicalbert):\")\n",
    "print(classification_report(true_labels, predictions, target_names=mlb.classes_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T15:20:08.657020Z",
     "iopub.status.busy": "2024-12-16T15:20:08.656212Z",
     "iopub.status.idle": "2024-12-16T15:20:09.131488Z",
     "shell.execute_reply": "2024-12-16T15:20:09.118339Z",
     "shell.execute_reply.started": "2024-12-16T15:20:08.656975Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Analyze class imbalance\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Flatten the list of ICD codes in the training set\n",
    "train_icd_counts = Counter([icd for codes in train_labels for icd, present in enumerate(codes) if present == 1])\n",
    "\n",
    "# Visualize the distribution\n",
    "labels, counts = zip(*train_icd_counts.items())\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(labels, counts)\n",
    "plt.title(\"ICD Code Distribution in Training Set\")\n",
    "plt.xlabel(\"ICD Code Index\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T15:22:46.876083Z",
     "iopub.status.busy": "2024-12-16T15:22:46.874465Z",
     "iopub.status.idle": "2024-12-16T15:22:55.945006Z",
     "shell.execute_reply": "2024-12-16T15:22:55.944720Z",
     "shell.execute_reply.started": "2024-12-16T15:22:46.876031Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clinical notes preprocessed.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def preprocess_notes(text):\n",
    "    # Remove special characters and extra spaces\n",
    "    text = re.sub(r'\\s+', ' ', text)  # Remove extra spaces\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove special characters\n",
    "    return text.strip()\n",
    "\n",
    "# Apply preprocessing to clinical notes\n",
    "df_consolidated['clinical_notes'] = df_consolidated['clinical_notes'].apply(preprocess_notes)\n",
    "print(\"Clinical notes preprocessed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T15:23:53.461791Z",
     "iopub.status.busy": "2024-12-16T15:23:53.461159Z",
     "iopub.status.idle": "2024-12-16T20:40:24.289602Z",
     "shell.execute_reply": "2024-12-16T20:40:24.288822Z",
     "shell.execute_reply.started": "2024-12-16T15:23:53.461750Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/NLP_project/lib/python3.12/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fine-Tuning ClinicalBERT Epoch 1/10: 100%|██████████| 4660/4660 [25:34<00:00,  3.04batch/s, loss=0.349]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss: 0.29205599710856894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-Tuning ClinicalBERT Epoch 2/10: 100%|██████████| 4660/4660 [24:40<00:00,  3.15batch/s, loss=0.231]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Loss: 0.28585160344263516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-Tuning ClinicalBERT Epoch 3/10: 100%|██████████| 4660/4660 [28:13<00:00,  2.75batch/s, loss=0.332]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Loss: 0.27838281857033653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-Tuning ClinicalBERT Epoch 4/10: 100%|██████████| 4660/4660 [35:07<00:00,  2.21batch/s, loss=0.222]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 Loss: 0.26979956957531587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-Tuning ClinicalBERT Epoch 5/10: 100%|██████████| 4660/4660 [33:47<00:00,  2.30batch/s, loss=0.318]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 Loss: 0.2609549741024879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-Tuning ClinicalBERT Epoch 6/10: 100%|██████████| 4660/4660 [33:39<00:00,  2.31batch/s, loss=0.245]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 Loss: 0.25134741251432846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-Tuning ClinicalBERT Epoch 7/10: 100%|██████████| 4660/4660 [33:51<00:00,  2.29batch/s, loss=0.207]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 Loss: 0.24105088054622192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-Tuning ClinicalBERT Epoch 8/10: 100%|██████████| 4660/4660 [35:11<00:00,  2.21batch/s, loss=0.141]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 Loss: 0.23084509592391392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-Tuning ClinicalBERT Epoch 9/10: 100%|██████████| 4660/4660 [32:06<00:00,  2.42batch/s, loss=0.224]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 Loss: 0.2201549998920235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-Tuning ClinicalBERT Epoch 10/10: 100%|██████████| 4660/4660 [34:18<00:00,  2.26batch/s, loss=0.173]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 Loss: 0.20929217975858455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 10  # Increased epochs\n",
    "optimizer = AdamW(model.parameters(), lr=1e-5)  # Smaller learning rate\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    progress_bar = tqdm(train_loader, desc=f\"Fine-Tuning ClinicalBERT Epoch {epoch + 1}/{epochs}\", unit=\"batch\")\n",
    "    for batch in progress_bar:\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        labels = batch[\"labels\"].to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "        loss = criterion(logits, labels)\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "\n",
    "        progress_bar.set_postfix({\"loss\": loss.item()})\n",
    "    print(f\"Epoch {epoch + 1} Loss: {total_loss / len(train_loader)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T21:42:21.972501Z",
     "iopub.status.busy": "2024-12-16T21:42:21.971764Z",
     "iopub.status.idle": "2024-12-16T21:44:11.435124Z",
     "shell.execute_reply": "2024-12-16T21:44:11.434853Z",
     "shell.execute_reply.started": "2024-12-16T21:42:21.972453Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.05665539996780943\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        D649       0.21      0.06      0.10      1979\n",
      "        E039       0.43      0.25      0.32      1975\n",
      "        E119       0.37      0.31      0.34      1951\n",
      "        E669       0.29      0.19      0.23      2036\n",
      "        E785       0.24      0.07      0.11      2046\n",
      "      F17210       0.35      0.30      0.32      2037\n",
      "        F329       0.29      0.13      0.18      1993\n",
      "        F419       0.33      0.17      0.23      1946\n",
      "       G4733       0.38      0.33      0.35      1982\n",
      "         I10       0.21      0.12      0.15      2031\n",
      "       I2510       0.37      0.24      0.29      2034\n",
      "       I4891       0.43      0.51      0.46      1975\n",
      "      J45909       0.43      0.28      0.34      2005\n",
      "        K219       0.26      0.07      0.11      1957\n",
      "        N179       0.23      0.20      0.22      2002\n",
      "        Y929       0.30      0.20      0.24      2000\n",
      "         Z66       0.43      0.28      0.34      2017\n",
      "       Z7901       0.47      0.35      0.41      2032\n",
      "        Z794       0.41      0.46      0.43      1989\n",
      "      Z87891       0.18      0.02      0.04      1949\n",
      "\n",
      "   micro avg       0.35      0.23      0.28     39936\n",
      "   macro avg       0.33      0.23      0.26     39936\n",
      "weighted avg       0.33      0.23      0.26     39936\n",
      " samples avg       0.29      0.24      0.24     39936\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/NLP_project/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.4  # Experiment with thresholds\n",
    "predictions, true_labels = [], []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch in val_loader:\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        labels = batch[\"labels\"].to(device)\n",
    "\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "        preds = (torch.sigmoid(logits) > threshold).cpu().numpy()\n",
    "        predictions.extend(preds)\n",
    "        true_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# Metrics for multi-label classification\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "print(\"Validation Accuracy:\", accuracy_score(true_labels, predictions))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(true_labels, predictions, target_names=mlb.classes_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wOYFsvPeaaCX",
    "outputId": "c425882f-23f9-4292-8635-ba7c8c77e9fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in the CSV file:\n",
      "Index(['subject_id_x', 'hadm_id', 'admittime', 'dischtime', 'deathtime',\n",
      "       'admission_type', 'admit_provider_id', 'admission_location',\n",
      "       'discharge_location', 'insurance', 'language', 'marital_status', 'race',\n",
      "       'edregtime', 'edouttime', 'hospital_expire_flag', 'subject_id_y',\n",
      "       'seq_num', 'icd_code', 'icd_version', 'note_id', 'subject_id',\n",
      "       'note_type', 'note_seq', 'charttime', 'storetime', 'text'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = '/Users/benjamintan/Downloads/mimic-iv-3.1/hosp/combined_hadm_id.csv'  # Replace with your CSV file path\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Display the column names\n",
    "print(\"Columns in the CSV file:\")\n",
    "print(df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NWyQA-j8aaCX",
    "outputId": "82491225-774b-41e5-9e74-83de2f6f3d3b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered CSV saved to: /Users/benjamintan/Downloads/mimic-iv-3.1/hosp/filtered_hadm_id.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = '/Users/benjamintan/Downloads/mimic-iv-3.1/hosp/combined_hadm_id.csv'  # Replace with your CSV file path\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Specify the columns of interest\n",
    "columns_of_interest = [\n",
    "    'hadm_id', 'admission_type', 'admit_provider_id', 'admission_location',\n",
    "    'marital_status', 'race', 'seq_num', 'icd_code', 'icd_version', 'note_id',\n",
    "    'subject_id', 'note_type', 'note_seq', 'text'\n",
    "]\n",
    "\n",
    "# Select only the columns of interest\n",
    "filtered_df = df[columns_of_interest]\n",
    "\n",
    "# Save the filtered DataFrame to a new CSV file\n",
    "output_file_path = '/Users/benjamintan/Downloads/mimic-iv-3.1/hosp/filtered_hadm_id.csv'  # Replace with your desired output file path\n",
    "filtered_df.to_csv(output_file_path, index=False)\n",
    "\n",
    "print(f\"Filtered CSV saved to: {output_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YQtbhINVaaCX",
    "outputId": "eee6a5b6-c6d5-4525-b625-9375d82e2aa5",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     \\nName:  ___             Unit No:   ___\\n \\nAdmission Date:  ___              Discharge Date:   ___\\n \\nDate of Birth:  ___             Sex:   F\\n \\nService: MEDICINE\\n \\nAllergies: \\nNo Known Allergies / Adverse Drug Reactions\\n \\nAttending: ___.\\n \\nChief Complaint:\\nfever, nausea/vomiting, flank pain\\n \\nMajor Surgical or Invasive Procedure:\\nnone \\n\\n \\nHistory of Present Illness:\\nHISTORY OF PRESENT ILLNESS:  \\nMs. ___ is a ___ year old ___ speaking lady with DM2 and \\nHTN who was evaluated in the ED ___, diagnosed with UTI and \\ntreated with macrobid, who returned with bilateral flank pain \\nL>R, fevers, chills, sweats, nausea, vomiting, headache, \\ndysuria. Denied neck stiffness. She was evaluated in ED \\ninitially with dizziness, headache, fever, found ot have a UTI \\nand discharged home w macrobid, which she took, but felt worse \\ntoday. She endorses minimal urine output that is dark.  \\nIn the ED, initial vs were: ___ pain 99.3 97 151/53 16 96% \\nyest. Today initial vitals were ___ pain 101.2 94 123/46 18 96% \\nRA. Today ED physical exam significant for bilateral \\ncostovertebral angle tenderness as well as mild suprapubic \\ntenderness, no meningismus clear lungs, normal heart exam. Labs \\nin ED sig for leukocytosis to 19.0 and a lactate of 3.0 ___s a bump in her creatinine from 1.2-1.3. Given the patient's \\nongoing symptoms rising leukocytosis as well as elevated lactate \\nand bilateral flank pain, she was given 1500 cc NS, 1 gram \\nceftriaxone, 1g acetaminophen for pyelonpehritis/fever, \\nunderwent renal u/s to evaluate for renal abscesses or \\nhydronephrosis (negative).  \\nVitals on Transfer: ___ pain 98.0 65 106/50 16 100%  \\n \\nOn the floor, vs were as below. She endorsed feeling somewhat \\nbetter but continued suprapubic discomfort and flank pain L>R. \\n\\n \\nPast Medical History:\\nType 2 diabetes  \\nAsthma  \\nHyperlipidemia  \\nHypertension  \\n\\n \\nSocial History:\\n___\\nFamily History:\\nShe has a sister deceased with endometrial cancer. No history of \\novarian, breast or colon cancer. No history of hypertension or \\ndiabetes in the family.  \\n\\n \\nPhysical Exam:\\nADMISSION EXAM: \\nVitals: tmax 101.2, tc 98.___ fs 207  \\nGeneral: Alert, oriented, no acute distress, lying in bed with \\nfamily at bedside  \\nHEENT: Sclera anicteric, MM dry  \\nNeck: supple, no meningismus, JVP not elevated  \\nLungs: Clear to auscultation bilaterally, no wheezes, rales, \\nronchi  \\nCV: Regular rate and rhythm, normal S1 + S2, no murmurs, rubs, \\ngallops  \\nAbdomen: soft, mild tenderness to deep palp @ suprapubic area, \\nnon-distended, bowel sounds present, no rebound tenderness, no \\norganomegaly  \\nBack: + CVA tenderness, L > R (mild on R)  \\nExt: Warm, well perfused, no edema  \\nSkin: moist, no rashes, no petechiae  \\nNeuro: speech fluent, linear, appropriate, no meningismus, \\noriented x3, moving all 4 extremities, did not assess gait.  \\n.\\nDISCHARGE EXAM: \\nPHYSICAL EXAM:  \\nGeneral: Alert, oriented, no acute distress, lying on bed \\nAbdomen: soft, non-tender, obese, bowel sounds present, no \\nrebound tenderness, no organomegaly  \\nBack: CVA tenderness resolved  \\nExt: Warm, well perfused, no edema  \\n\\n \\nPertinent Results:\\nADMISSION LABS: \\n___ 10:39PM   LACTATE-1.6\\n___ 09:00PM URINE  BLOOD-SM  NITRITE-NEG PROTEIN-TR \\nGLUCOSE-NEG KETONE-NEG BILIRUBIN-NEG UROBILNGN-NEG PH-5.0 \\nLEUK-LG\\n___ 09:00PM URINE  RBC-21* WBC-34* BACTERIA-FEW YEAST-NONE \\nEPI-2 TRANS EPI-<1\\n___ 07:27PM   LACTATE-3.0*\\n___ 07:17PM   GLUCOSE-210* UREA N-21* CREAT-1.3* \\nSODIUM-130* POTASSIUM-4.0 CHLORIDE-94* TOTAL CO2-22 ANION GAP-18\\n___ 07:17PM   WBC-19.2* RBC-3.65* HGB-11.0* HCT-31.1* \\nMCV-85 MCH-30.1 MCHC-35.4* RDW-12.6\\n___ 07:17PM   NEUTS-84.8* LYMPHS-10.1* MONOS-4.4 EOS-0.4 \\nBASOS-0.3\\n___ 07:17PM   PLT COUNT-204\\n.\\nRELEVANT LABS: \\n.\\n___ blood cultures: ___ bottles: \\n___ 7:17 pm BLOOD CULTURE\\n\\n                            **FINAL REPORT ___\\n\\n   Blood Culture, Routine (Final ___: \\n      ESCHERICHIA COLI.    FINAL SENSITIVITIES. \\n         Cefazolin interpretative criteria are based on a dosage \\nregimen of\\n         2g every 8h. \\n\\n                              SENSITIVITIES: MIC expressed in \\nMCG/ML\\n                      \\n_________________________________________________________\\n                             ESCHERICHIA COLI\\n                             |   \\nAMPICILLIN------------     4 S\\nAMPICILLIN/SULBACTAM--     4 S\\nCEFAZOLIN-------------   <=4 S\\nCEFEPIME--------------   <=1 S\\nCEFTAZIDIME-----------   <=1 S\\nCEFTRIAXONE-----------   <=1 S\\nCIPROFLOXACIN---------<=0.25 S\\nGENTAMICIN------------   <=1 S\\nMEROPENEM-------------<=0.25 S\\nPIPERACILLIN/TAZO-----   <=4 S\\nTOBRAMYCIN------------   <=1 S\\nTRIMETHOPRIM/SULFA----   <=1 S\\n\\n   Anaerobic Bottle Gram Stain (Final ___: \\n      GRAM NEGATIVE ROD(S). \\n      Reported to and read back by ___. ___ ___ 08:13AM. \\n\\n   Aerobic Bottle Gram Stain (Final ___:    GRAM NEGATIVE \\nROD(S). \\n\\n.\\n.\\nsubsequent blood cultures negative.\\n.\\n.\\n\\n                        \\n   URINE CULTURE (Final ___: \\n      MIXED BACTERIAL FLORA ( >= 3 COLONY TYPES), CONSISTENT \\nWITH SKIN\\n      AND/OR GENITAL CONTAMINATION. \\n.\\nDISCHARGE LABS: \\n.\\n___ 10:50AM BLOOD WBC-6.1 RBC-2.82* Hgb-8.3* Hct-24.4* \\nMCV-87 MCH-29.5 MCHC-34.1 RDW-12.3 Plt ___\\n___ 10:50AM BLOOD Plt ___\\n___ 07:15AM BLOOD Glucose-177* UreaN-14 Creat-0.9 Na-138 \\nK-3.9 Cl-102 HCO3-26 AnGap-14\\n___ 10:50AM BLOOD LD(LDH)-125 TotBili-0.4\\n___ 10:50AM BLOOD Iron-21*\\n___ 07:15AM BLOOD Calcium-8.9 Phos-2.7 Mg-1.7\\n___ 10:50AM BLOOD calTIBC-215* Hapto-224* Ferritn-333* \\nTRF-165*\\n \\nBrief Hospital Course:\\n___ was admitted on ___ for fevers, flank pain, \\nnausea/vomiting and headache. She had been admitted ___ for \\nurinary tract infection and discharged on nitrofurantoin. She \\nrepresented on ___, found to be febrile, with urinalysis \\nconsistent with infection, and was started on IV ceftriaxone. \\nRenal ultrasound was preformed, showing only a 8mm simple cyst. \\nSubsequent blood cultures showed GNR. \\n.\\nACUTE ISSUES: \\n.\\n# Pyelonephritis and Sepsis: Fever, dysuria, flank pain. \\ntreating initially w/ iv ceftriaxone. Renal u/s w/o e/o abscess \\nor stone as nidus. Patient was started on IV ceftriaxone, and \\ntransitioned to PO cipro\\nplan ___: Likely in setting of volume depletion given insensible \\nlosses (fever), vomiting, poor PO intake, as evidence by \\nelevated lactate and creatinine.  \\n- Cr 1.3 on admission --> .9 on discharged, resolved with IV \\nfluids\\n.\\nAnemia: requires outpatient evaluation.  Iron studies and lysis \\nlabs above. \\n.\\nCHRONIC ISSUES:\\n.\\n# Type 2 DM: Given acute infection, held glipizide and \\nmetformin.  \\n- insulin humalgos sliding scale  \\n- qid fingersticks  \\n- restarted on metformin, glipizide on discharge. \\n. \\n# Hyponatremia: Improved with hydration.\\n.\\n# Asthma: asymptomatic, not wheezing, monitor.  \\n.\\n# Hyperlipidemia: Continue statin, aspirin  \\n.\\n# Hypertension: held indapamide during stay for low-normal BPs, \\ndid not restart indapamide, to be restarted at discretion of PCP\\n.\\nFollow-up: \\n.\\nTo follow up with PCP to ensure resolution of symptoms as well \\nas to follow up anemia. \\n.\\nTo follow up with renal as scheduled prior to this inpatient \\nstay.\\n\\n \\nMedications on Admission:\\nThe Preadmission Medication list is accurate and complete.\\n1. Nitrofurantoin Monohyd (MacroBID) 100 mg PO Q12H \\n2. Aspirin 81 mg PO DAILY \\n3. Simvastatin 40 mg PO HS \\n4. Lisinopril 20 mg PO DAILY \\nplease hold for SBP<100, HR<60 \\n5. GlipiZIDE 5 mg PO DAILY \\n6. MetFORMIN (Glucophage) 1000 mg PO BID \\n7. Indapamide 1.25 mg PO DAILY \\nplease hold for SBP<100 \\n\\n \\nDischarge Medications:\\n1. Aspirin 81 mg PO DAILY \\n2. Simvastatin 40 mg PO HS \\n3. Ciprofloxacin HCl 500 mg PO Q12H \\nRX *ciprofloxacin 500 mg 1 tablet(s) by mouth twice a day Disp \\n#*23 Tablet Refills:*0\\n4. Acetaminophen ___ mg PO Q6H:PRN pain,fever, headache \\nRX *acetaminophen 500 mg 1 tablet(s) by mouth q6hrs Disp #*60 \\nTablet Refills:*0\\n5. GlipiZIDE 5 mg PO DAILY \\n6. Lisinopril 20 mg PO DAILY \\n7. MetFORMIN (Glucophage) 1000 mg PO BID \\n\\n \\nDischarge Disposition:\\nHome\\n \\nDischarge Diagnosis:\\nPrimary Diagnosis:\\n# Sepsis, secondary to pyelonephritis\\n\\nSecondary Diagnosis: \\n# Diabetes Type II\\n# Hypertension\\n# Hyperlipidemia\\n# Asthma\\n\\n \\nDischarge Condition:\\nMental Status: Clear and coherent.\\nLevel of Consciousness: Alert and interactive.\\nActivity Status: Ambulatory - Independent.\\n\\n \\nDischarge Instructions:\\nIt was a pleasure taking part in your care at ___ \\n___.\\n\\n___ were admitted for an infection in your blood and in your \\nkidneys, after recently being diagnosed and treated for a \\nurinary tract infection. Your kidney and blood infection were \\ntreated with IV antibiotics. ___ also had temporary kidney \\ninjury resulting from dehydration, which improved with \\nintravenous fluids. An ultrasound was preformed to look at your \\nkidneys, and everything looked normal. \\n\\n___ did not have a fever on the day of discharge. PLease buy a \\nthermometer for home. ___ should take your temperature several \\ntimes a day for the next few days. If your temperature is \\ngreater than 102 degrees, ___ should return to the ED.\\n\\n___ are discharged on ciprofloxacin 500mg twice a day for 14 \\ndays, to be completed on ___.\\n\\n___ should follow up with your PCP, ___ week\\n\\n___ should follow up your kidney doctor on ___ as planned. \\n \\n \\nFollowup Instructions:\\n___\\n\n",
       "1     \\nName:  ___             Unit No:   ___\\n \\nAdmission Date:  ___              Discharge Date:   ___\\n \\nDate of Birth:  ___             Sex:   F\\n \\nService: MEDICINE\\n \\nAllergies: \\nNo Known Allergies / Adverse Drug Reactions\\n \\nAttending: ___.\\n \\nChief Complaint:\\nfever, nausea/vomiting, flank pain\\n \\nMajor Surgical or Invasive Procedure:\\nnone \\n\\n \\nHistory of Present Illness:\\nHISTORY OF PRESENT ILLNESS:  \\nMs. ___ is a ___ year old ___ speaking lady with DM2 and \\nHTN who was evaluated in the ED ___, diagnosed with UTI and \\ntreated with macrobid, who returned with bilateral flank pain \\nL>R, fevers, chills, sweats, nausea, vomiting, headache, \\ndysuria. Denied neck stiffness. She was evaluated in ED \\ninitially with dizziness, headache, fever, found ot have a UTI \\nand discharged home w macrobid, which she took, but felt worse \\ntoday. She endorses minimal urine output that is dark.  \\nIn the ED, initial vs were: ___ pain 99.3 97 151/53 16 96% \\nyest. Today initial vitals were ___ pain 101.2 94 123/46 18 96% \\nRA. Today ED physical exam significant for bilateral \\ncostovertebral angle tenderness as well as mild suprapubic \\ntenderness, no meningismus clear lungs, normal heart exam. Labs \\nin ED sig for leukocytosis to 19.0 and a lactate of 3.0 ___s a bump in her creatinine from 1.2-1.3. Given the patient's \\nongoing symptoms rising leukocytosis as well as elevated lactate \\nand bilateral flank pain, she was given 1500 cc NS, 1 gram \\nceftriaxone, 1g acetaminophen for pyelonpehritis/fever, \\nunderwent renal u/s to evaluate for renal abscesses or \\nhydronephrosis (negative).  \\nVitals on Transfer: ___ pain 98.0 65 106/50 16 100%  \\n \\nOn the floor, vs were as below. She endorsed feeling somewhat \\nbetter but continued suprapubic discomfort and flank pain L>R. \\n\\n \\nPast Medical History:\\nType 2 diabetes  \\nAsthma  \\nHyperlipidemia  \\nHypertension  \\n\\n \\nSocial History:\\n___\\nFamily History:\\nShe has a sister deceased with endometrial cancer. No history of \\novarian, breast or colon cancer. No history of hypertension or \\ndiabetes in the family.  \\n\\n \\nPhysical Exam:\\nADMISSION EXAM: \\nVitals: tmax 101.2, tc 98.___ fs 207  \\nGeneral: Alert, oriented, no acute distress, lying in bed with \\nfamily at bedside  \\nHEENT: Sclera anicteric, MM dry  \\nNeck: supple, no meningismus, JVP not elevated  \\nLungs: Clear to auscultation bilaterally, no wheezes, rales, \\nronchi  \\nCV: Regular rate and rhythm, normal S1 + S2, no murmurs, rubs, \\ngallops  \\nAbdomen: soft, mild tenderness to deep palp @ suprapubic area, \\nnon-distended, bowel sounds present, no rebound tenderness, no \\norganomegaly  \\nBack: + CVA tenderness, L > R (mild on R)  \\nExt: Warm, well perfused, no edema  \\nSkin: moist, no rashes, no petechiae  \\nNeuro: speech fluent, linear, appropriate, no meningismus, \\noriented x3, moving all 4 extremities, did not assess gait.  \\n.\\nDISCHARGE EXAM: \\nPHYSICAL EXAM:  \\nGeneral: Alert, oriented, no acute distress, lying on bed \\nAbdomen: soft, non-tender, obese, bowel sounds present, no \\nrebound tenderness, no organomegaly  \\nBack: CVA tenderness resolved  \\nExt: Warm, well perfused, no edema  \\n\\n \\nPertinent Results:\\nADMISSION LABS: \\n___ 10:39PM   LACTATE-1.6\\n___ 09:00PM URINE  BLOOD-SM  NITRITE-NEG PROTEIN-TR \\nGLUCOSE-NEG KETONE-NEG BILIRUBIN-NEG UROBILNGN-NEG PH-5.0 \\nLEUK-LG\\n___ 09:00PM URINE  RBC-21* WBC-34* BACTERIA-FEW YEAST-NONE \\nEPI-2 TRANS EPI-<1\\n___ 07:27PM   LACTATE-3.0*\\n___ 07:17PM   GLUCOSE-210* UREA N-21* CREAT-1.3* \\nSODIUM-130* POTASSIUM-4.0 CHLORIDE-94* TOTAL CO2-22 ANION GAP-18\\n___ 07:17PM   WBC-19.2* RBC-3.65* HGB-11.0* HCT-31.1* \\nMCV-85 MCH-30.1 MCHC-35.4* RDW-12.6\\n___ 07:17PM   NEUTS-84.8* LYMPHS-10.1* MONOS-4.4 EOS-0.4 \\nBASOS-0.3\\n___ 07:17PM   PLT COUNT-204\\n.\\nRELEVANT LABS: \\n.\\n___ blood cultures: ___ bottles: \\n___ 7:17 pm BLOOD CULTURE\\n\\n                            **FINAL REPORT ___\\n\\n   Blood Culture, Routine (Final ___: \\n      ESCHERICHIA COLI.    FINAL SENSITIVITIES. \\n         Cefazolin interpretative criteria are based on a dosage \\nregimen of\\n         2g every 8h. \\n\\n                              SENSITIVITIES: MIC expressed in \\nMCG/ML\\n                      \\n_________________________________________________________\\n                             ESCHERICHIA COLI\\n                             |   \\nAMPICILLIN------------     4 S\\nAMPICILLIN/SULBACTAM--     4 S\\nCEFAZOLIN-------------   <=4 S\\nCEFEPIME--------------   <=1 S\\nCEFTAZIDIME-----------   <=1 S\\nCEFTRIAXONE-----------   <=1 S\\nCIPROFLOXACIN---------<=0.25 S\\nGENTAMICIN------------   <=1 S\\nMEROPENEM-------------<=0.25 S\\nPIPERACILLIN/TAZO-----   <=4 S\\nTOBRAMYCIN------------   <=1 S\\nTRIMETHOPRIM/SULFA----   <=1 S\\n\\n   Anaerobic Bottle Gram Stain (Final ___: \\n      GRAM NEGATIVE ROD(S). \\n      Reported to and read back by ___. ___ ___ 08:13AM. \\n\\n   Aerobic Bottle Gram Stain (Final ___:    GRAM NEGATIVE \\nROD(S). \\n\\n.\\n.\\nsubsequent blood cultures negative.\\n.\\n.\\n\\n                        \\n   URINE CULTURE (Final ___: \\n      MIXED BACTERIAL FLORA ( >= 3 COLONY TYPES), CONSISTENT \\nWITH SKIN\\n      AND/OR GENITAL CONTAMINATION. \\n.\\nDISCHARGE LABS: \\n.\\n___ 10:50AM BLOOD WBC-6.1 RBC-2.82* Hgb-8.3* Hct-24.4* \\nMCV-87 MCH-29.5 MCHC-34.1 RDW-12.3 Plt ___\\n___ 10:50AM BLOOD Plt ___\\n___ 07:15AM BLOOD Glucose-177* UreaN-14 Creat-0.9 Na-138 \\nK-3.9 Cl-102 HCO3-26 AnGap-14\\n___ 10:50AM BLOOD LD(LDH)-125 TotBili-0.4\\n___ 10:50AM BLOOD Iron-21*\\n___ 07:15AM BLOOD Calcium-8.9 Phos-2.7 Mg-1.7\\n___ 10:50AM BLOOD calTIBC-215* Hapto-224* Ferritn-333* \\nTRF-165*\\n \\nBrief Hospital Course:\\n___ was admitted on ___ for fevers, flank pain, \\nnausea/vomiting and headache. She had been admitted ___ for \\nurinary tract infection and discharged on nitrofurantoin. She \\nrepresented on ___, found to be febrile, with urinalysis \\nconsistent with infection, and was started on IV ceftriaxone. \\nRenal ultrasound was preformed, showing only a 8mm simple cyst. \\nSubsequent blood cultures showed GNR. \\n.\\nACUTE ISSUES: \\n.\\n# Pyelonephritis and Sepsis: Fever, dysuria, flank pain. \\ntreating initially w/ iv ceftriaxone. Renal u/s w/o e/o abscess \\nor stone as nidus. Patient was started on IV ceftriaxone, and \\ntransitioned to PO cipro\\nplan ___: Likely in setting of volume depletion given insensible \\nlosses (fever), vomiting, poor PO intake, as evidence by \\nelevated lactate and creatinine.  \\n- Cr 1.3 on admission --> .9 on discharged, resolved with IV \\nfluids\\n.\\nAnemia: requires outpatient evaluation.  Iron studies and lysis \\nlabs above. \\n.\\nCHRONIC ISSUES:\\n.\\n# Type 2 DM: Given acute infection, held glipizide and \\nmetformin.  \\n- insulin humalgos sliding scale  \\n- qid fingersticks  \\n- restarted on metformin, glipizide on discharge. \\n. \\n# Hyponatremia: Improved with hydration.\\n.\\n# Asthma: asymptomatic, not wheezing, monitor.  \\n.\\n# Hyperlipidemia: Continue statin, aspirin  \\n.\\n# Hypertension: held indapamide during stay for low-normal BPs, \\ndid not restart indapamide, to be restarted at discretion of PCP\\n.\\nFollow-up: \\n.\\nTo follow up with PCP to ensure resolution of symptoms as well \\nas to follow up anemia. \\n.\\nTo follow up with renal as scheduled prior to this inpatient \\nstay.\\n\\n \\nMedications on Admission:\\nThe Preadmission Medication list is accurate and complete.\\n1. Nitrofurantoin Monohyd (MacroBID) 100 mg PO Q12H \\n2. Aspirin 81 mg PO DAILY \\n3. Simvastatin 40 mg PO HS \\n4. Lisinopril 20 mg PO DAILY \\nplease hold for SBP<100, HR<60 \\n5. GlipiZIDE 5 mg PO DAILY \\n6. MetFORMIN (Glucophage) 1000 mg PO BID \\n7. Indapamide 1.25 mg PO DAILY \\nplease hold for SBP<100 \\n\\n \\nDischarge Medications:\\n1. Aspirin 81 mg PO DAILY \\n2. Simvastatin 40 mg PO HS \\n3. Ciprofloxacin HCl 500 mg PO Q12H \\nRX *ciprofloxacin 500 mg 1 tablet(s) by mouth twice a day Disp \\n#*23 Tablet Refills:*0\\n4. Acetaminophen ___ mg PO Q6H:PRN pain,fever, headache \\nRX *acetaminophen 500 mg 1 tablet(s) by mouth q6hrs Disp #*60 \\nTablet Refills:*0\\n5. GlipiZIDE 5 mg PO DAILY \\n6. Lisinopril 20 mg PO DAILY \\n7. MetFORMIN (Glucophage) 1000 mg PO BID \\n\\n \\nDischarge Disposition:\\nHome\\n \\nDischarge Diagnosis:\\nPrimary Diagnosis:\\n# Sepsis, secondary to pyelonephritis\\n\\nSecondary Diagnosis: \\n# Diabetes Type II\\n# Hypertension\\n# Hyperlipidemia\\n# Asthma\\n\\n \\nDischarge Condition:\\nMental Status: Clear and coherent.\\nLevel of Consciousness: Alert and interactive.\\nActivity Status: Ambulatory - Independent.\\n\\n \\nDischarge Instructions:\\nIt was a pleasure taking part in your care at ___ \\n___.\\n\\n___ were admitted for an infection in your blood and in your \\nkidneys, after recently being diagnosed and treated for a \\nurinary tract infection. Your kidney and blood infection were \\ntreated with IV antibiotics. ___ also had temporary kidney \\ninjury resulting from dehydration, which improved with \\nintravenous fluids. An ultrasound was preformed to look at your \\nkidneys, and everything looked normal. \\n\\n___ did not have a fever on the day of discharge. PLease buy a \\nthermometer for home. ___ should take your temperature several \\ntimes a day for the next few days. If your temperature is \\ngreater than 102 degrees, ___ should return to the ED.\\n\\n___ are discharged on ciprofloxacin 500mg twice a day for 14 \\ndays, to be completed on ___.\\n\\n___ should follow up with your PCP, ___ week\\n\\n___ should follow up your kidney doctor on ___ as planned. \\n \\n \\nFollowup Instructions:\\n___\\n\n",
       "2     \\nName:  ___             Unit No:   ___\\n \\nAdmission Date:  ___              Discharge Date:   ___\\n \\nDate of Birth:  ___             Sex:   F\\n \\nService: MEDICINE\\n \\nAllergies: \\nNo Known Allergies / Adverse Drug Reactions\\n \\nAttending: ___.\\n \\nChief Complaint:\\nfever, nausea/vomiting, flank pain\\n \\nMajor Surgical or Invasive Procedure:\\nnone \\n\\n \\nHistory of Present Illness:\\nHISTORY OF PRESENT ILLNESS:  \\nMs. ___ is a ___ year old ___ speaking lady with DM2 and \\nHTN who was evaluated in the ED ___, diagnosed with UTI and \\ntreated with macrobid, who returned with bilateral flank pain \\nL>R, fevers, chills, sweats, nausea, vomiting, headache, \\ndysuria. Denied neck stiffness. She was evaluated in ED \\ninitially with dizziness, headache, fever, found ot have a UTI \\nand discharged home w macrobid, which she took, but felt worse \\ntoday. She endorses minimal urine output that is dark.  \\nIn the ED, initial vs were: ___ pain 99.3 97 151/53 16 96% \\nyest. Today initial vitals were ___ pain 101.2 94 123/46 18 96% \\nRA. Today ED physical exam significant for bilateral \\ncostovertebral angle tenderness as well as mild suprapubic \\ntenderness, no meningismus clear lungs, normal heart exam. Labs \\nin ED sig for leukocytosis to 19.0 and a lactate of 3.0 ___s a bump in her creatinine from 1.2-1.3. Given the patient's \\nongoing symptoms rising leukocytosis as well as elevated lactate \\nand bilateral flank pain, she was given 1500 cc NS, 1 gram \\nceftriaxone, 1g acetaminophen for pyelonpehritis/fever, \\nunderwent renal u/s to evaluate for renal abscesses or \\nhydronephrosis (negative).  \\nVitals on Transfer: ___ pain 98.0 65 106/50 16 100%  \\n \\nOn the floor, vs were as below. She endorsed feeling somewhat \\nbetter but continued suprapubic discomfort and flank pain L>R. \\n\\n \\nPast Medical History:\\nType 2 diabetes  \\nAsthma  \\nHyperlipidemia  \\nHypertension  \\n\\n \\nSocial History:\\n___\\nFamily History:\\nShe has a sister deceased with endometrial cancer. No history of \\novarian, breast or colon cancer. No history of hypertension or \\ndiabetes in the family.  \\n\\n \\nPhysical Exam:\\nADMISSION EXAM: \\nVitals: tmax 101.2, tc 98.___ fs 207  \\nGeneral: Alert, oriented, no acute distress, lying in bed with \\nfamily at bedside  \\nHEENT: Sclera anicteric, MM dry  \\nNeck: supple, no meningismus, JVP not elevated  \\nLungs: Clear to auscultation bilaterally, no wheezes, rales, \\nronchi  \\nCV: Regular rate and rhythm, normal S1 + S2, no murmurs, rubs, \\ngallops  \\nAbdomen: soft, mild tenderness to deep palp @ suprapubic area, \\nnon-distended, bowel sounds present, no rebound tenderness, no \\norganomegaly  \\nBack: + CVA tenderness, L > R (mild on R)  \\nExt: Warm, well perfused, no edema  \\nSkin: moist, no rashes, no petechiae  \\nNeuro: speech fluent, linear, appropriate, no meningismus, \\noriented x3, moving all 4 extremities, did not assess gait.  \\n.\\nDISCHARGE EXAM: \\nPHYSICAL EXAM:  \\nGeneral: Alert, oriented, no acute distress, lying on bed \\nAbdomen: soft, non-tender, obese, bowel sounds present, no \\nrebound tenderness, no organomegaly  \\nBack: CVA tenderness resolved  \\nExt: Warm, well perfused, no edema  \\n\\n \\nPertinent Results:\\nADMISSION LABS: \\n___ 10:39PM   LACTATE-1.6\\n___ 09:00PM URINE  BLOOD-SM  NITRITE-NEG PROTEIN-TR \\nGLUCOSE-NEG KETONE-NEG BILIRUBIN-NEG UROBILNGN-NEG PH-5.0 \\nLEUK-LG\\n___ 09:00PM URINE  RBC-21* WBC-34* BACTERIA-FEW YEAST-NONE \\nEPI-2 TRANS EPI-<1\\n___ 07:27PM   LACTATE-3.0*\\n___ 07:17PM   GLUCOSE-210* UREA N-21* CREAT-1.3* \\nSODIUM-130* POTASSIUM-4.0 CHLORIDE-94* TOTAL CO2-22 ANION GAP-18\\n___ 07:17PM   WBC-19.2* RBC-3.65* HGB-11.0* HCT-31.1* \\nMCV-85 MCH-30.1 MCHC-35.4* RDW-12.6\\n___ 07:17PM   NEUTS-84.8* LYMPHS-10.1* MONOS-4.4 EOS-0.4 \\nBASOS-0.3\\n___ 07:17PM   PLT COUNT-204\\n.\\nRELEVANT LABS: \\n.\\n___ blood cultures: ___ bottles: \\n___ 7:17 pm BLOOD CULTURE\\n\\n                            **FINAL REPORT ___\\n\\n   Blood Culture, Routine (Final ___: \\n      ESCHERICHIA COLI.    FINAL SENSITIVITIES. \\n         Cefazolin interpretative criteria are based on a dosage \\nregimen of\\n         2g every 8h. \\n\\n                              SENSITIVITIES: MIC expressed in \\nMCG/ML\\n                      \\n_________________________________________________________\\n                             ESCHERICHIA COLI\\n                             |   \\nAMPICILLIN------------     4 S\\nAMPICILLIN/SULBACTAM--     4 S\\nCEFAZOLIN-------------   <=4 S\\nCEFEPIME--------------   <=1 S\\nCEFTAZIDIME-----------   <=1 S\\nCEFTRIAXONE-----------   <=1 S\\nCIPROFLOXACIN---------<=0.25 S\\nGENTAMICIN------------   <=1 S\\nMEROPENEM-------------<=0.25 S\\nPIPERACILLIN/TAZO-----   <=4 S\\nTOBRAMYCIN------------   <=1 S\\nTRIMETHOPRIM/SULFA----   <=1 S\\n\\n   Anaerobic Bottle Gram Stain (Final ___: \\n      GRAM NEGATIVE ROD(S). \\n      Reported to and read back by ___. ___ ___ 08:13AM. \\n\\n   Aerobic Bottle Gram Stain (Final ___:    GRAM NEGATIVE \\nROD(S). \\n\\n.\\n.\\nsubsequent blood cultures negative.\\n.\\n.\\n\\n                        \\n   URINE CULTURE (Final ___: \\n      MIXED BACTERIAL FLORA ( >= 3 COLONY TYPES), CONSISTENT \\nWITH SKIN\\n      AND/OR GENITAL CONTAMINATION. \\n.\\nDISCHARGE LABS: \\n.\\n___ 10:50AM BLOOD WBC-6.1 RBC-2.82* Hgb-8.3* Hct-24.4* \\nMCV-87 MCH-29.5 MCHC-34.1 RDW-12.3 Plt ___\\n___ 10:50AM BLOOD Plt ___\\n___ 07:15AM BLOOD Glucose-177* UreaN-14 Creat-0.9 Na-138 \\nK-3.9 Cl-102 HCO3-26 AnGap-14\\n___ 10:50AM BLOOD LD(LDH)-125 TotBili-0.4\\n___ 10:50AM BLOOD Iron-21*\\n___ 07:15AM BLOOD Calcium-8.9 Phos-2.7 Mg-1.7\\n___ 10:50AM BLOOD calTIBC-215* Hapto-224* Ferritn-333* \\nTRF-165*\\n \\nBrief Hospital Course:\\n___ was admitted on ___ for fevers, flank pain, \\nnausea/vomiting and headache. She had been admitted ___ for \\nurinary tract infection and discharged on nitrofurantoin. She \\nrepresented on ___, found to be febrile, with urinalysis \\nconsistent with infection, and was started on IV ceftriaxone. \\nRenal ultrasound was preformed, showing only a 8mm simple cyst. \\nSubsequent blood cultures showed GNR. \\n.\\nACUTE ISSUES: \\n.\\n# Pyelonephritis and Sepsis: Fever, dysuria, flank pain. \\ntreating initially w/ iv ceftriaxone. Renal u/s w/o e/o abscess \\nor stone as nidus. Patient was started on IV ceftriaxone, and \\ntransitioned to PO cipro\\nplan ___: Likely in setting of volume depletion given insensible \\nlosses (fever), vomiting, poor PO intake, as evidence by \\nelevated lactate and creatinine.  \\n- Cr 1.3 on admission --> .9 on discharged, resolved with IV \\nfluids\\n.\\nAnemia: requires outpatient evaluation.  Iron studies and lysis \\nlabs above. \\n.\\nCHRONIC ISSUES:\\n.\\n# Type 2 DM: Given acute infection, held glipizide and \\nmetformin.  \\n- insulin humalgos sliding scale  \\n- qid fingersticks  \\n- restarted on metformin, glipizide on discharge. \\n. \\n# Hyponatremia: Improved with hydration.\\n.\\n# Asthma: asymptomatic, not wheezing, monitor.  \\n.\\n# Hyperlipidemia: Continue statin, aspirin  \\n.\\n# Hypertension: held indapamide during stay for low-normal BPs, \\ndid not restart indapamide, to be restarted at discretion of PCP\\n.\\nFollow-up: \\n.\\nTo follow up with PCP to ensure resolution of symptoms as well \\nas to follow up anemia. \\n.\\nTo follow up with renal as scheduled prior to this inpatient \\nstay.\\n\\n \\nMedications on Admission:\\nThe Preadmission Medication list is accurate and complete.\\n1. Nitrofurantoin Monohyd (MacroBID) 100 mg PO Q12H \\n2. Aspirin 81 mg PO DAILY \\n3. Simvastatin 40 mg PO HS \\n4. Lisinopril 20 mg PO DAILY \\nplease hold for SBP<100, HR<60 \\n5. GlipiZIDE 5 mg PO DAILY \\n6. MetFORMIN (Glucophage) 1000 mg PO BID \\n7. Indapamide 1.25 mg PO DAILY \\nplease hold for SBP<100 \\n\\n \\nDischarge Medications:\\n1. Aspirin 81 mg PO DAILY \\n2. Simvastatin 40 mg PO HS \\n3. Ciprofloxacin HCl 500 mg PO Q12H \\nRX *ciprofloxacin 500 mg 1 tablet(s) by mouth twice a day Disp \\n#*23 Tablet Refills:*0\\n4. Acetaminophen ___ mg PO Q6H:PRN pain,fever, headache \\nRX *acetaminophen 500 mg 1 tablet(s) by mouth q6hrs Disp #*60 \\nTablet Refills:*0\\n5. GlipiZIDE 5 mg PO DAILY \\n6. Lisinopril 20 mg PO DAILY \\n7. MetFORMIN (Glucophage) 1000 mg PO BID \\n\\n \\nDischarge Disposition:\\nHome\\n \\nDischarge Diagnosis:\\nPrimary Diagnosis:\\n# Sepsis, secondary to pyelonephritis\\n\\nSecondary Diagnosis: \\n# Diabetes Type II\\n# Hypertension\\n# Hyperlipidemia\\n# Asthma\\n\\n \\nDischarge Condition:\\nMental Status: Clear and coherent.\\nLevel of Consciousness: Alert and interactive.\\nActivity Status: Ambulatory - Independent.\\n\\n \\nDischarge Instructions:\\nIt was a pleasure taking part in your care at ___ \\n___.\\n\\n___ were admitted for an infection in your blood and in your \\nkidneys, after recently being diagnosed and treated for a \\nurinary tract infection. Your kidney and blood infection were \\ntreated with IV antibiotics. ___ also had temporary kidney \\ninjury resulting from dehydration, which improved with \\nintravenous fluids. An ultrasound was preformed to look at your \\nkidneys, and everything looked normal. \\n\\n___ did not have a fever on the day of discharge. PLease buy a \\nthermometer for home. ___ should take your temperature several \\ntimes a day for the next few days. If your temperature is \\ngreater than 102 degrees, ___ should return to the ED.\\n\\n___ are discharged on ciprofloxacin 500mg twice a day for 14 \\ndays, to be completed on ___.\\n\\n___ should follow up with your PCP, ___ week\\n\\n___ should follow up your kidney doctor on ___ as planned. \\n \\n \\nFollowup Instructions:\\n___\\n\n",
       "3     \\nName:  ___             Unit No:   ___\\n \\nAdmission Date:  ___              Discharge Date:   ___\\n \\nDate of Birth:  ___             Sex:   F\\n \\nService: MEDICINE\\n \\nAllergies: \\nNo Known Allergies / Adverse Drug Reactions\\n \\nAttending: ___.\\n \\nChief Complaint:\\nfever, nausea/vomiting, flank pain\\n \\nMajor Surgical or Invasive Procedure:\\nnone \\n\\n \\nHistory of Present Illness:\\nHISTORY OF PRESENT ILLNESS:  \\nMs. ___ is a ___ year old ___ speaking lady with DM2 and \\nHTN who was evaluated in the ED ___, diagnosed with UTI and \\ntreated with macrobid, who returned with bilateral flank pain \\nL>R, fevers, chills, sweats, nausea, vomiting, headache, \\ndysuria. Denied neck stiffness. She was evaluated in ED \\ninitially with dizziness, headache, fever, found ot have a UTI \\nand discharged home w macrobid, which she took, but felt worse \\ntoday. She endorses minimal urine output that is dark.  \\nIn the ED, initial vs were: ___ pain 99.3 97 151/53 16 96% \\nyest. Today initial vitals were ___ pain 101.2 94 123/46 18 96% \\nRA. Today ED physical exam significant for bilateral \\ncostovertebral angle tenderness as well as mild suprapubic \\ntenderness, no meningismus clear lungs, normal heart exam. Labs \\nin ED sig for leukocytosis to 19.0 and a lactate of 3.0 ___s a bump in her creatinine from 1.2-1.3. Given the patient's \\nongoing symptoms rising leukocytosis as well as elevated lactate \\nand bilateral flank pain, she was given 1500 cc NS, 1 gram \\nceftriaxone, 1g acetaminophen for pyelonpehritis/fever, \\nunderwent renal u/s to evaluate for renal abscesses or \\nhydronephrosis (negative).  \\nVitals on Transfer: ___ pain 98.0 65 106/50 16 100%  \\n \\nOn the floor, vs were as below. She endorsed feeling somewhat \\nbetter but continued suprapubic discomfort and flank pain L>R. \\n\\n \\nPast Medical History:\\nType 2 diabetes  \\nAsthma  \\nHyperlipidemia  \\nHypertension  \\n\\n \\nSocial History:\\n___\\nFamily History:\\nShe has a sister deceased with endometrial cancer. No history of \\novarian, breast or colon cancer. No history of hypertension or \\ndiabetes in the family.  \\n\\n \\nPhysical Exam:\\nADMISSION EXAM: \\nVitals: tmax 101.2, tc 98.___ fs 207  \\nGeneral: Alert, oriented, no acute distress, lying in bed with \\nfamily at bedside  \\nHEENT: Sclera anicteric, MM dry  \\nNeck: supple, no meningismus, JVP not elevated  \\nLungs: Clear to auscultation bilaterally, no wheezes, rales, \\nronchi  \\nCV: Regular rate and rhythm, normal S1 + S2, no murmurs, rubs, \\ngallops  \\nAbdomen: soft, mild tenderness to deep palp @ suprapubic area, \\nnon-distended, bowel sounds present, no rebound tenderness, no \\norganomegaly  \\nBack: + CVA tenderness, L > R (mild on R)  \\nExt: Warm, well perfused, no edema  \\nSkin: moist, no rashes, no petechiae  \\nNeuro: speech fluent, linear, appropriate, no meningismus, \\noriented x3, moving all 4 extremities, did not assess gait.  \\n.\\nDISCHARGE EXAM: \\nPHYSICAL EXAM:  \\nGeneral: Alert, oriented, no acute distress, lying on bed \\nAbdomen: soft, non-tender, obese, bowel sounds present, no \\nrebound tenderness, no organomegaly  \\nBack: CVA tenderness resolved  \\nExt: Warm, well perfused, no edema  \\n\\n \\nPertinent Results:\\nADMISSION LABS: \\n___ 10:39PM   LACTATE-1.6\\n___ 09:00PM URINE  BLOOD-SM  NITRITE-NEG PROTEIN-TR \\nGLUCOSE-NEG KETONE-NEG BILIRUBIN-NEG UROBILNGN-NEG PH-5.0 \\nLEUK-LG\\n___ 09:00PM URINE  RBC-21* WBC-34* BACTERIA-FEW YEAST-NONE \\nEPI-2 TRANS EPI-<1\\n___ 07:27PM   LACTATE-3.0*\\n___ 07:17PM   GLUCOSE-210* UREA N-21* CREAT-1.3* \\nSODIUM-130* POTASSIUM-4.0 CHLORIDE-94* TOTAL CO2-22 ANION GAP-18\\n___ 07:17PM   WBC-19.2* RBC-3.65* HGB-11.0* HCT-31.1* \\nMCV-85 MCH-30.1 MCHC-35.4* RDW-12.6\\n___ 07:17PM   NEUTS-84.8* LYMPHS-10.1* MONOS-4.4 EOS-0.4 \\nBASOS-0.3\\n___ 07:17PM   PLT COUNT-204\\n.\\nRELEVANT LABS: \\n.\\n___ blood cultures: ___ bottles: \\n___ 7:17 pm BLOOD CULTURE\\n\\n                            **FINAL REPORT ___\\n\\n   Blood Culture, Routine (Final ___: \\n      ESCHERICHIA COLI.    FINAL SENSITIVITIES. \\n         Cefazolin interpretative criteria are based on a dosage \\nregimen of\\n         2g every 8h. \\n\\n                              SENSITIVITIES: MIC expressed in \\nMCG/ML\\n                      \\n_________________________________________________________\\n                             ESCHERICHIA COLI\\n                             |   \\nAMPICILLIN------------     4 S\\nAMPICILLIN/SULBACTAM--     4 S\\nCEFAZOLIN-------------   <=4 S\\nCEFEPIME--------------   <=1 S\\nCEFTAZIDIME-----------   <=1 S\\nCEFTRIAXONE-----------   <=1 S\\nCIPROFLOXACIN---------<=0.25 S\\nGENTAMICIN------------   <=1 S\\nMEROPENEM-------------<=0.25 S\\nPIPERACILLIN/TAZO-----   <=4 S\\nTOBRAMYCIN------------   <=1 S\\nTRIMETHOPRIM/SULFA----   <=1 S\\n\\n   Anaerobic Bottle Gram Stain (Final ___: \\n      GRAM NEGATIVE ROD(S). \\n      Reported to and read back by ___. ___ ___ 08:13AM. \\n\\n   Aerobic Bottle Gram Stain (Final ___:    GRAM NEGATIVE \\nROD(S). \\n\\n.\\n.\\nsubsequent blood cultures negative.\\n.\\n.\\n\\n                        \\n   URINE CULTURE (Final ___: \\n      MIXED BACTERIAL FLORA ( >= 3 COLONY TYPES), CONSISTENT \\nWITH SKIN\\n      AND/OR GENITAL CONTAMINATION. \\n.\\nDISCHARGE LABS: \\n.\\n___ 10:50AM BLOOD WBC-6.1 RBC-2.82* Hgb-8.3* Hct-24.4* \\nMCV-87 MCH-29.5 MCHC-34.1 RDW-12.3 Plt ___\\n___ 10:50AM BLOOD Plt ___\\n___ 07:15AM BLOOD Glucose-177* UreaN-14 Creat-0.9 Na-138 \\nK-3.9 Cl-102 HCO3-26 AnGap-14\\n___ 10:50AM BLOOD LD(LDH)-125 TotBili-0.4\\n___ 10:50AM BLOOD Iron-21*\\n___ 07:15AM BLOOD Calcium-8.9 Phos-2.7 Mg-1.7\\n___ 10:50AM BLOOD calTIBC-215* Hapto-224* Ferritn-333* \\nTRF-165*\\n \\nBrief Hospital Course:\\n___ was admitted on ___ for fevers, flank pain, \\nnausea/vomiting and headache. She had been admitted ___ for \\nurinary tract infection and discharged on nitrofurantoin. She \\nrepresented on ___, found to be febrile, with urinalysis \\nconsistent with infection, and was started on IV ceftriaxone. \\nRenal ultrasound was preformed, showing only a 8mm simple cyst. \\nSubsequent blood cultures showed GNR. \\n.\\nACUTE ISSUES: \\n.\\n# Pyelonephritis and Sepsis: Fever, dysuria, flank pain. \\ntreating initially w/ iv ceftriaxone. Renal u/s w/o e/o abscess \\nor stone as nidus. Patient was started on IV ceftriaxone, and \\ntransitioned to PO cipro\\nplan ___: Likely in setting of volume depletion given insensible \\nlosses (fever), vomiting, poor PO intake, as evidence by \\nelevated lactate and creatinine.  \\n- Cr 1.3 on admission --> .9 on discharged, resolved with IV \\nfluids\\n.\\nAnemia: requires outpatient evaluation.  Iron studies and lysis \\nlabs above. \\n.\\nCHRONIC ISSUES:\\n.\\n# Type 2 DM: Given acute infection, held glipizide and \\nmetformin.  \\n- insulin humalgos sliding scale  \\n- qid fingersticks  \\n- restarted on metformin, glipizide on discharge. \\n. \\n# Hyponatremia: Improved with hydration.\\n.\\n# Asthma: asymptomatic, not wheezing, monitor.  \\n.\\n# Hyperlipidemia: Continue statin, aspirin  \\n.\\n# Hypertension: held indapamide during stay for low-normal BPs, \\ndid not restart indapamide, to be restarted at discretion of PCP\\n.\\nFollow-up: \\n.\\nTo follow up with PCP to ensure resolution of symptoms as well \\nas to follow up anemia. \\n.\\nTo follow up with renal as scheduled prior to this inpatient \\nstay.\\n\\n \\nMedications on Admission:\\nThe Preadmission Medication list is accurate and complete.\\n1. Nitrofurantoin Monohyd (MacroBID) 100 mg PO Q12H \\n2. Aspirin 81 mg PO DAILY \\n3. Simvastatin 40 mg PO HS \\n4. Lisinopril 20 mg PO DAILY \\nplease hold for SBP<100, HR<60 \\n5. GlipiZIDE 5 mg PO DAILY \\n6. MetFORMIN (Glucophage) 1000 mg PO BID \\n7. Indapamide 1.25 mg PO DAILY \\nplease hold for SBP<100 \\n\\n \\nDischarge Medications:\\n1. Aspirin 81 mg PO DAILY \\n2. Simvastatin 40 mg PO HS \\n3. Ciprofloxacin HCl 500 mg PO Q12H \\nRX *ciprofloxacin 500 mg 1 tablet(s) by mouth twice a day Disp \\n#*23 Tablet Refills:*0\\n4. Acetaminophen ___ mg PO Q6H:PRN pain,fever, headache \\nRX *acetaminophen 500 mg 1 tablet(s) by mouth q6hrs Disp #*60 \\nTablet Refills:*0\\n5. GlipiZIDE 5 mg PO DAILY \\n6. Lisinopril 20 mg PO DAILY \\n7. MetFORMIN (Glucophage) 1000 mg PO BID \\n\\n \\nDischarge Disposition:\\nHome\\n \\nDischarge Diagnosis:\\nPrimary Diagnosis:\\n# Sepsis, secondary to pyelonephritis\\n\\nSecondary Diagnosis: \\n# Diabetes Type II\\n# Hypertension\\n# Hyperlipidemia\\n# Asthma\\n\\n \\nDischarge Condition:\\nMental Status: Clear and coherent.\\nLevel of Consciousness: Alert and interactive.\\nActivity Status: Ambulatory - Independent.\\n\\n \\nDischarge Instructions:\\nIt was a pleasure taking part in your care at ___ \\n___.\\n\\n___ were admitted for an infection in your blood and in your \\nkidneys, after recently being diagnosed and treated for a \\nurinary tract infection. Your kidney and blood infection were \\ntreated with IV antibiotics. ___ also had temporary kidney \\ninjury resulting from dehydration, which improved with \\nintravenous fluids. An ultrasound was preformed to look at your \\nkidneys, and everything looked normal. \\n\\n___ did not have a fever on the day of discharge. PLease buy a \\nthermometer for home. ___ should take your temperature several \\ntimes a day for the next few days. If your temperature is \\ngreater than 102 degrees, ___ should return to the ED.\\n\\n___ are discharged on ciprofloxacin 500mg twice a day for 14 \\ndays, to be completed on ___.\\n\\n___ should follow up with your PCP, ___ week\\n\\n___ should follow up your kidney doctor on ___ as planned. \\n \\n \\nFollowup Instructions:\\n___\\n\n",
       "4     \\nName:  ___             Unit No:   ___\\n \\nAdmission Date:  ___              Discharge Date:   ___\\n \\nDate of Birth:  ___             Sex:   F\\n \\nService: MEDICINE\\n \\nAllergies: \\nNo Known Allergies / Adverse Drug Reactions\\n \\nAttending: ___.\\n \\nChief Complaint:\\nfever, nausea/vomiting, flank pain\\n \\nMajor Surgical or Invasive Procedure:\\nnone \\n\\n \\nHistory of Present Illness:\\nHISTORY OF PRESENT ILLNESS:  \\nMs. ___ is a ___ year old ___ speaking lady with DM2 and \\nHTN who was evaluated in the ED ___, diagnosed with UTI and \\ntreated with macrobid, who returned with bilateral flank pain \\nL>R, fevers, chills, sweats, nausea, vomiting, headache, \\ndysuria. Denied neck stiffness. She was evaluated in ED \\ninitially with dizziness, headache, fever, found ot have a UTI \\nand discharged home w macrobid, which she took, but felt worse \\ntoday. She endorses minimal urine output that is dark.  \\nIn the ED, initial vs were: ___ pain 99.3 97 151/53 16 96% \\nyest. Today initial vitals were ___ pain 101.2 94 123/46 18 96% \\nRA. Today ED physical exam significant for bilateral \\ncostovertebral angle tenderness as well as mild suprapubic \\ntenderness, no meningismus clear lungs, normal heart exam. Labs \\nin ED sig for leukocytosis to 19.0 and a lactate of 3.0 ___s a bump in her creatinine from 1.2-1.3. Given the patient's \\nongoing symptoms rising leukocytosis as well as elevated lactate \\nand bilateral flank pain, she was given 1500 cc NS, 1 gram \\nceftriaxone, 1g acetaminophen for pyelonpehritis/fever, \\nunderwent renal u/s to evaluate for renal abscesses or \\nhydronephrosis (negative).  \\nVitals on Transfer: ___ pain 98.0 65 106/50 16 100%  \\n \\nOn the floor, vs were as below. She endorsed feeling somewhat \\nbetter but continued suprapubic discomfort and flank pain L>R. \\n\\n \\nPast Medical History:\\nType 2 diabetes  \\nAsthma  \\nHyperlipidemia  \\nHypertension  \\n\\n \\nSocial History:\\n___\\nFamily History:\\nShe has a sister deceased with endometrial cancer. No history of \\novarian, breast or colon cancer. No history of hypertension or \\ndiabetes in the family.  \\n\\n \\nPhysical Exam:\\nADMISSION EXAM: \\nVitals: tmax 101.2, tc 98.___ fs 207  \\nGeneral: Alert, oriented, no acute distress, lying in bed with \\nfamily at bedside  \\nHEENT: Sclera anicteric, MM dry  \\nNeck: supple, no meningismus, JVP not elevated  \\nLungs: Clear to auscultation bilaterally, no wheezes, rales, \\nronchi  \\nCV: Regular rate and rhythm, normal S1 + S2, no murmurs, rubs, \\ngallops  \\nAbdomen: soft, mild tenderness to deep palp @ suprapubic area, \\nnon-distended, bowel sounds present, no rebound tenderness, no \\norganomegaly  \\nBack: + CVA tenderness, L > R (mild on R)  \\nExt: Warm, well perfused, no edema  \\nSkin: moist, no rashes, no petechiae  \\nNeuro: speech fluent, linear, appropriate, no meningismus, \\noriented x3, moving all 4 extremities, did not assess gait.  \\n.\\nDISCHARGE EXAM: \\nPHYSICAL EXAM:  \\nGeneral: Alert, oriented, no acute distress, lying on bed \\nAbdomen: soft, non-tender, obese, bowel sounds present, no \\nrebound tenderness, no organomegaly  \\nBack: CVA tenderness resolved  \\nExt: Warm, well perfused, no edema  \\n\\n \\nPertinent Results:\\nADMISSION LABS: \\n___ 10:39PM   LACTATE-1.6\\n___ 09:00PM URINE  BLOOD-SM  NITRITE-NEG PROTEIN-TR \\nGLUCOSE-NEG KETONE-NEG BILIRUBIN-NEG UROBILNGN-NEG PH-5.0 \\nLEUK-LG\\n___ 09:00PM URINE  RBC-21* WBC-34* BACTERIA-FEW YEAST-NONE \\nEPI-2 TRANS EPI-<1\\n___ 07:27PM   LACTATE-3.0*\\n___ 07:17PM   GLUCOSE-210* UREA N-21* CREAT-1.3* \\nSODIUM-130* POTASSIUM-4.0 CHLORIDE-94* TOTAL CO2-22 ANION GAP-18\\n___ 07:17PM   WBC-19.2* RBC-3.65* HGB-11.0* HCT-31.1* \\nMCV-85 MCH-30.1 MCHC-35.4* RDW-12.6\\n___ 07:17PM   NEUTS-84.8* LYMPHS-10.1* MONOS-4.4 EOS-0.4 \\nBASOS-0.3\\n___ 07:17PM   PLT COUNT-204\\n.\\nRELEVANT LABS: \\n.\\n___ blood cultures: ___ bottles: \\n___ 7:17 pm BLOOD CULTURE\\n\\n                            **FINAL REPORT ___\\n\\n   Blood Culture, Routine (Final ___: \\n      ESCHERICHIA COLI.    FINAL SENSITIVITIES. \\n         Cefazolin interpretative criteria are based on a dosage \\nregimen of\\n         2g every 8h. \\n\\n                              SENSITIVITIES: MIC expressed in \\nMCG/ML\\n                      \\n_________________________________________________________\\n                             ESCHERICHIA COLI\\n                             |   \\nAMPICILLIN------------     4 S\\nAMPICILLIN/SULBACTAM--     4 S\\nCEFAZOLIN-------------   <=4 S\\nCEFEPIME--------------   <=1 S\\nCEFTAZIDIME-----------   <=1 S\\nCEFTRIAXONE-----------   <=1 S\\nCIPROFLOXACIN---------<=0.25 S\\nGENTAMICIN------------   <=1 S\\nMEROPENEM-------------<=0.25 S\\nPIPERACILLIN/TAZO-----   <=4 S\\nTOBRAMYCIN------------   <=1 S\\nTRIMETHOPRIM/SULFA----   <=1 S\\n\\n   Anaerobic Bottle Gram Stain (Final ___: \\n      GRAM NEGATIVE ROD(S). \\n      Reported to and read back by ___. ___ ___ 08:13AM. \\n\\n   Aerobic Bottle Gram Stain (Final ___:    GRAM NEGATIVE \\nROD(S). \\n\\n.\\n.\\nsubsequent blood cultures negative.\\n.\\n.\\n\\n                        \\n   URINE CULTURE (Final ___: \\n      MIXED BACTERIAL FLORA ( >= 3 COLONY TYPES), CONSISTENT \\nWITH SKIN\\n      AND/OR GENITAL CONTAMINATION. \\n.\\nDISCHARGE LABS: \\n.\\n___ 10:50AM BLOOD WBC-6.1 RBC-2.82* Hgb-8.3* Hct-24.4* \\nMCV-87 MCH-29.5 MCHC-34.1 RDW-12.3 Plt ___\\n___ 10:50AM BLOOD Plt ___\\n___ 07:15AM BLOOD Glucose-177* UreaN-14 Creat-0.9 Na-138 \\nK-3.9 Cl-102 HCO3-26 AnGap-14\\n___ 10:50AM BLOOD LD(LDH)-125 TotBili-0.4\\n___ 10:50AM BLOOD Iron-21*\\n___ 07:15AM BLOOD Calcium-8.9 Phos-2.7 Mg-1.7\\n___ 10:50AM BLOOD calTIBC-215* Hapto-224* Ferritn-333* \\nTRF-165*\\n \\nBrief Hospital Course:\\n___ was admitted on ___ for fevers, flank pain, \\nnausea/vomiting and headache. She had been admitted ___ for \\nurinary tract infection and discharged on nitrofurantoin. She \\nrepresented on ___, found to be febrile, with urinalysis \\nconsistent with infection, and was started on IV ceftriaxone. \\nRenal ultrasound was preformed, showing only a 8mm simple cyst. \\nSubsequent blood cultures showed GNR. \\n.\\nACUTE ISSUES: \\n.\\n# Pyelonephritis and Sepsis: Fever, dysuria, flank pain. \\ntreating initially w/ iv ceftriaxone. Renal u/s w/o e/o abscess \\nor stone as nidus. Patient was started on IV ceftriaxone, and \\ntransitioned to PO cipro\\nplan ___: Likely in setting of volume depletion given insensible \\nlosses (fever), vomiting, poor PO intake, as evidence by \\nelevated lactate and creatinine.  \\n- Cr 1.3 on admission --> .9 on discharged, resolved with IV \\nfluids\\n.\\nAnemia: requires outpatient evaluation.  Iron studies and lysis \\nlabs above. \\n.\\nCHRONIC ISSUES:\\n.\\n# Type 2 DM: Given acute infection, held glipizide and \\nmetformin.  \\n- insulin humalgos sliding scale  \\n- qid fingersticks  \\n- restarted on metformin, glipizide on discharge. \\n. \\n# Hyponatremia: Improved with hydration.\\n.\\n# Asthma: asymptomatic, not wheezing, monitor.  \\n.\\n# Hyperlipidemia: Continue statin, aspirin  \\n.\\n# Hypertension: held indapamide during stay for low-normal BPs, \\ndid not restart indapamide, to be restarted at discretion of PCP\\n.\\nFollow-up: \\n.\\nTo follow up with PCP to ensure resolution of symptoms as well \\nas to follow up anemia. \\n.\\nTo follow up with renal as scheduled prior to this inpatient \\nstay.\\n\\n \\nMedications on Admission:\\nThe Preadmission Medication list is accurate and complete.\\n1. Nitrofurantoin Monohyd (MacroBID) 100 mg PO Q12H \\n2. Aspirin 81 mg PO DAILY \\n3. Simvastatin 40 mg PO HS \\n4. Lisinopril 20 mg PO DAILY \\nplease hold for SBP<100, HR<60 \\n5. GlipiZIDE 5 mg PO DAILY \\n6. MetFORMIN (Glucophage) 1000 mg PO BID \\n7. Indapamide 1.25 mg PO DAILY \\nplease hold for SBP<100 \\n\\n \\nDischarge Medications:\\n1. Aspirin 81 mg PO DAILY \\n2. Simvastatin 40 mg PO HS \\n3. Ciprofloxacin HCl 500 mg PO Q12H \\nRX *ciprofloxacin 500 mg 1 tablet(s) by mouth twice a day Disp \\n#*23 Tablet Refills:*0\\n4. Acetaminophen ___ mg PO Q6H:PRN pain,fever, headache \\nRX *acetaminophen 500 mg 1 tablet(s) by mouth q6hrs Disp #*60 \\nTablet Refills:*0\\n5. GlipiZIDE 5 mg PO DAILY \\n6. Lisinopril 20 mg PO DAILY \\n7. MetFORMIN (Glucophage) 1000 mg PO BID \\n\\n \\nDischarge Disposition:\\nHome\\n \\nDischarge Diagnosis:\\nPrimary Diagnosis:\\n# Sepsis, secondary to pyelonephritis\\n\\nSecondary Diagnosis: \\n# Diabetes Type II\\n# Hypertension\\n# Hyperlipidemia\\n# Asthma\\n\\n \\nDischarge Condition:\\nMental Status: Clear and coherent.\\nLevel of Consciousness: Alert and interactive.\\nActivity Status: Ambulatory - Independent.\\n\\n \\nDischarge Instructions:\\nIt was a pleasure taking part in your care at ___ \\n___.\\n\\n___ were admitted for an infection in your blood and in your \\nkidneys, after recently being diagnosed and treated for a \\nurinary tract infection. Your kidney and blood infection were \\ntreated with IV antibiotics. ___ also had temporary kidney \\ninjury resulting from dehydration, which improved with \\nintravenous fluids. An ultrasound was preformed to look at your \\nkidneys, and everything looked normal. \\n\\n___ did not have a fever on the day of discharge. PLease buy a \\nthermometer for home. ___ should take your temperature several \\ntimes a day for the next few days. If your temperature is \\ngreater than 102 degrees, ___ should return to the ED.\\n\\n___ are discharged on ciprofloxacin 500mg twice a day for 14 \\ndays, to be completed on ___.\\n\\n___ should follow up with your PCP, ___ week\\n\\n___ should follow up your kidney doctor on ___ as planned. \\n \\n \\nFollowup Instructions:\\n___\\n\n",
       "5     \\nName:  ___             Unit No:   ___\\n \\nAdmission Date:  ___              Discharge Date:   ___\\n \\nDate of Birth:  ___             Sex:   F\\n \\nService: MEDICINE\\n \\nAllergies: \\nNo Known Allergies / Adverse Drug Reactions\\n \\nAttending: ___.\\n \\nChief Complaint:\\nfever, nausea/vomiting, flank pain\\n \\nMajor Surgical or Invasive Procedure:\\nnone \\n\\n \\nHistory of Present Illness:\\nHISTORY OF PRESENT ILLNESS:  \\nMs. ___ is a ___ year old ___ speaking lady with DM2 and \\nHTN who was evaluated in the ED ___, diagnosed with UTI and \\ntreated with macrobid, who returned with bilateral flank pain \\nL>R, fevers, chills, sweats, nausea, vomiting, headache, \\ndysuria. Denied neck stiffness. She was evaluated in ED \\ninitially with dizziness, headache, fever, found ot have a UTI \\nand discharged home w macrobid, which she took, but felt worse \\ntoday. She endorses minimal urine output that is dark.  \\nIn the ED, initial vs were: ___ pain 99.3 97 151/53 16 96% \\nyest. Today initial vitals were ___ pain 101.2 94 123/46 18 96% \\nRA. Today ED physical exam significant for bilateral \\ncostovertebral angle tenderness as well as mild suprapubic \\ntenderness, no meningismus clear lungs, normal heart exam. Labs \\nin ED sig for leukocytosis to 19.0 and a lactate of 3.0 ___s a bump in her creatinine from 1.2-1.3. Given the patient's \\nongoing symptoms rising leukocytosis as well as elevated lactate \\nand bilateral flank pain, she was given 1500 cc NS, 1 gram \\nceftriaxone, 1g acetaminophen for pyelonpehritis/fever, \\nunderwent renal u/s to evaluate for renal abscesses or \\nhydronephrosis (negative).  \\nVitals on Transfer: ___ pain 98.0 65 106/50 16 100%  \\n \\nOn the floor, vs were as below. She endorsed feeling somewhat \\nbetter but continued suprapubic discomfort and flank pain L>R. \\n\\n \\nPast Medical History:\\nType 2 diabetes  \\nAsthma  \\nHyperlipidemia  \\nHypertension  \\n\\n \\nSocial History:\\n___\\nFamily History:\\nShe has a sister deceased with endometrial cancer. No history of \\novarian, breast or colon cancer. No history of hypertension or \\ndiabetes in the family.  \\n\\n \\nPhysical Exam:\\nADMISSION EXAM: \\nVitals: tmax 101.2, tc 98.___ fs 207  \\nGeneral: Alert, oriented, no acute distress, lying in bed with \\nfamily at bedside  \\nHEENT: Sclera anicteric, MM dry  \\nNeck: supple, no meningismus, JVP not elevated  \\nLungs: Clear to auscultation bilaterally, no wheezes, rales, \\nronchi  \\nCV: Regular rate and rhythm, normal S1 + S2, no murmurs, rubs, \\ngallops  \\nAbdomen: soft, mild tenderness to deep palp @ suprapubic area, \\nnon-distended, bowel sounds present, no rebound tenderness, no \\norganomegaly  \\nBack: + CVA tenderness, L > R (mild on R)  \\nExt: Warm, well perfused, no edema  \\nSkin: moist, no rashes, no petechiae  \\nNeuro: speech fluent, linear, appropriate, no meningismus, \\noriented x3, moving all 4 extremities, did not assess gait.  \\n.\\nDISCHARGE EXAM: \\nPHYSICAL EXAM:  \\nGeneral: Alert, oriented, no acute distress, lying on bed \\nAbdomen: soft, non-tender, obese, bowel sounds present, no \\nrebound tenderness, no organomegaly  \\nBack: CVA tenderness resolved  \\nExt: Warm, well perfused, no edema  \\n\\n \\nPertinent Results:\\nADMISSION LABS: \\n___ 10:39PM   LACTATE-1.6\\n___ 09:00PM URINE  BLOOD-SM  NITRITE-NEG PROTEIN-TR \\nGLUCOSE-NEG KETONE-NEG BILIRUBIN-NEG UROBILNGN-NEG PH-5.0 \\nLEUK-LG\\n___ 09:00PM URINE  RBC-21* WBC-34* BACTERIA-FEW YEAST-NONE \\nEPI-2 TRANS EPI-<1\\n___ 07:27PM   LACTATE-3.0*\\n___ 07:17PM   GLUCOSE-210* UREA N-21* CREAT-1.3* \\nSODIUM-130* POTASSIUM-4.0 CHLORIDE-94* TOTAL CO2-22 ANION GAP-18\\n___ 07:17PM   WBC-19.2* RBC-3.65* HGB-11.0* HCT-31.1* \\nMCV-85 MCH-30.1 MCHC-35.4* RDW-12.6\\n___ 07:17PM   NEUTS-84.8* LYMPHS-10.1* MONOS-4.4 EOS-0.4 \\nBASOS-0.3\\n___ 07:17PM   PLT COUNT-204\\n.\\nRELEVANT LABS: \\n.\\n___ blood cultures: ___ bottles: \\n___ 7:17 pm BLOOD CULTURE\\n\\n                            **FINAL REPORT ___\\n\\n   Blood Culture, Routine (Final ___: \\n      ESCHERICHIA COLI.    FINAL SENSITIVITIES. \\n         Cefazolin interpretative criteria are based on a dosage \\nregimen of\\n         2g every 8h. \\n\\n                              SENSITIVITIES: MIC expressed in \\nMCG/ML\\n                      \\n_________________________________________________________\\n                             ESCHERICHIA COLI\\n                             |   \\nAMPICILLIN------------     4 S\\nAMPICILLIN/SULBACTAM--     4 S\\nCEFAZOLIN-------------   <=4 S\\nCEFEPIME--------------   <=1 S\\nCEFTAZIDIME-----------   <=1 S\\nCEFTRIAXONE-----------   <=1 S\\nCIPROFLOXACIN---------<=0.25 S\\nGENTAMICIN------------   <=1 S\\nMEROPENEM-------------<=0.25 S\\nPIPERACILLIN/TAZO-----   <=4 S\\nTOBRAMYCIN------------   <=1 S\\nTRIMETHOPRIM/SULFA----   <=1 S\\n\\n   Anaerobic Bottle Gram Stain (Final ___: \\n      GRAM NEGATIVE ROD(S). \\n      Reported to and read back by ___. ___ ___ 08:13AM. \\n\\n   Aerobic Bottle Gram Stain (Final ___:    GRAM NEGATIVE \\nROD(S). \\n\\n.\\n.\\nsubsequent blood cultures negative.\\n.\\n.\\n\\n                        \\n   URINE CULTURE (Final ___: \\n      MIXED BACTERIAL FLORA ( >= 3 COLONY TYPES), CONSISTENT \\nWITH SKIN\\n      AND/OR GENITAL CONTAMINATION. \\n.\\nDISCHARGE LABS: \\n.\\n___ 10:50AM BLOOD WBC-6.1 RBC-2.82* Hgb-8.3* Hct-24.4* \\nMCV-87 MCH-29.5 MCHC-34.1 RDW-12.3 Plt ___\\n___ 10:50AM BLOOD Plt ___\\n___ 07:15AM BLOOD Glucose-177* UreaN-14 Creat-0.9 Na-138 \\nK-3.9 Cl-102 HCO3-26 AnGap-14\\n___ 10:50AM BLOOD LD(LDH)-125 TotBili-0.4\\n___ 10:50AM BLOOD Iron-21*\\n___ 07:15AM BLOOD Calcium-8.9 Phos-2.7 Mg-1.7\\n___ 10:50AM BLOOD calTIBC-215* Hapto-224* Ferritn-333* \\nTRF-165*\\n \\nBrief Hospital Course:\\n___ was admitted on ___ for fevers, flank pain, \\nnausea/vomiting and headache. She had been admitted ___ for \\nurinary tract infection and discharged on nitrofurantoin. She \\nrepresented on ___, found to be febrile, with urinalysis \\nconsistent with infection, and was started on IV ceftriaxone. \\nRenal ultrasound was preformed, showing only a 8mm simple cyst. \\nSubsequent blood cultures showed GNR. \\n.\\nACUTE ISSUES: \\n.\\n# Pyelonephritis and Sepsis: Fever, dysuria, flank pain. \\ntreating initially w/ iv ceftriaxone. Renal u/s w/o e/o abscess \\nor stone as nidus. Patient was started on IV ceftriaxone, and \\ntransitioned to PO cipro\\nplan ___: Likely in setting of volume depletion given insensible \\nlosses (fever), vomiting, poor PO intake, as evidence by \\nelevated lactate and creatinine.  \\n- Cr 1.3 on admission --> .9 on discharged, resolved with IV \\nfluids\\n.\\nAnemia: requires outpatient evaluation.  Iron studies and lysis \\nlabs above. \\n.\\nCHRONIC ISSUES:\\n.\\n# Type 2 DM: Given acute infection, held glipizide and \\nmetformin.  \\n- insulin humalgos sliding scale  \\n- qid fingersticks  \\n- restarted on metformin, glipizide on discharge. \\n. \\n# Hyponatremia: Improved with hydration.\\n.\\n# Asthma: asymptomatic, not wheezing, monitor.  \\n.\\n# Hyperlipidemia: Continue statin, aspirin  \\n.\\n# Hypertension: held indapamide during stay for low-normal BPs, \\ndid not restart indapamide, to be restarted at discretion of PCP\\n.\\nFollow-up: \\n.\\nTo follow up with PCP to ensure resolution of symptoms as well \\nas to follow up anemia. \\n.\\nTo follow up with renal as scheduled prior to this inpatient \\nstay.\\n\\n \\nMedications on Admission:\\nThe Preadmission Medication list is accurate and complete.\\n1. Nitrofurantoin Monohyd (MacroBID) 100 mg PO Q12H \\n2. Aspirin 81 mg PO DAILY \\n3. Simvastatin 40 mg PO HS \\n4. Lisinopril 20 mg PO DAILY \\nplease hold for SBP<100, HR<60 \\n5. GlipiZIDE 5 mg PO DAILY \\n6. MetFORMIN (Glucophage) 1000 mg PO BID \\n7. Indapamide 1.25 mg PO DAILY \\nplease hold for SBP<100 \\n\\n \\nDischarge Medications:\\n1. Aspirin 81 mg PO DAILY \\n2. Simvastatin 40 mg PO HS \\n3. Ciprofloxacin HCl 500 mg PO Q12H \\nRX *ciprofloxacin 500 mg 1 tablet(s) by mouth twice a day Disp \\n#*23 Tablet Refills:*0\\n4. Acetaminophen ___ mg PO Q6H:PRN pain,fever, headache \\nRX *acetaminophen 500 mg 1 tablet(s) by mouth q6hrs Disp #*60 \\nTablet Refills:*0\\n5. GlipiZIDE 5 mg PO DAILY \\n6. Lisinopril 20 mg PO DAILY \\n7. MetFORMIN (Glucophage) 1000 mg PO BID \\n\\n \\nDischarge Disposition:\\nHome\\n \\nDischarge Diagnosis:\\nPrimary Diagnosis:\\n# Sepsis, secondary to pyelonephritis\\n\\nSecondary Diagnosis: \\n# Diabetes Type II\\n# Hypertension\\n# Hyperlipidemia\\n# Asthma\\n\\n \\nDischarge Condition:\\nMental Status: Clear and coherent.\\nLevel of Consciousness: Alert and interactive.\\nActivity Status: Ambulatory - Independent.\\n\\n \\nDischarge Instructions:\\nIt was a pleasure taking part in your care at ___ \\n___.\\n\\n___ were admitted for an infection in your blood and in your \\nkidneys, after recently being diagnosed and treated for a \\nurinary tract infection. Your kidney and blood infection were \\ntreated with IV antibiotics. ___ also had temporary kidney \\ninjury resulting from dehydration, which improved with \\nintravenous fluids. An ultrasound was preformed to look at your \\nkidneys, and everything looked normal. \\n\\n___ did not have a fever on the day of discharge. PLease buy a \\nthermometer for home. ___ should take your temperature several \\ntimes a day for the next few days. If your temperature is \\ngreater than 102 degrees, ___ should return to the ED.\\n\\n___ are discharged on ciprofloxacin 500mg twice a day for 14 \\ndays, to be completed on ___.\\n\\n___ should follow up with your PCP, ___ week\\n\\n___ should follow up your kidney doctor on ___ as planned. \\n \\n \\nFollowup Instructions:\\n___\\n\n",
       "6     \\nName:  ___             Unit No:   ___\\n \\nAdmission Date:  ___              Discharge Date:   ___\\n \\nDate of Birth:  ___             Sex:   F\\n \\nService: MEDICINE\\n \\nAllergies: \\nNo Known Allergies / Adverse Drug Reactions\\n \\nAttending: ___.\\n \\nChief Complaint:\\nfever, nausea/vomiting, flank pain\\n \\nMajor Surgical or Invasive Procedure:\\nnone \\n\\n \\nHistory of Present Illness:\\nHISTORY OF PRESENT ILLNESS:  \\nMs. ___ is a ___ year old ___ speaking lady with DM2 and \\nHTN who was evaluated in the ED ___, diagnosed with UTI and \\ntreated with macrobid, who returned with bilateral flank pain \\nL>R, fevers, chills, sweats, nausea, vomiting, headache, \\ndysuria. Denied neck stiffness. She was evaluated in ED \\ninitially with dizziness, headache, fever, found ot have a UTI \\nand discharged home w macrobid, which she took, but felt worse \\ntoday. She endorses minimal urine output that is dark.  \\nIn the ED, initial vs were: ___ pain 99.3 97 151/53 16 96% \\nyest. Today initial vitals were ___ pain 101.2 94 123/46 18 96% \\nRA. Today ED physical exam significant for bilateral \\ncostovertebral angle tenderness as well as mild suprapubic \\ntenderness, no meningismus clear lungs, normal heart exam. Labs \\nin ED sig for leukocytosis to 19.0 and a lactate of 3.0 ___s a bump in her creatinine from 1.2-1.3. Given the patient's \\nongoing symptoms rising leukocytosis as well as elevated lactate \\nand bilateral flank pain, she was given 1500 cc NS, 1 gram \\nceftriaxone, 1g acetaminophen for pyelonpehritis/fever, \\nunderwent renal u/s to evaluate for renal abscesses or \\nhydronephrosis (negative).  \\nVitals on Transfer: ___ pain 98.0 65 106/50 16 100%  \\n \\nOn the floor, vs were as below. She endorsed feeling somewhat \\nbetter but continued suprapubic discomfort and flank pain L>R. \\n\\n \\nPast Medical History:\\nType 2 diabetes  \\nAsthma  \\nHyperlipidemia  \\nHypertension  \\n\\n \\nSocial History:\\n___\\nFamily History:\\nShe has a sister deceased with endometrial cancer. No history of \\novarian, breast or colon cancer. No history of hypertension or \\ndiabetes in the family.  \\n\\n \\nPhysical Exam:\\nADMISSION EXAM: \\nVitals: tmax 101.2, tc 98.___ fs 207  \\nGeneral: Alert, oriented, no acute distress, lying in bed with \\nfamily at bedside  \\nHEENT: Sclera anicteric, MM dry  \\nNeck: supple, no meningismus, JVP not elevated  \\nLungs: Clear to auscultation bilaterally, no wheezes, rales, \\nronchi  \\nCV: Regular rate and rhythm, normal S1 + S2, no murmurs, rubs, \\ngallops  \\nAbdomen: soft, mild tenderness to deep palp @ suprapubic area, \\nnon-distended, bowel sounds present, no rebound tenderness, no \\norganomegaly  \\nBack: + CVA tenderness, L > R (mild on R)  \\nExt: Warm, well perfused, no edema  \\nSkin: moist, no rashes, no petechiae  \\nNeuro: speech fluent, linear, appropriate, no meningismus, \\noriented x3, moving all 4 extremities, did not assess gait.  \\n.\\nDISCHARGE EXAM: \\nPHYSICAL EXAM:  \\nGeneral: Alert, oriented, no acute distress, lying on bed \\nAbdomen: soft, non-tender, obese, bowel sounds present, no \\nrebound tenderness, no organomegaly  \\nBack: CVA tenderness resolved  \\nExt: Warm, well perfused, no edema  \\n\\n \\nPertinent Results:\\nADMISSION LABS: \\n___ 10:39PM   LACTATE-1.6\\n___ 09:00PM URINE  BLOOD-SM  NITRITE-NEG PROTEIN-TR \\nGLUCOSE-NEG KETONE-NEG BILIRUBIN-NEG UROBILNGN-NEG PH-5.0 \\nLEUK-LG\\n___ 09:00PM URINE  RBC-21* WBC-34* BACTERIA-FEW YEAST-NONE \\nEPI-2 TRANS EPI-<1\\n___ 07:27PM   LACTATE-3.0*\\n___ 07:17PM   GLUCOSE-210* UREA N-21* CREAT-1.3* \\nSODIUM-130* POTASSIUM-4.0 CHLORIDE-94* TOTAL CO2-22 ANION GAP-18\\n___ 07:17PM   WBC-19.2* RBC-3.65* HGB-11.0* HCT-31.1* \\nMCV-85 MCH-30.1 MCHC-35.4* RDW-12.6\\n___ 07:17PM   NEUTS-84.8* LYMPHS-10.1* MONOS-4.4 EOS-0.4 \\nBASOS-0.3\\n___ 07:17PM   PLT COUNT-204\\n.\\nRELEVANT LABS: \\n.\\n___ blood cultures: ___ bottles: \\n___ 7:17 pm BLOOD CULTURE\\n\\n                            **FINAL REPORT ___\\n\\n   Blood Culture, Routine (Final ___: \\n      ESCHERICHIA COLI.    FINAL SENSITIVITIES. \\n         Cefazolin interpretative criteria are based on a dosage \\nregimen of\\n         2g every 8h. \\n\\n                              SENSITIVITIES: MIC expressed in \\nMCG/ML\\n                      \\n_________________________________________________________\\n                             ESCHERICHIA COLI\\n                             |   \\nAMPICILLIN------------     4 S\\nAMPICILLIN/SULBACTAM--     4 S\\nCEFAZOLIN-------------   <=4 S\\nCEFEPIME--------------   <=1 S\\nCEFTAZIDIME-----------   <=1 S\\nCEFTRIAXONE-----------   <=1 S\\nCIPROFLOXACIN---------<=0.25 S\\nGENTAMICIN------------   <=1 S\\nMEROPENEM-------------<=0.25 S\\nPIPERACILLIN/TAZO-----   <=4 S\\nTOBRAMYCIN------------   <=1 S\\nTRIMETHOPRIM/SULFA----   <=1 S\\n\\n   Anaerobic Bottle Gram Stain (Final ___: \\n      GRAM NEGATIVE ROD(S). \\n      Reported to and read back by ___. ___ ___ 08:13AM. \\n\\n   Aerobic Bottle Gram Stain (Final ___:    GRAM NEGATIVE \\nROD(S). \\n\\n.\\n.\\nsubsequent blood cultures negative.\\n.\\n.\\n\\n                        \\n   URINE CULTURE (Final ___: \\n      MIXED BACTERIAL FLORA ( >= 3 COLONY TYPES), CONSISTENT \\nWITH SKIN\\n      AND/OR GENITAL CONTAMINATION. \\n.\\nDISCHARGE LABS: \\n.\\n___ 10:50AM BLOOD WBC-6.1 RBC-2.82* Hgb-8.3* Hct-24.4* \\nMCV-87 MCH-29.5 MCHC-34.1 RDW-12.3 Plt ___\\n___ 10:50AM BLOOD Plt ___\\n___ 07:15AM BLOOD Glucose-177* UreaN-14 Creat-0.9 Na-138 \\nK-3.9 Cl-102 HCO3-26 AnGap-14\\n___ 10:50AM BLOOD LD(LDH)-125 TotBili-0.4\\n___ 10:50AM BLOOD Iron-21*\\n___ 07:15AM BLOOD Calcium-8.9 Phos-2.7 Mg-1.7\\n___ 10:50AM BLOOD calTIBC-215* Hapto-224* Ferritn-333* \\nTRF-165*\\n \\nBrief Hospital Course:\\n___ was admitted on ___ for fevers, flank pain, \\nnausea/vomiting and headache. She had been admitted ___ for \\nurinary tract infection and discharged on nitrofurantoin. She \\nrepresented on ___, found to be febrile, with urinalysis \\nconsistent with infection, and was started on IV ceftriaxone. \\nRenal ultrasound was preformed, showing only a 8mm simple cyst. \\nSubsequent blood cultures showed GNR. \\n.\\nACUTE ISSUES: \\n.\\n# Pyelonephritis and Sepsis: Fever, dysuria, flank pain. \\ntreating initially w/ iv ceftriaxone. Renal u/s w/o e/o abscess \\nor stone as nidus. Patient was started on IV ceftriaxone, and \\ntransitioned to PO cipro\\nplan ___: Likely in setting of volume depletion given insensible \\nlosses (fever), vomiting, poor PO intake, as evidence by \\nelevated lactate and creatinine.  \\n- Cr 1.3 on admission --> .9 on discharged, resolved with IV \\nfluids\\n.\\nAnemia: requires outpatient evaluation.  Iron studies and lysis \\nlabs above. \\n.\\nCHRONIC ISSUES:\\n.\\n# Type 2 DM: Given acute infection, held glipizide and \\nmetformin.  \\n- insulin humalgos sliding scale  \\n- qid fingersticks  \\n- restarted on metformin, glipizide on discharge. \\n. \\n# Hyponatremia: Improved with hydration.\\n.\\n# Asthma: asymptomatic, not wheezing, monitor.  \\n.\\n# Hyperlipidemia: Continue statin, aspirin  \\n.\\n# Hypertension: held indapamide during stay for low-normal BPs, \\ndid not restart indapamide, to be restarted at discretion of PCP\\n.\\nFollow-up: \\n.\\nTo follow up with PCP to ensure resolution of symptoms as well \\nas to follow up anemia. \\n.\\nTo follow up with renal as scheduled prior to this inpatient \\nstay.\\n\\n \\nMedications on Admission:\\nThe Preadmission Medication list is accurate and complete.\\n1. Nitrofurantoin Monohyd (MacroBID) 100 mg PO Q12H \\n2. Aspirin 81 mg PO DAILY \\n3. Simvastatin 40 mg PO HS \\n4. Lisinopril 20 mg PO DAILY \\nplease hold for SBP<100, HR<60 \\n5. GlipiZIDE 5 mg PO DAILY \\n6. MetFORMIN (Glucophage) 1000 mg PO BID \\n7. Indapamide 1.25 mg PO DAILY \\nplease hold for SBP<100 \\n\\n \\nDischarge Medications:\\n1. Aspirin 81 mg PO DAILY \\n2. Simvastatin 40 mg PO HS \\n3. Ciprofloxacin HCl 500 mg PO Q12H \\nRX *ciprofloxacin 500 mg 1 tablet(s) by mouth twice a day Disp \\n#*23 Tablet Refills:*0\\n4. Acetaminophen ___ mg PO Q6H:PRN pain,fever, headache \\nRX *acetaminophen 500 mg 1 tablet(s) by mouth q6hrs Disp #*60 \\nTablet Refills:*0\\n5. GlipiZIDE 5 mg PO DAILY \\n6. Lisinopril 20 mg PO DAILY \\n7. MetFORMIN (Glucophage) 1000 mg PO BID \\n\\n \\nDischarge Disposition:\\nHome\\n \\nDischarge Diagnosis:\\nPrimary Diagnosis:\\n# Sepsis, secondary to pyelonephritis\\n\\nSecondary Diagnosis: \\n# Diabetes Type II\\n# Hypertension\\n# Hyperlipidemia\\n# Asthma\\n\\n \\nDischarge Condition:\\nMental Status: Clear and coherent.\\nLevel of Consciousness: Alert and interactive.\\nActivity Status: Ambulatory - Independent.\\n\\n \\nDischarge Instructions:\\nIt was a pleasure taking part in your care at ___ \\n___.\\n\\n___ were admitted for an infection in your blood and in your \\nkidneys, after recently being diagnosed and treated for a \\nurinary tract infection. Your kidney and blood infection were \\ntreated with IV antibiotics. ___ also had temporary kidney \\ninjury resulting from dehydration, which improved with \\nintravenous fluids. An ultrasound was preformed to look at your \\nkidneys, and everything looked normal. \\n\\n___ did not have a fever on the day of discharge. PLease buy a \\nthermometer for home. ___ should take your temperature several \\ntimes a day for the next few days. If your temperature is \\ngreater than 102 degrees, ___ should return to the ED.\\n\\n___ are discharged on ciprofloxacin 500mg twice a day for 14 \\ndays, to be completed on ___.\\n\\n___ should follow up with your PCP, ___ week\\n\\n___ should follow up your kidney doctor on ___ as planned. \\n \\n \\nFollowup Instructions:\\n___\\n\n",
       "7     \\nName:  ___             Unit No:   ___\\n \\nAdmission Date:  ___              Discharge Date:   ___\\n \\nDate of Birth:  ___             Sex:   F\\n \\nService: MEDICINE\\n \\nAllergies: \\nNo Known Allergies / Adverse Drug Reactions\\n \\nAttending: ___.\\n \\nChief Complaint:\\nfever, nausea/vomiting, flank pain\\n \\nMajor Surgical or Invasive Procedure:\\nnone \\n\\n \\nHistory of Present Illness:\\nHISTORY OF PRESENT ILLNESS:  \\nMs. ___ is a ___ year old ___ speaking lady with DM2 and \\nHTN who was evaluated in the ED ___, diagnosed with UTI and \\ntreated with macrobid, who returned with bilateral flank pain \\nL>R, fevers, chills, sweats, nausea, vomiting, headache, \\ndysuria. Denied neck stiffness. She was evaluated in ED \\ninitially with dizziness, headache, fever, found ot have a UTI \\nand discharged home w macrobid, which she took, but felt worse \\ntoday. She endorses minimal urine output that is dark.  \\nIn the ED, initial vs were: ___ pain 99.3 97 151/53 16 96% \\nyest. Today initial vitals were ___ pain 101.2 94 123/46 18 96% \\nRA. Today ED physical exam significant for bilateral \\ncostovertebral angle tenderness as well as mild suprapubic \\ntenderness, no meningismus clear lungs, normal heart exam. Labs \\nin ED sig for leukocytosis to 19.0 and a lactate of 3.0 ___s a bump in her creatinine from 1.2-1.3. Given the patient's \\nongoing symptoms rising leukocytosis as well as elevated lactate \\nand bilateral flank pain, she was given 1500 cc NS, 1 gram \\nceftriaxone, 1g acetaminophen for pyelonpehritis/fever, \\nunderwent renal u/s to evaluate for renal abscesses or \\nhydronephrosis (negative).  \\nVitals on Transfer: ___ pain 98.0 65 106/50 16 100%  \\n \\nOn the floor, vs were as below. She endorsed feeling somewhat \\nbetter but continued suprapubic discomfort and flank pain L>R. \\n\\n \\nPast Medical History:\\nType 2 diabetes  \\nAsthma  \\nHyperlipidemia  \\nHypertension  \\n\\n \\nSocial History:\\n___\\nFamily History:\\nShe has a sister deceased with endometrial cancer. No history of \\novarian, breast or colon cancer. No history of hypertension or \\ndiabetes in the family.  \\n\\n \\nPhysical Exam:\\nADMISSION EXAM: \\nVitals: tmax 101.2, tc 98.___ fs 207  \\nGeneral: Alert, oriented, no acute distress, lying in bed with \\nfamily at bedside  \\nHEENT: Sclera anicteric, MM dry  \\nNeck: supple, no meningismus, JVP not elevated  \\nLungs: Clear to auscultation bilaterally, no wheezes, rales, \\nronchi  \\nCV: Regular rate and rhythm, normal S1 + S2, no murmurs, rubs, \\ngallops  \\nAbdomen: soft, mild tenderness to deep palp @ suprapubic area, \\nnon-distended, bowel sounds present, no rebound tenderness, no \\norganomegaly  \\nBack: + CVA tenderness, L > R (mild on R)  \\nExt: Warm, well perfused, no edema  \\nSkin: moist, no rashes, no petechiae  \\nNeuro: speech fluent, linear, appropriate, no meningismus, \\noriented x3, moving all 4 extremities, did not assess gait.  \\n.\\nDISCHARGE EXAM: \\nPHYSICAL EXAM:  \\nGeneral: Alert, oriented, no acute distress, lying on bed \\nAbdomen: soft, non-tender, obese, bowel sounds present, no \\nrebound tenderness, no organomegaly  \\nBack: CVA tenderness resolved  \\nExt: Warm, well perfused, no edema  \\n\\n \\nPertinent Results:\\nADMISSION LABS: \\n___ 10:39PM   LACTATE-1.6\\n___ 09:00PM URINE  BLOOD-SM  NITRITE-NEG PROTEIN-TR \\nGLUCOSE-NEG KETONE-NEG BILIRUBIN-NEG UROBILNGN-NEG PH-5.0 \\nLEUK-LG\\n___ 09:00PM URINE  RBC-21* WBC-34* BACTERIA-FEW YEAST-NONE \\nEPI-2 TRANS EPI-<1\\n___ 07:27PM   LACTATE-3.0*\\n___ 07:17PM   GLUCOSE-210* UREA N-21* CREAT-1.3* \\nSODIUM-130* POTASSIUM-4.0 CHLORIDE-94* TOTAL CO2-22 ANION GAP-18\\n___ 07:17PM   WBC-19.2* RBC-3.65* HGB-11.0* HCT-31.1* \\nMCV-85 MCH-30.1 MCHC-35.4* RDW-12.6\\n___ 07:17PM   NEUTS-84.8* LYMPHS-10.1* MONOS-4.4 EOS-0.4 \\nBASOS-0.3\\n___ 07:17PM   PLT COUNT-204\\n.\\nRELEVANT LABS: \\n.\\n___ blood cultures: ___ bottles: \\n___ 7:17 pm BLOOD CULTURE\\n\\n                            **FINAL REPORT ___\\n\\n   Blood Culture, Routine (Final ___: \\n      ESCHERICHIA COLI.    FINAL SENSITIVITIES. \\n         Cefazolin interpretative criteria are based on a dosage \\nregimen of\\n         2g every 8h. \\n\\n                              SENSITIVITIES: MIC expressed in \\nMCG/ML\\n                      \\n_________________________________________________________\\n                             ESCHERICHIA COLI\\n                             |   \\nAMPICILLIN------------     4 S\\nAMPICILLIN/SULBACTAM--     4 S\\nCEFAZOLIN-------------   <=4 S\\nCEFEPIME--------------   <=1 S\\nCEFTAZIDIME-----------   <=1 S\\nCEFTRIAXONE-----------   <=1 S\\nCIPROFLOXACIN---------<=0.25 S\\nGENTAMICIN------------   <=1 S\\nMEROPENEM-------------<=0.25 S\\nPIPERACILLIN/TAZO-----   <=4 S\\nTOBRAMYCIN------------   <=1 S\\nTRIMETHOPRIM/SULFA----   <=1 S\\n\\n   Anaerobic Bottle Gram Stain (Final ___: \\n      GRAM NEGATIVE ROD(S). \\n      Reported to and read back by ___. ___ ___ 08:13AM. \\n\\n   Aerobic Bottle Gram Stain (Final ___:    GRAM NEGATIVE \\nROD(S). \\n\\n.\\n.\\nsubsequent blood cultures negative.\\n.\\n.\\n\\n                        \\n   URINE CULTURE (Final ___: \\n      MIXED BACTERIAL FLORA ( >= 3 COLONY TYPES), CONSISTENT \\nWITH SKIN\\n      AND/OR GENITAL CONTAMINATION. \\n.\\nDISCHARGE LABS: \\n.\\n___ 10:50AM BLOOD WBC-6.1 RBC-2.82* Hgb-8.3* Hct-24.4* \\nMCV-87 MCH-29.5 MCHC-34.1 RDW-12.3 Plt ___\\n___ 10:50AM BLOOD Plt ___\\n___ 07:15AM BLOOD Glucose-177* UreaN-14 Creat-0.9 Na-138 \\nK-3.9 Cl-102 HCO3-26 AnGap-14\\n___ 10:50AM BLOOD LD(LDH)-125 TotBili-0.4\\n___ 10:50AM BLOOD Iron-21*\\n___ 07:15AM BLOOD Calcium-8.9 Phos-2.7 Mg-1.7\\n___ 10:50AM BLOOD calTIBC-215* Hapto-224* Ferritn-333* \\nTRF-165*\\n \\nBrief Hospital Course:\\n___ was admitted on ___ for fevers, flank pain, \\nnausea/vomiting and headache. She had been admitted ___ for \\nurinary tract infection and discharged on nitrofurantoin. She \\nrepresented on ___, found to be febrile, with urinalysis \\nconsistent with infection, and was started on IV ceftriaxone. \\nRenal ultrasound was preformed, showing only a 8mm simple cyst. \\nSubsequent blood cultures showed GNR. \\n.\\nACUTE ISSUES: \\n.\\n# Pyelonephritis and Sepsis: Fever, dysuria, flank pain. \\ntreating initially w/ iv ceftriaxone. Renal u/s w/o e/o abscess \\nor stone as nidus. Patient was started on IV ceftriaxone, and \\ntransitioned to PO cipro\\nplan ___: Likely in setting of volume depletion given insensible \\nlosses (fever), vomiting, poor PO intake, as evidence by \\nelevated lactate and creatinine.  \\n- Cr 1.3 on admission --> .9 on discharged, resolved with IV \\nfluids\\n.\\nAnemia: requires outpatient evaluation.  Iron studies and lysis \\nlabs above. \\n.\\nCHRONIC ISSUES:\\n.\\n# Type 2 DM: Given acute infection, held glipizide and \\nmetformin.  \\n- insulin humalgos sliding scale  \\n- qid fingersticks  \\n- restarted on metformin, glipizide on discharge. \\n. \\n# Hyponatremia: Improved with hydration.\\n.\\n# Asthma: asymptomatic, not wheezing, monitor.  \\n.\\n# Hyperlipidemia: Continue statin, aspirin  \\n.\\n# Hypertension: held indapamide during stay for low-normal BPs, \\ndid not restart indapamide, to be restarted at discretion of PCP\\n.\\nFollow-up: \\n.\\nTo follow up with PCP to ensure resolution of symptoms as well \\nas to follow up anemia. \\n.\\nTo follow up with renal as scheduled prior to this inpatient \\nstay.\\n\\n \\nMedications on Admission:\\nThe Preadmission Medication list is accurate and complete.\\n1. Nitrofurantoin Monohyd (MacroBID) 100 mg PO Q12H \\n2. Aspirin 81 mg PO DAILY \\n3. Simvastatin 40 mg PO HS \\n4. Lisinopril 20 mg PO DAILY \\nplease hold for SBP<100, HR<60 \\n5. GlipiZIDE 5 mg PO DAILY \\n6. MetFORMIN (Glucophage) 1000 mg PO BID \\n7. Indapamide 1.25 mg PO DAILY \\nplease hold for SBP<100 \\n\\n \\nDischarge Medications:\\n1. Aspirin 81 mg PO DAILY \\n2. Simvastatin 40 mg PO HS \\n3. Ciprofloxacin HCl 500 mg PO Q12H \\nRX *ciprofloxacin 500 mg 1 tablet(s) by mouth twice a day Disp \\n#*23 Tablet Refills:*0\\n4. Acetaminophen ___ mg PO Q6H:PRN pain,fever, headache \\nRX *acetaminophen 500 mg 1 tablet(s) by mouth q6hrs Disp #*60 \\nTablet Refills:*0\\n5. GlipiZIDE 5 mg PO DAILY \\n6. Lisinopril 20 mg PO DAILY \\n7. MetFORMIN (Glucophage) 1000 mg PO BID \\n\\n \\nDischarge Disposition:\\nHome\\n \\nDischarge Diagnosis:\\nPrimary Diagnosis:\\n# Sepsis, secondary to pyelonephritis\\n\\nSecondary Diagnosis: \\n# Diabetes Type II\\n# Hypertension\\n# Hyperlipidemia\\n# Asthma\\n\\n \\nDischarge Condition:\\nMental Status: Clear and coherent.\\nLevel of Consciousness: Alert and interactive.\\nActivity Status: Ambulatory - Independent.\\n\\n \\nDischarge Instructions:\\nIt was a pleasure taking part in your care at ___ \\n___.\\n\\n___ were admitted for an infection in your blood and in your \\nkidneys, after recently being diagnosed and treated for a \\nurinary tract infection. Your kidney and blood infection were \\ntreated with IV antibiotics. ___ also had temporary kidney \\ninjury resulting from dehydration, which improved with \\nintravenous fluids. An ultrasound was preformed to look at your \\nkidneys, and everything looked normal. \\n\\n___ did not have a fever on the day of discharge. PLease buy a \\nthermometer for home. ___ should take your temperature several \\ntimes a day for the next few days. If your temperature is \\ngreater than 102 degrees, ___ should return to the ED.\\n\\n___ are discharged on ciprofloxacin 500mg twice a day for 14 \\ndays, to be completed on ___.\\n\\n___ should follow up with your PCP, ___ week\\n\\n___ should follow up your kidney doctor on ___ as planned. \\n \\n \\nFollowup Instructions:\\n___\\n\n",
       "8     \\nName:  ___             Unit No:   ___\\n \\nAdmission Date:  ___              Discharge Date:   ___\\n \\nDate of Birth:  ___             Sex:   F\\n \\nService: MEDICINE\\n \\nAllergies: \\nNo Known Allergies / Adverse Drug Reactions\\n \\nAttending: ___.\\n \\nChief Complaint:\\nfever, nausea/vomiting, flank pain\\n \\nMajor Surgical or Invasive Procedure:\\nnone \\n\\n \\nHistory of Present Illness:\\nHISTORY OF PRESENT ILLNESS:  \\nMs. ___ is a ___ year old ___ speaking lady with DM2 and \\nHTN who was evaluated in the ED ___, diagnosed with UTI and \\ntreated with macrobid, who returned with bilateral flank pain \\nL>R, fevers, chills, sweats, nausea, vomiting, headache, \\ndysuria. Denied neck stiffness. She was evaluated in ED \\ninitially with dizziness, headache, fever, found ot have a UTI \\nand discharged home w macrobid, which she took, but felt worse \\ntoday. She endorses minimal urine output that is dark.  \\nIn the ED, initial vs were: ___ pain 99.3 97 151/53 16 96% \\nyest. Today initial vitals were ___ pain 101.2 94 123/46 18 96% \\nRA. Today ED physical exam significant for bilateral \\ncostovertebral angle tenderness as well as mild suprapubic \\ntenderness, no meningismus clear lungs, normal heart exam. Labs \\nin ED sig for leukocytosis to 19.0 and a lactate of 3.0 ___s a bump in her creatinine from 1.2-1.3. Given the patient's \\nongoing symptoms rising leukocytosis as well as elevated lactate \\nand bilateral flank pain, she was given 1500 cc NS, 1 gram \\nceftriaxone, 1g acetaminophen for pyelonpehritis/fever, \\nunderwent renal u/s to evaluate for renal abscesses or \\nhydronephrosis (negative).  \\nVitals on Transfer: ___ pain 98.0 65 106/50 16 100%  \\n \\nOn the floor, vs were as below. She endorsed feeling somewhat \\nbetter but continued suprapubic discomfort and flank pain L>R. \\n\\n \\nPast Medical History:\\nType 2 diabetes  \\nAsthma  \\nHyperlipidemia  \\nHypertension  \\n\\n \\nSocial History:\\n___\\nFamily History:\\nShe has a sister deceased with endometrial cancer. No history of \\novarian, breast or colon cancer. No history of hypertension or \\ndiabetes in the family.  \\n\\n \\nPhysical Exam:\\nADMISSION EXAM: \\nVitals: tmax 101.2, tc 98.___ fs 207  \\nGeneral: Alert, oriented, no acute distress, lying in bed with \\nfamily at bedside  \\nHEENT: Sclera anicteric, MM dry  \\nNeck: supple, no meningismus, JVP not elevated  \\nLungs: Clear to auscultation bilaterally, no wheezes, rales, \\nronchi  \\nCV: Regular rate and rhythm, normal S1 + S2, no murmurs, rubs, \\ngallops  \\nAbdomen: soft, mild tenderness to deep palp @ suprapubic area, \\nnon-distended, bowel sounds present, no rebound tenderness, no \\norganomegaly  \\nBack: + CVA tenderness, L > R (mild on R)  \\nExt: Warm, well perfused, no edema  \\nSkin: moist, no rashes, no petechiae  \\nNeuro: speech fluent, linear, appropriate, no meningismus, \\noriented x3, moving all 4 extremities, did not assess gait.  \\n.\\nDISCHARGE EXAM: \\nPHYSICAL EXAM:  \\nGeneral: Alert, oriented, no acute distress, lying on bed \\nAbdomen: soft, non-tender, obese, bowel sounds present, no \\nrebound tenderness, no organomegaly  \\nBack: CVA tenderness resolved  \\nExt: Warm, well perfused, no edema  \\n\\n \\nPertinent Results:\\nADMISSION LABS: \\n___ 10:39PM   LACTATE-1.6\\n___ 09:00PM URINE  BLOOD-SM  NITRITE-NEG PROTEIN-TR \\nGLUCOSE-NEG KETONE-NEG BILIRUBIN-NEG UROBILNGN-NEG PH-5.0 \\nLEUK-LG\\n___ 09:00PM URINE  RBC-21* WBC-34* BACTERIA-FEW YEAST-NONE \\nEPI-2 TRANS EPI-<1\\n___ 07:27PM   LACTATE-3.0*\\n___ 07:17PM   GLUCOSE-210* UREA N-21* CREAT-1.3* \\nSODIUM-130* POTASSIUM-4.0 CHLORIDE-94* TOTAL CO2-22 ANION GAP-18\\n___ 07:17PM   WBC-19.2* RBC-3.65* HGB-11.0* HCT-31.1* \\nMCV-85 MCH-30.1 MCHC-35.4* RDW-12.6\\n___ 07:17PM   NEUTS-84.8* LYMPHS-10.1* MONOS-4.4 EOS-0.4 \\nBASOS-0.3\\n___ 07:17PM   PLT COUNT-204\\n.\\nRELEVANT LABS: \\n.\\n___ blood cultures: ___ bottles: \\n___ 7:17 pm BLOOD CULTURE\\n\\n                            **FINAL REPORT ___\\n\\n   Blood Culture, Routine (Final ___: \\n      ESCHERICHIA COLI.    FINAL SENSITIVITIES. \\n         Cefazolin interpretative criteria are based on a dosage \\nregimen of\\n         2g every 8h. \\n\\n                              SENSITIVITIES: MIC expressed in \\nMCG/ML\\n                      \\n_________________________________________________________\\n                             ESCHERICHIA COLI\\n                             |   \\nAMPICILLIN------------     4 S\\nAMPICILLIN/SULBACTAM--     4 S\\nCEFAZOLIN-------------   <=4 S\\nCEFEPIME--------------   <=1 S\\nCEFTAZIDIME-----------   <=1 S\\nCEFTRIAXONE-----------   <=1 S\\nCIPROFLOXACIN---------<=0.25 S\\nGENTAMICIN------------   <=1 S\\nMEROPENEM-------------<=0.25 S\\nPIPERACILLIN/TAZO-----   <=4 S\\nTOBRAMYCIN------------   <=1 S\\nTRIMETHOPRIM/SULFA----   <=1 S\\n\\n   Anaerobic Bottle Gram Stain (Final ___: \\n      GRAM NEGATIVE ROD(S). \\n      Reported to and read back by ___. ___ ___ 08:13AM. \\n\\n   Aerobic Bottle Gram Stain (Final ___:    GRAM NEGATIVE \\nROD(S). \\n\\n.\\n.\\nsubsequent blood cultures negative.\\n.\\n.\\n\\n                        \\n   URINE CULTURE (Final ___: \\n      MIXED BACTERIAL FLORA ( >= 3 COLONY TYPES), CONSISTENT \\nWITH SKIN\\n      AND/OR GENITAL CONTAMINATION. \\n.\\nDISCHARGE LABS: \\n.\\n___ 10:50AM BLOOD WBC-6.1 RBC-2.82* Hgb-8.3* Hct-24.4* \\nMCV-87 MCH-29.5 MCHC-34.1 RDW-12.3 Plt ___\\n___ 10:50AM BLOOD Plt ___\\n___ 07:15AM BLOOD Glucose-177* UreaN-14 Creat-0.9 Na-138 \\nK-3.9 Cl-102 HCO3-26 AnGap-14\\n___ 10:50AM BLOOD LD(LDH)-125 TotBili-0.4\\n___ 10:50AM BLOOD Iron-21*\\n___ 07:15AM BLOOD Calcium-8.9 Phos-2.7 Mg-1.7\\n___ 10:50AM BLOOD calTIBC-215* Hapto-224* Ferritn-333* \\nTRF-165*\\n \\nBrief Hospital Course:\\n___ was admitted on ___ for fevers, flank pain, \\nnausea/vomiting and headache. She had been admitted ___ for \\nurinary tract infection and discharged on nitrofurantoin. She \\nrepresented on ___, found to be febrile, with urinalysis \\nconsistent with infection, and was started on IV ceftriaxone. \\nRenal ultrasound was preformed, showing only a 8mm simple cyst. \\nSubsequent blood cultures showed GNR. \\n.\\nACUTE ISSUES: \\n.\\n# Pyelonephritis and Sepsis: Fever, dysuria, flank pain. \\ntreating initially w/ iv ceftriaxone. Renal u/s w/o e/o abscess \\nor stone as nidus. Patient was started on IV ceftriaxone, and \\ntransitioned to PO cipro\\nplan ___: Likely in setting of volume depletion given insensible \\nlosses (fever), vomiting, poor PO intake, as evidence by \\nelevated lactate and creatinine.  \\n- Cr 1.3 on admission --> .9 on discharged, resolved with IV \\nfluids\\n.\\nAnemia: requires outpatient evaluation.  Iron studies and lysis \\nlabs above. \\n.\\nCHRONIC ISSUES:\\n.\\n# Type 2 DM: Given acute infection, held glipizide and \\nmetformin.  \\n- insulin humalgos sliding scale  \\n- qid fingersticks  \\n- restarted on metformin, glipizide on discharge. \\n. \\n# Hyponatremia: Improved with hydration.\\n.\\n# Asthma: asymptomatic, not wheezing, monitor.  \\n.\\n# Hyperlipidemia: Continue statin, aspirin  \\n.\\n# Hypertension: held indapamide during stay for low-normal BPs, \\ndid not restart indapamide, to be restarted at discretion of PCP\\n.\\nFollow-up: \\n.\\nTo follow up with PCP to ensure resolution of symptoms as well \\nas to follow up anemia. \\n.\\nTo follow up with renal as scheduled prior to this inpatient \\nstay.\\n\\n \\nMedications on Admission:\\nThe Preadmission Medication list is accurate and complete.\\n1. Nitrofurantoin Monohyd (MacroBID) 100 mg PO Q12H \\n2. Aspirin 81 mg PO DAILY \\n3. Simvastatin 40 mg PO HS \\n4. Lisinopril 20 mg PO DAILY \\nplease hold for SBP<100, HR<60 \\n5. GlipiZIDE 5 mg PO DAILY \\n6. MetFORMIN (Glucophage) 1000 mg PO BID \\n7. Indapamide 1.25 mg PO DAILY \\nplease hold for SBP<100 \\n\\n \\nDischarge Medications:\\n1. Aspirin 81 mg PO DAILY \\n2. Simvastatin 40 mg PO HS \\n3. Ciprofloxacin HCl 500 mg PO Q12H \\nRX *ciprofloxacin 500 mg 1 tablet(s) by mouth twice a day Disp \\n#*23 Tablet Refills:*0\\n4. Acetaminophen ___ mg PO Q6H:PRN pain,fever, headache \\nRX *acetaminophen 500 mg 1 tablet(s) by mouth q6hrs Disp #*60 \\nTablet Refills:*0\\n5. GlipiZIDE 5 mg PO DAILY \\n6. Lisinopril 20 mg PO DAILY \\n7. MetFORMIN (Glucophage) 1000 mg PO BID \\n\\n \\nDischarge Disposition:\\nHome\\n \\nDischarge Diagnosis:\\nPrimary Diagnosis:\\n# Sepsis, secondary to pyelonephritis\\n\\nSecondary Diagnosis: \\n# Diabetes Type II\\n# Hypertension\\n# Hyperlipidemia\\n# Asthma\\n\\n \\nDischarge Condition:\\nMental Status: Clear and coherent.\\nLevel of Consciousness: Alert and interactive.\\nActivity Status: Ambulatory - Independent.\\n\\n \\nDischarge Instructions:\\nIt was a pleasure taking part in your care at ___ \\n___.\\n\\n___ were admitted for an infection in your blood and in your \\nkidneys, after recently being diagnosed and treated for a \\nurinary tract infection. Your kidney and blood infection were \\ntreated with IV antibiotics. ___ also had temporary kidney \\ninjury resulting from dehydration, which improved with \\nintravenous fluids. An ultrasound was preformed to look at your \\nkidneys, and everything looked normal. \\n\\n___ did not have a fever on the day of discharge. PLease buy a \\nthermometer for home. ___ should take your temperature several \\ntimes a day for the next few days. If your temperature is \\ngreater than 102 degrees, ___ should return to the ED.\\n\\n___ are discharged on ciprofloxacin 500mg twice a day for 14 \\ndays, to be completed on ___.\\n\\n___ should follow up with your PCP, ___ week\\n\\n___ should follow up your kidney doctor on ___ as planned. \\n \\n \\nFollowup Instructions:\\n___\\n\n",
       "9     \\nName:  ___             Unit No:   ___\\n \\nAdmission Date:  ___              Discharge Date:   ___\\n \\nDate of Birth:  ___             Sex:   F\\n \\nService: MEDICINE\\n \\nAllergies: \\nNo Known Allergies / Adverse Drug Reactions\\n \\nAttending: ___.\\n \\nChief Complaint:\\nfever, nausea/vomiting, flank pain\\n \\nMajor Surgical or Invasive Procedure:\\nnone \\n\\n \\nHistory of Present Illness:\\nHISTORY OF PRESENT ILLNESS:  \\nMs. ___ is a ___ year old ___ speaking lady with DM2 and \\nHTN who was evaluated in the ED ___, diagnosed with UTI and \\ntreated with macrobid, who returned with bilateral flank pain \\nL>R, fevers, chills, sweats, nausea, vomiting, headache, \\ndysuria. Denied neck stiffness. She was evaluated in ED \\ninitially with dizziness, headache, fever, found ot have a UTI \\nand discharged home w macrobid, which she took, but felt worse \\ntoday. She endorses minimal urine output that is dark.  \\nIn the ED, initial vs were: ___ pain 99.3 97 151/53 16 96% \\nyest. Today initial vitals were ___ pain 101.2 94 123/46 18 96% \\nRA. Today ED physical exam significant for bilateral \\ncostovertebral angle tenderness as well as mild suprapubic \\ntenderness, no meningismus clear lungs, normal heart exam. Labs \\nin ED sig for leukocytosis to 19.0 and a lactate of 3.0 ___s a bump in her creatinine from 1.2-1.3. Given the patient's \\nongoing symptoms rising leukocytosis as well as elevated lactate \\nand bilateral flank pain, she was given 1500 cc NS, 1 gram \\nceftriaxone, 1g acetaminophen for pyelonpehritis/fever, \\nunderwent renal u/s to evaluate for renal abscesses or \\nhydronephrosis (negative).  \\nVitals on Transfer: ___ pain 98.0 65 106/50 16 100%  \\n \\nOn the floor, vs were as below. She endorsed feeling somewhat \\nbetter but continued suprapubic discomfort and flank pain L>R. \\n\\n \\nPast Medical History:\\nType 2 diabetes  \\nAsthma  \\nHyperlipidemia  \\nHypertension  \\n\\n \\nSocial History:\\n___\\nFamily History:\\nShe has a sister deceased with endometrial cancer. No history of \\novarian, breast or colon cancer. No history of hypertension or \\ndiabetes in the family.  \\n\\n \\nPhysical Exam:\\nADMISSION EXAM: \\nVitals: tmax 101.2, tc 98.___ fs 207  \\nGeneral: Alert, oriented, no acute distress, lying in bed with \\nfamily at bedside  \\nHEENT: Sclera anicteric, MM dry  \\nNeck: supple, no meningismus, JVP not elevated  \\nLungs: Clear to auscultation bilaterally, no wheezes, rales, \\nronchi  \\nCV: Regular rate and rhythm, normal S1 + S2, no murmurs, rubs, \\ngallops  \\nAbdomen: soft, mild tenderness to deep palp @ suprapubic area, \\nnon-distended, bowel sounds present, no rebound tenderness, no \\norganomegaly  \\nBack: + CVA tenderness, L > R (mild on R)  \\nExt: Warm, well perfused, no edema  \\nSkin: moist, no rashes, no petechiae  \\nNeuro: speech fluent, linear, appropriate, no meningismus, \\noriented x3, moving all 4 extremities, did not assess gait.  \\n.\\nDISCHARGE EXAM: \\nPHYSICAL EXAM:  \\nGeneral: Alert, oriented, no acute distress, lying on bed \\nAbdomen: soft, non-tender, obese, bowel sounds present, no \\nrebound tenderness, no organomegaly  \\nBack: CVA tenderness resolved  \\nExt: Warm, well perfused, no edema  \\n\\n \\nPertinent Results:\\nADMISSION LABS: \\n___ 10:39PM   LACTATE-1.6\\n___ 09:00PM URINE  BLOOD-SM  NITRITE-NEG PROTEIN-TR \\nGLUCOSE-NEG KETONE-NEG BILIRUBIN-NEG UROBILNGN-NEG PH-5.0 \\nLEUK-LG\\n___ 09:00PM URINE  RBC-21* WBC-34* BACTERIA-FEW YEAST-NONE \\nEPI-2 TRANS EPI-<1\\n___ 07:27PM   LACTATE-3.0*\\n___ 07:17PM   GLUCOSE-210* UREA N-21* CREAT-1.3* \\nSODIUM-130* POTASSIUM-4.0 CHLORIDE-94* TOTAL CO2-22 ANION GAP-18\\n___ 07:17PM   WBC-19.2* RBC-3.65* HGB-11.0* HCT-31.1* \\nMCV-85 MCH-30.1 MCHC-35.4* RDW-12.6\\n___ 07:17PM   NEUTS-84.8* LYMPHS-10.1* MONOS-4.4 EOS-0.4 \\nBASOS-0.3\\n___ 07:17PM   PLT COUNT-204\\n.\\nRELEVANT LABS: \\n.\\n___ blood cultures: ___ bottles: \\n___ 7:17 pm BLOOD CULTURE\\n\\n                            **FINAL REPORT ___\\n\\n   Blood Culture, Routine (Final ___: \\n      ESCHERICHIA COLI.    FINAL SENSITIVITIES. \\n         Cefazolin interpretative criteria are based on a dosage \\nregimen of\\n         2g every 8h. \\n\\n                              SENSITIVITIES: MIC expressed in \\nMCG/ML\\n                      \\n_________________________________________________________\\n                             ESCHERICHIA COLI\\n                             |   \\nAMPICILLIN------------     4 S\\nAMPICILLIN/SULBACTAM--     4 S\\nCEFAZOLIN-------------   <=4 S\\nCEFEPIME--------------   <=1 S\\nCEFTAZIDIME-----------   <=1 S\\nCEFTRIAXONE-----------   <=1 S\\nCIPROFLOXACIN---------<=0.25 S\\nGENTAMICIN------------   <=1 S\\nMEROPENEM-------------<=0.25 S\\nPIPERACILLIN/TAZO-----   <=4 S\\nTOBRAMYCIN------------   <=1 S\\nTRIMETHOPRIM/SULFA----   <=1 S\\n\\n   Anaerobic Bottle Gram Stain (Final ___: \\n      GRAM NEGATIVE ROD(S). \\n      Reported to and read back by ___. ___ ___ 08:13AM. \\n\\n   Aerobic Bottle Gram Stain (Final ___:    GRAM NEGATIVE \\nROD(S). \\n\\n.\\n.\\nsubsequent blood cultures negative.\\n.\\n.\\n\\n                        \\n   URINE CULTURE (Final ___: \\n      MIXED BACTERIAL FLORA ( >= 3 COLONY TYPES), CONSISTENT \\nWITH SKIN\\n      AND/OR GENITAL CONTAMINATION. \\n.\\nDISCHARGE LABS: \\n.\\n___ 10:50AM BLOOD WBC-6.1 RBC-2.82* Hgb-8.3* Hct-24.4* \\nMCV-87 MCH-29.5 MCHC-34.1 RDW-12.3 Plt ___\\n___ 10:50AM BLOOD Plt ___\\n___ 07:15AM BLOOD Glucose-177* UreaN-14 Creat-0.9 Na-138 \\nK-3.9 Cl-102 HCO3-26 AnGap-14\\n___ 10:50AM BLOOD LD(LDH)-125 TotBili-0.4\\n___ 10:50AM BLOOD Iron-21*\\n___ 07:15AM BLOOD Calcium-8.9 Phos-2.7 Mg-1.7\\n___ 10:50AM BLOOD calTIBC-215* Hapto-224* Ferritn-333* \\nTRF-165*\\n \\nBrief Hospital Course:\\n___ was admitted on ___ for fevers, flank pain, \\nnausea/vomiting and headache. She had been admitted ___ for \\nurinary tract infection and discharged on nitrofurantoin. She \\nrepresented on ___, found to be febrile, with urinalysis \\nconsistent with infection, and was started on IV ceftriaxone. \\nRenal ultrasound was preformed, showing only a 8mm simple cyst. \\nSubsequent blood cultures showed GNR. \\n.\\nACUTE ISSUES: \\n.\\n# Pyelonephritis and Sepsis: Fever, dysuria, flank pain. \\ntreating initially w/ iv ceftriaxone. Renal u/s w/o e/o abscess \\nor stone as nidus. Patient was started on IV ceftriaxone, and \\ntransitioned to PO cipro\\nplan ___: Likely in setting of volume depletion given insensible \\nlosses (fever), vomiting, poor PO intake, as evidence by \\nelevated lactate and creatinine.  \\n- Cr 1.3 on admission --> .9 on discharged, resolved with IV \\nfluids\\n.\\nAnemia: requires outpatient evaluation.  Iron studies and lysis \\nlabs above. \\n.\\nCHRONIC ISSUES:\\n.\\n# Type 2 DM: Given acute infection, held glipizide and \\nmetformin.  \\n- insulin humalgos sliding scale  \\n- qid fingersticks  \\n- restarted on metformin, glipizide on discharge. \\n. \\n# Hyponatremia: Improved with hydration.\\n.\\n# Asthma: asymptomatic, not wheezing, monitor.  \\n.\\n# Hyperlipidemia: Continue statin, aspirin  \\n.\\n# Hypertension: held indapamide during stay for low-normal BPs, \\ndid not restart indapamide, to be restarted at discretion of PCP\\n.\\nFollow-up: \\n.\\nTo follow up with PCP to ensure resolution of symptoms as well \\nas to follow up anemia. \\n.\\nTo follow up with renal as scheduled prior to this inpatient \\nstay.\\n\\n \\nMedications on Admission:\\nThe Preadmission Medication list is accurate and complete.\\n1. Nitrofurantoin Monohyd (MacroBID) 100 mg PO Q12H \\n2. Aspirin 81 mg PO DAILY \\n3. Simvastatin 40 mg PO HS \\n4. Lisinopril 20 mg PO DAILY \\nplease hold for SBP<100, HR<60 \\n5. GlipiZIDE 5 mg PO DAILY \\n6. MetFORMIN (Glucophage) 1000 mg PO BID \\n7. Indapamide 1.25 mg PO DAILY \\nplease hold for SBP<100 \\n\\n \\nDischarge Medications:\\n1. Aspirin 81 mg PO DAILY \\n2. Simvastatin 40 mg PO HS \\n3. Ciprofloxacin HCl 500 mg PO Q12H \\nRX *ciprofloxacin 500 mg 1 tablet(s) by mouth twice a day Disp \\n#*23 Tablet Refills:*0\\n4. Acetaminophen ___ mg PO Q6H:PRN pain,fever, headache \\nRX *acetaminophen 500 mg 1 tablet(s) by mouth q6hrs Disp #*60 \\nTablet Refills:*0\\n5. GlipiZIDE 5 mg PO DAILY \\n6. Lisinopril 20 mg PO DAILY \\n7. MetFORMIN (Glucophage) 1000 mg PO BID \\n\\n \\nDischarge Disposition:\\nHome\\n \\nDischarge Diagnosis:\\nPrimary Diagnosis:\\n# Sepsis, secondary to pyelonephritis\\n\\nSecondary Diagnosis: \\n# Diabetes Type II\\n# Hypertension\\n# Hyperlipidemia\\n# Asthma\\n\\n \\nDischarge Condition:\\nMental Status: Clear and coherent.\\nLevel of Consciousness: Alert and interactive.\\nActivity Status: Ambulatory - Independent.\\n\\n \\nDischarge Instructions:\\nIt was a pleasure taking part in your care at ___ \\n___.\\n\\n___ were admitted for an infection in your blood and in your \\nkidneys, after recently being diagnosed and treated for a \\nurinary tract infection. Your kidney and blood infection were \\ntreated with IV antibiotics. ___ also had temporary kidney \\ninjury resulting from dehydration, which improved with \\nintravenous fluids. An ultrasound was preformed to look at your \\nkidneys, and everything looked normal. \\n\\n___ did not have a fever on the day of discharge. PLease buy a \\nthermometer for home. ___ should take your temperature several \\ntimes a day for the next few days. If your temperature is \\ngreater than 102 degrees, ___ should return to the ED.\\n\\n___ are discharged on ciprofloxacin 500mg twice a day for 14 \\ndays, to be completed on ___.\\n\\n___ should follow up with your PCP, ___ week\\n\\n___ should follow up your kidney doctor on ___ as planned. \\n \\n \\nFollowup Instructions:\\n___\\n\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the first 10 rows of the 'text' column\n",
    "# Set display options to avoid truncation\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "filtered_df['text'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VaCg_AFYaaCY",
    "outputId": "e5df8ffd-10fc-4888-8f03-80654873bd82"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6365080/6365080 [10:02<00:00, 10566.64it/s]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = '/Users/benjamintan/Downloads/mimic-iv-3.1/hosp/filtered_hadm_id.csv'  # Replace with your CSV file path\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Function to extract specific sections of interest\n",
    "def extract_sections(text):\n",
    "    # Check if text is a valid string\n",
    "    if not isinstance(text, str):\n",
    "        return {\n",
    "            'History of Present Illness': '',\n",
    "            'Past Medical History': '',\n",
    "            'Physical Exam': ''\n",
    "        }\n",
    "\n",
    "    # Regular expression to extract \"History of Present Illness\"\n",
    "    history_present_illness = re.search(r'History of Present Illness:([\\s\\S]*?)(?=\\n\\n|Past Medical History:|Physical Exam:|\\Z)', text, re.S | re.I)\n",
    "    history_present_illness = history_present_illness.group(1).strip() if history_present_illness else ''\n",
    "\n",
    "    # Regular expression to extract \"Past Medical History\"\n",
    "    past_medical_history = re.search(r'Past Medical History:([\\s\\S]*?)(?=\\n\\n|History of Present Illness:|Physical Exam:|\\Z)', text, re.S | re.I)\n",
    "    past_medical_history = past_medical_history.group(1).strip() if past_medical_history else ''\n",
    "\n",
    "    # Regular expression to extract \"Physical Exam\"\n",
    "    physical_exam = re.search(r'Physical Exam:([\\s\\S]*?)(?=\\n\\n|History of Present Illness:|Past Medical History:|\\Z)', text, re.S | re.I)\n",
    "    physical_exam = physical_exam.group(1).strip() if physical_exam else ''\n",
    "\n",
    "    # Combine the extracted sections into a dictionary\n",
    "    return {\n",
    "        'History of Present Illness': history_present_illness,\n",
    "        'Past Medical History': past_medical_history,\n",
    "        'Physical Exam': physical_exam\n",
    "    }\n",
    "\n",
    "# Apply the extraction function to the 'text' column with tqdm progress bar\n",
    "tqdm.pandas()\n",
    "extracted_data = df['text'].progress_apply(extract_sections)\n",
    "\n",
    "# Convert the extracted data to a DataFrame\n",
    "df_extracted = pd.DataFrame(extracted_data.tolist())\n",
    "\n",
    "# Concatenate the extracted columns with the original dataframe (excluding the old 'text' column)\n",
    "df_combined = pd.concat([df.drop(columns=['text']), df_extracted], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UfYUhLvWaaCY",
    "outputId": "0868b33b-e475-48c3-9b5b-b479ebd759c0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted sections saved to: /Users/benjamintan/Downloads/mimic-iv-3.1/hosp/extracted_sections.csv\n"
     ]
    }
   ],
   "source": [
    "# Save the new DataFrame with the extracted columns to a CSV file\n",
    "output_file_path = '/Users/benjamintan/Downloads/mimic-iv-3.1/hosp/extracted_sections.csv'  # Replace with your desired output file path\n",
    "df_combined.to_csv(output_file_path, index=False)\n",
    "\n",
    "print(f\"Extracted sections saved to: {output_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1PHZYalHaaCY"
   },
   "outputs": [],
   "source": [
    "# Drop rows where all extracted columns are empty\n",
    "df_combined = df_combined[~(df_combined['History of Present Illness'] == '') & ~(df_combined['Past Medical History'] == '') & ~(df_combined['Physical Exam'] == '')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yPLXWa5XaaCY",
    "outputId": "b9b5ee4d-389c-44c7-9b2a-a4d1e426686e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows where all extracted columns are empty: 0\n"
     ]
    }
   ],
   "source": [
    "df_combined.count() == 0\n",
    "\n",
    "# Count rows where all extracted columns are empty\n",
    "empty_rows_count = df_combined[\n",
    "    (df_combined['History of Present Illness'] == '') &\n",
    "    (df_combined['Past Medical History'] == '') &\n",
    "    (df_combined['Physical Exam'] == '')\n",
    "].shape[0]\n",
    "\n",
    "print(f\"Number of rows where all extracted columns are empty: {empty_rows_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-5kfc4YPaaCY",
    "outputId": "67b4f9ee-48ee-4b8b-b7d5-38ad4b1cc965"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted sections saved to: /Users/benjamintan/Downloads/mimic-iv-3.1/hosp/extracted_sections_drop_empty.csv\n"
     ]
    }
   ],
   "source": [
    "# Save the new DataFrame with the extracted columns to a CSV file\n",
    "output_file_path = '/Users/benjamintan/Downloads/mimic-iv-3.1/hosp/extracted_sections_drop_empty.csv'  # Replace with your desired output file path\n",
    "df_combined.to_csv(output_file_path, index=False)\n",
    "\n",
    "print(f\"Extracted sections saved to: {output_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T09:08:50.154081Z",
     "iopub.status.busy": "2024-12-10T09:08:50.153914Z",
     "iopub.status.idle": "2024-12-10T09:09:21.950654Z",
     "shell.execute_reply": "2024-12-10T09:09:21.950316Z",
     "shell.execute_reply.started": "2024-12-10T09:08:50.154069Z"
    },
    "id": "l1UoofN1aaCY",
    "outputId": "140c334e-c7a3-4b64-d6ac-3e192b7158d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled dataset saved to: /Users/benjamintan/Downloads/mimic-iv-3.1/hosp/extracted_sections_sampled_300000.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = '/Users/benjamintan/Downloads/mimic-iv-3.1/hosp/extracted_sections_drop_empty.csv'  # Replace with your CSV file path\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Randomly sample 500,000 rows from the DataFrame\n",
    "df_sampled = df.sample(n=300000, random_state=42)\n",
    "\n",
    "# Save the reduced dataset to a new CSV file\n",
    "output_file_path = '/Users/benjamintan/Downloads/mimic-iv-3.1/hosp/extracted_sections_sampled_300000.csv'\n",
    "df_sampled.to_csv(output_file_path, index=False)\n",
    "\n",
    "print(f\"Sampled dataset saved to: {output_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-EQYuGrRaaCY",
    "outputId": "6858c5cd-33af-45be-8a11-8cdc85b46780",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/NLP_project/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Generating Embeddings: 100%|██████████| 30000/30000 [1:09:31<00:00,  7.19it/s]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.017666666666666667\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       00845       0.00      0.00      0.00         8\n",
      "        0088       0.00      0.00      0.00         2\n",
      "        0380       0.00      0.00      0.00         1\n",
      "       03811       0.00      0.00      0.00         1\n",
      "       03840       0.00      0.00      0.00         1\n",
      "       03842       0.00      0.00      0.00         2\n",
      "        0389       0.00      0.00      0.00         6\n",
      "       04104       0.00      0.00      0.00         4\n",
      "       04111       0.00      0.00      0.00         4\n",
      "       04112       0.00      0.00      0.00         4\n",
      "       04119       0.00      0.00      0.00         1\n",
      "        0413       0.00      0.00      0.00         1\n",
      "        0414       0.00      0.00      0.00         2\n",
      "       04149       0.00      0.00      0.00         7\n",
      "        0416       0.00      0.00      0.00         1\n",
      "        0417       0.00      0.00      0.00         2\n",
      "       04184       0.00      0.00      0.00         1\n",
      "       04185       0.00      0.00      0.00         1\n",
      "       04186       0.00      0.00      0.00         1\n",
      "       04189       0.00      0.00      0.00         2\n",
      "        0419       0.00      0.00      0.00         1\n",
      "         042       0.00      0.00      0.00         0\n",
      "        0530       0.00      0.00      0.00         1\n",
      "       05319       0.00      0.00      0.00         1\n",
      "       05410       0.00      0.00      0.00         1\n",
      "        0661       0.00      0.00      0.00         1\n",
      "       07030       0.00      0.00      0.00         2\n",
      "       07032       0.00      0.00      0.00         2\n",
      "       07044       0.00      0.00      0.00         1\n",
      "       07051       0.00      0.00      0.00         1\n",
      "       07054       0.00      0.00      0.00         3\n",
      "       07070       0.00      0.00      0.00         4\n",
      "       07799       0.00      0.00      0.00         1\n",
      "        0785       0.00      0.00      0.00         1\n",
      "       07999       0.00      0.00      0.00         0\n",
      "        0949       0.00      0.00      0.00         1\n",
      "        1104       0.00      0.00      0.00         1\n",
      "        1120       0.00      0.00      0.00         6\n",
      "        1122       0.00      0.00      0.00         2\n",
      "        1177       0.00      0.00      0.00         1\n",
      "        1508       0.00      0.00      0.00         2\n",
      "        1510       0.00      0.00      0.00         1\n",
      "        1534       0.00      0.00      0.00         1\n",
      "        1536       0.00      0.00      0.00         2\n",
      "        1550       0.00      0.00      0.00         2\n",
      "        1570       0.00      0.00      0.00         1\n",
      "        1578       0.00      0.00      0.00         1\n",
      "        1579       0.00      0.00      0.00         1\n",
      "        1623       0.00      0.00      0.00         2\n",
      "        1624       0.00      0.00      0.00         1\n",
      "        1625       0.00      0.00      0.00         1\n",
      "        1629       0.00      0.00      0.00         1\n",
      "        1706       0.00      0.00      0.00         1\n",
      "        1707       0.00      0.00      0.00         1\n",
      "        1723       0.00      0.00      0.00         1\n",
      "        1727       0.00      0.00      0.00         1\n",
      "        1732       0.00      0.00      0.00         1\n",
      "        1749       0.00      0.00      0.00         3\n",
      "        1760       0.00      0.00      0.00         1\n",
      "        1820       0.00      0.00      0.00         0\n",
      "        1830       0.00      0.00      0.00         3\n",
      "         185       0.00      0.00      0.00         5\n",
      "        1888       0.00      0.00      0.00         0\n",
      "        1890       0.00      0.00      0.00         0\n",
      "        1911       0.00      0.00      0.00         1\n",
      "        1961       0.00      0.00      0.00         1\n",
      "        1962       0.00      0.00      0.00         0\n",
      "        1966       0.00      0.00      0.00         1\n",
      "        1969       0.00      0.00      0.00         1\n",
      "        1970       0.00      0.00      0.00         0\n",
      "        1972       0.00      0.00      0.00         2\n",
      "        1976       0.00      0.00      0.00         2\n",
      "        1977       0.00      0.00      0.00         6\n",
      "        1980       0.00      0.00      0.00         0\n",
      "        1982       0.00      0.00      0.00         0\n",
      "        1983       0.00      0.00      0.00         4\n",
      "        1984       0.00      0.00      0.00         1\n",
      "        1985       0.05      0.14      0.08         7\n",
      "        1986       0.00      0.00      0.00         2\n",
      "        1987       0.00      0.00      0.00         1\n",
      "       19882       0.00      0.00      0.00         1\n",
      "       19889       0.00      0.00      0.00         1\n",
      "        1991       0.00      0.00      0.00         1\n",
      "       20044       0.00      0.00      0.00         1\n",
      "       20050       0.00      0.00      0.00         0\n",
      "       20280       0.00      0.00      0.00         5\n",
      "       20300       0.00      0.00      0.00         3\n",
      "       20301       0.00      0.00      0.00         0\n",
      "       20302       0.00      0.00      0.00         1\n",
      "       20410       0.00      0.00      0.00         2\n",
      "       20500       0.00      0.00      0.00         2\n",
      "       20502       0.00      0.00      0.00         2\n",
      "       20510       0.00      0.00      0.00         1\n",
      "        2102       0.00      0.00      0.00         1\n",
      "        2112       0.00      0.00      0.00         1\n",
      "        2113       0.00      0.00      0.00         8\n",
      "        2143       0.00      0.00      0.00         1\n",
      "        2180       0.00      0.00      0.00         1\n",
      "        2182       0.00      0.00      0.00         1\n",
      "        2189       0.00      0.00      0.00         2\n",
      "        2252       0.00      0.00      0.00         2\n",
      "        2270       0.00      0.00      0.00         1\n",
      "        2330       0.00      0.00      0.00         0\n",
      "        2384       0.00      0.00      0.00         1\n",
      "       23871       0.00      0.00      0.00         1\n",
      "       23875       0.00      0.00      0.00         1\n",
      "        2410       0.00      0.00      0.00         2\n",
      "        2411       0.00      0.00      0.00         1\n",
      "       24290       0.00      0.00      0.00         1\n",
      "        2440       0.00      0.00      0.00         1\n",
      "        2448       0.00      0.00      0.00         1\n",
      "        2449       0.01      0.02      0.02        43\n",
      "        2452       0.00      0.00      0.00         1\n",
      "       25000       0.03      0.05      0.03        58\n",
      "       25002       0.00      0.00      0.00         6\n",
      "       25012       0.00      0.00      0.00         1\n",
      "       25013       0.00      0.00      0.00         1\n",
      "       25040       0.00      0.00      0.00         3\n",
      "       25041       0.00      0.00      0.00         2\n",
      "       25042       0.00      0.00      0.00         1\n",
      "       25043       0.00      0.00      0.00         1\n",
      "       25050       0.00      0.00      0.00         7\n",
      "       25051       0.00      0.00      0.00         2\n",
      "       25053       0.00      0.00      0.00         3\n",
      "       25060       0.00      0.00      0.00         7\n",
      "       25061       0.00      0.00      0.00         3\n",
      "       25062       0.00      0.00      0.00         3\n",
      "       25063       0.00      0.00      0.00         2\n",
      "       25071       0.00      0.00      0.00         1\n",
      "       25080       0.00      0.00      0.00         1\n",
      "       25081       0.00      0.00      0.00         1\n",
      "       25082       0.00      0.00      0.00         4\n",
      "       25083       0.00      0.00      0.00         2\n",
      "       25090       0.00      0.00      0.00         1\n",
      "        2513       0.00      0.00      0.00         1\n",
      "       25200       0.00      0.00      0.00         1\n",
      "        2535       0.00      0.00      0.00         1\n",
      "        2536       0.00      0.00      0.00         4\n",
      "       25541       0.00      0.00      0.00         2\n",
      "        2572       0.00      0.00      0.00         2\n",
      "         261       0.00      0.00      0.00         1\n",
      "         262       0.00      0.00      0.00         1\n",
      "        2631       0.00      0.00      0.00         1\n",
      "        2638       0.00      0.00      0.00         1\n",
      "        2639       0.00      0.00      0.00         5\n",
      "        2662       0.00      0.00      0.00         3\n",
      "        2689       0.00      0.00      0.00         3\n",
      "        2690       0.00      0.00      0.00         1\n",
      "        2704       0.00      0.00      0.00         1\n",
      "        2720       0.00      0.00      0.00        28\n",
      "        2721       0.00      0.00      0.00         2\n",
      "        2724       0.02      0.10      0.04        91\n",
      "        2731       0.00      0.00      0.00         2\n",
      "        2738       0.00      0.00      0.00         3\n",
      "       27400       0.00      0.00      0.00         1\n",
      "       27401       0.00      0.00      0.00         1\n",
      "       27403       0.00      0.00      0.00         1\n",
      "        2749       0.00      0.00      0.00        13\n",
      "        2752       0.00      0.00      0.00         6\n",
      "        2753       0.00      0.00      0.00         3\n",
      "       27541       0.00      0.00      0.00         6\n",
      "       27542       0.00      0.00      0.00         4\n",
      "       27549       0.00      0.00      0.00         3\n",
      "        2760       0.00      0.00      0.00        12\n",
      "        2761       0.00      0.00      0.00        16\n",
      "        2762       0.00      0.00      0.00        14\n",
      "        2763       0.00      0.00      0.00         4\n",
      "        2764       0.00      0.00      0.00         1\n",
      "       27650       0.00      0.00      0.00         1\n",
      "       27651       0.00      0.00      0.00        12\n",
      "       27652       0.00      0.00      0.00         5\n",
      "        2766       0.00      0.00      0.00         1\n",
      "       27669       0.00      0.00      0.00         2\n",
      "        2767       0.00      0.00      0.00        12\n",
      "        2768       0.00      0.00      0.00        10\n",
      "       27739       0.00      0.00      0.00         1\n",
      "        2777       0.00      0.00      0.00         1\n",
      "       27787       0.00      0.00      0.00         1\n",
      "       27800       0.00      0.00      0.00        11\n",
      "       27801       0.00      0.00      0.00         8\n",
      "       27803       0.00      0.00      0.00         1\n",
      "       27901       0.00      0.00      0.00         1\n",
      "       27952       0.00      0.00      0.00         1\n",
      "        2800       0.00      0.00      0.00         3\n",
      "        2809       0.00      0.00      0.00         7\n",
      "        2811       0.00      0.00      0.00         3\n",
      "       28249       0.00      0.00      0.00         1\n",
      "       28260       0.00      0.00      0.00         1\n",
      "        2841       0.00      0.00      0.00         6\n",
      "       28419       0.00      0.00      0.00         1\n",
      "        2851       0.00      0.00      0.00        11\n",
      "       28521       0.00      0.00      0.00        11\n",
      "       28522       0.00      0.00      0.00         1\n",
      "       28529       0.00      0.00      0.00         4\n",
      "        2853       0.00      0.00      0.00         2\n",
      "        2859       0.03      0.07      0.05        27\n",
      "        2860       0.00      0.00      0.00         1\n",
      "        2866       0.00      0.00      0.00         3\n",
      "        2867       0.00      0.00      0.00         1\n",
      "        2869       0.00      0.00      0.00         0\n",
      "        2871       0.00      0.00      0.00         1\n",
      "        2872       0.00      0.00      0.00         1\n",
      "       28730       0.00      0.00      0.00         1\n",
      "        2874       0.00      0.00      0.00         1\n",
      "       28749       0.00      0.00      0.00         1\n",
      "        2875       0.00      0.00      0.00        13\n",
      "       28800       0.00      0.00      0.00         3\n",
      "       28803       0.00      0.00      0.00         2\n",
      "        2883       0.00      0.00      0.00         2\n",
      "       28850       0.00      0.00      0.00         2\n",
      "       28860       0.00      0.00      0.00         9\n",
      "       28959       0.00      0.00      0.00         1\n",
      "       28981       0.00      0.00      0.00         3\n",
      "       29040       0.00      0.00      0.00         3\n",
      "       29181       0.00      0.00      0.00         3\n",
      "        2920       0.00      0.00      0.00         1\n",
      "        2930       0.00      0.00      0.00         3\n",
      "        2939       0.00      0.00      0.00         1\n",
      "       29410       0.00      0.00      0.00         2\n",
      "       29420       0.00      0.00      0.00         2\n",
      "        2948       0.00      0.00      0.00         4\n",
      "       29570       0.00      0.00      0.00         1\n",
      "       29572       0.00      0.00      0.00         2\n",
      "       29574       0.00      0.00      0.00         1\n",
      "       29580       0.00      0.00      0.00         1\n",
      "       29620       0.00      0.00      0.00         2\n",
      "       29623       0.00      0.00      0.00         1\n",
      "       29633       0.00      0.00      0.00         1\n",
      "       29634       0.00      0.00      0.00         1\n",
      "       29640       0.00      0.00      0.00         1\n",
      "       29644       0.00      0.00      0.00         1\n",
      "       29650       0.00      0.00      0.00         1\n",
      "       29680       0.00      0.00      0.00         2\n",
      "        2989       0.00      0.00      0.00         2\n",
      "       29980       0.00      0.00      0.00         1\n",
      "       30000       0.00      0.00      0.00        28\n",
      "       30002       0.00      0.00      0.00         1\n",
      "       30009       0.00      0.00      0.00         1\n",
      "       30021       0.00      0.00      0.00         2\n",
      "        3003       0.00      0.00      0.00         1\n",
      "        3004       0.00      0.00      0.00         8\n",
      "       30300       0.00      0.00      0.00         3\n",
      "       30301       0.00      0.00      0.00         0\n",
      "       30390       0.00      0.00      0.00         4\n",
      "       30391       0.00      0.00      0.00         4\n",
      "       30392       0.00      0.00      0.00         1\n",
      "       30393       0.00      0.00      0.00         3\n",
      "       30400       0.00      0.00      0.00         0\n",
      "       30401       0.00      0.00      0.00         1\n",
      "       30420       0.00      0.00      0.00         1\n",
      "       30461       0.00      0.00      0.00         1\n",
      "       30471       0.00      0.00      0.00         1\n",
      "       30480       0.00      0.00      0.00         1\n",
      "       30500       0.00      0.00      0.00         9\n",
      "       30501       0.00      0.00      0.00         4\n",
      "       30502       0.00      0.00      0.00         1\n",
      "       30503       0.00      0.00      0.00         3\n",
      "        3051       0.04      0.07      0.05        28\n",
      "       30520       0.00      0.00      0.00         3\n",
      "       30550       0.00      0.00      0.00         1\n",
      "       30551       0.00      0.00      0.00         3\n",
      "       30560       0.00      0.00      0.00         2\n",
      "       30563       0.00      0.00      0.00         0\n",
      "       30590       0.00      0.00      0.00         2\n",
      "       30591       0.00      0.00      0.00         1\n",
      "       30593       0.00      0.00      0.00         1\n",
      "       30751       0.00      0.00      0.00         1\n",
      "       30981       0.00      0.00      0.00         5\n",
      "        3102       0.00      0.00      0.00         2\n",
      "         311       0.01      0.02      0.01        46\n",
      "       31401       0.00      0.00      0.00         0\n",
      "         319       0.00      0.00      0.00         2\n",
      "       32361       0.00      0.00      0.00         1\n",
      "        3241       0.00      0.00      0.00         0\n",
      "       32723       0.00      0.00      0.00        18\n",
      "        3310       0.00      0.00      0.00         2\n",
      "       33119       0.00      0.00      0.00         0\n",
      "       33183       0.00      0.00      0.00         1\n",
      "        3319       0.00      0.00      0.00         1\n",
      "        3321       0.00      0.00      0.00         1\n",
      "        3331       0.00      0.00      0.00         1\n",
      "       33394       0.00      0.00      0.00         3\n",
      "       33520       0.00      0.00      0.00         2\n",
      "        3369       0.00      0.00      0.00         1\n",
      "        3371       0.00      0.00      0.00         1\n",
      "        3379       0.00      0.00      0.00         1\n",
      "       33818       0.00      0.00      0.00         2\n",
      "       33829       0.00      0.00      0.00        15\n",
      "        3383       0.00      0.00      0.00         3\n",
      "        3410       0.00      0.00      0.00         1\n",
      "       34202       0.00      0.00      0.00         0\n",
      "       34290       0.00      0.00      0.00         0\n",
      "       34292       0.00      0.00      0.00         1\n",
      "        3441       0.00      0.00      0.00         3\n",
      "       34500       0.00      0.00      0.00         1\n",
      "       34510       0.00      0.00      0.00         1\n",
      "       34540       0.00      0.00      0.00         2\n",
      "       34541       0.00      0.00      0.00         3\n",
      "       34580       0.00      0.00      0.00         1\n",
      "       34581       0.00      0.00      0.00         1\n",
      "       34590       0.00      0.00      0.00         8\n",
      "       34690       0.00      0.00      0.00         9\n",
      "       34691       0.00      0.00      0.00         1\n",
      "        3481       0.00      0.00      0.00         1\n",
      "        3482       0.00      0.00      0.00         1\n",
      "       34830       0.00      0.00      0.00         1\n",
      "       34831       0.00      0.00      0.00         3\n",
      "       34839       0.00      0.00      0.00         1\n",
      "        3484       0.00      0.00      0.00         1\n",
      "        3485       0.00      0.00      0.00         5\n",
      "       34889       0.00      0.00      0.00         1\n",
      "        3490       0.00      0.00      0.00         1\n",
      "       34982       0.00      0.00      0.00         5\n",
      "        3510       0.00      0.00      0.00         2\n",
      "        3530       0.00      0.00      0.00         0\n",
      "        3541       0.00      0.00      0.00         1\n",
      "        3543       0.00      0.00      0.00         1\n",
      "        3558       0.00      0.00      0.00         1\n",
      "        3559       0.00      0.00      0.00         2\n",
      "        3569       0.00      0.00      0.00         6\n",
      "        3572       0.12      0.15      0.13        13\n",
      "        3575       0.00      0.00      0.00         1\n",
      "       35800       0.00      0.00      0.00         1\n",
      "       35801       0.00      0.00      0.00         1\n",
      "       36201       0.00      0.00      0.00         4\n",
      "       36207       0.00      0.00      0.00         1\n",
      "       36250       0.00      0.00      0.00         1\n",
      "       36274       0.00      0.00      0.00         1\n",
      "       36411       0.00      0.00      0.00         1\n",
      "       36563       0.00      0.00      0.00         1\n",
      "        3659       0.00      0.00      0.00         8\n",
      "       36616       0.00      0.00      0.00         1\n",
      "        3669       0.00      0.00      0.00         1\n",
      "        3682       0.00      0.00      0.00         1\n",
      "        3688       0.00      0.00      0.00         2\n",
      "        3689       0.00      0.00      0.00         1\n",
      "       36900       0.00      0.00      0.00         1\n",
      "        3694       0.00      0.00      0.00         5\n",
      "       36960       0.00      0.00      0.00         2\n",
      "       37230       0.00      0.00      0.00         1\n",
      "       37515       0.00      0.00      0.00         1\n",
      "       37601       0.00      0.00      0.00         0\n",
      "       37730       0.00      0.00      0.00         1\n",
      "       37941       0.00      0.00      0.00         1\n",
      "       38600       0.00      0.00      0.00         1\n",
      "       38611       0.00      0.00      0.00         1\n",
      "       38650       0.00      0.00      0.00         1\n",
      "       38910       0.00      0.00      0.00         0\n",
      "        3899       0.00      0.00      0.00         2\n",
      "        3941       0.00      0.00      0.00         1\n",
      "        3963       0.00      0.00      0.00         1\n",
      "        3968       0.00      0.00      0.00         1\n",
      "        3970       0.00      0.00      0.00         5\n",
      "       39891       0.00      0.00      0.00         2\n",
      "        4011       0.00      0.00      0.00         5\n",
      "        4019       0.04      0.19      0.07       143\n",
      "       40300       0.00      0.00      0.00         1\n",
      "       40310       0.00      0.00      0.00         2\n",
      "       40390       0.06      0.05      0.05        39\n",
      "       40391       0.00      0.00      0.00        13\n",
      "       40491       0.00      0.00      0.00         2\n",
      "       41011       0.00      0.00      0.00         0\n",
      "       41012       0.00      0.00      0.00         1\n",
      "       41041       0.00      0.00      0.00         1\n",
      "       41042       0.00      0.00      0.00         1\n",
      "       41071       0.00      0.00      0.00         7\n",
      "       41072       0.00      0.00      0.00         1\n",
      "        4110       0.00      0.00      0.00         1\n",
      "        4111       0.00      0.00      0.00         3\n",
      "       41189       0.00      0.00      0.00         1\n",
      "         412       0.00      0.00      0.00        20\n",
      "       41400       0.00      0.00      0.00        14\n",
      "       41401       0.05      0.13      0.08        45\n",
      "       41402       0.00      0.00      0.00         1\n",
      "       41412       0.00      0.00      0.00         2\n",
      "        4142       0.00      0.00      0.00         1\n",
      "        4148       0.00      0.00      0.00         5\n",
      "        4150       0.00      0.00      0.00         1\n",
      "       41511       0.00      0.00      0.00         3\n",
      "       41519       0.00      0.00      0.00         3\n",
      "        4162       0.00      0.00      0.00         1\n",
      "        4168       0.00      0.00      0.00         6\n",
      "        4210       0.00      0.00      0.00         0\n",
      "        4233       0.00      0.00      0.00         1\n",
      "        4239       0.00      0.00      0.00         1\n",
      "        4240       0.00      0.00      0.00        10\n",
      "        4241       0.00      0.00      0.00         6\n",
      "        4242       0.00      0.00      0.00         1\n",
      "        4254       0.00      0.00      0.00         5\n",
      "        4257       0.00      0.00      0.00         1\n",
      "        4258       0.00      0.00      0.00         1\n",
      "        4260       0.00      0.00      0.00         2\n",
      "       42611       0.00      0.00      0.00         3\n",
      "        4263       0.00      0.00      0.00         1\n",
      "        4264       0.00      0.00      0.00         1\n",
      "        4271       0.00      0.00      0.00         3\n",
      "       42731       0.03      0.10      0.05        42\n",
      "       42732       0.00      0.00      0.00         9\n",
      "        4275       0.00      0.00      0.00         1\n",
      "       42761       0.00      0.00      0.00         1\n",
      "       42781       0.00      0.00      0.00         1\n",
      "       42789       0.00      0.00      0.00        13\n",
      "        4280       0.03      0.08      0.04        48\n",
      "       42820       0.00      0.00      0.00         1\n",
      "       42821       0.00      0.00      0.00         1\n",
      "       42822       0.00      0.00      0.00         7\n",
      "       42823       0.00      0.00      0.00         5\n",
      "       42830       0.00      0.00      0.00         1\n",
      "       42832       0.00      0.00      0.00        15\n",
      "       42833       0.00      0.00      0.00        10\n",
      "       42842       0.00      0.00      0.00         2\n",
      "       42843       0.00      0.00      0.00         1\n",
      "        4293       0.00      0.00      0.00         1\n",
      "         430       0.00      0.00      0.00         1\n",
      "         431       0.00      0.00      0.00         2\n",
      "        4321       0.00      0.00      0.00         0\n",
      "       43310       0.00      0.00      0.00         1\n",
      "       43330       0.00      0.00      0.00         1\n",
      "       43411       0.00      0.00      0.00         3\n",
      "       43491       0.00      0.00      0.00         1\n",
      "        4358       0.00      0.00      0.00         1\n",
      "        4359       0.00      0.00      0.00         3\n",
      "        4372       0.00      0.00      0.00         1\n",
      "        4373       0.00      0.00      0.00         4\n",
      "        4380       0.00      0.00      0.00         1\n",
      "       43811       0.00      0.00      0.00         1\n",
      "       43820       0.00      0.00      0.00         1\n",
      "       43850       0.00      0.00      0.00         1\n",
      "       43883       0.00      0.00      0.00         2\n",
      "       43889       0.00      0.00      0.00         1\n",
      "        4400       0.00      0.00      0.00         1\n",
      "       44020       0.00      0.00      0.00         1\n",
      "       44021       0.00      0.00      0.00         1\n",
      "       44022       0.00      0.00      0.00         1\n",
      "       44023       0.00      0.00      0.00         1\n",
      "       44031       0.00      0.00      0.00         0\n",
      "        4412       0.00      0.00      0.00         1\n",
      "        4414       0.00      0.00      0.00         4\n",
      "        4422       0.00      0.00      0.00         0\n",
      "       44281       0.00      0.00      0.00         1\n",
      "       44289       0.00      0.00      0.00         1\n",
      "        4430       0.00      0.00      0.00         1\n",
      "       44381       0.00      0.00      0.00         1\n",
      "       44389       0.00      0.00      0.00         1\n",
      "        4439       0.00      0.00      0.00         8\n",
      "        4474       0.00      0.00      0.00         1\n",
      "        4510       0.00      0.00      0.00         1\n",
      "       45182       0.00      0.00      0.00         2\n",
      "       45184       0.00      0.00      0.00         1\n",
      "        4533       0.00      0.00      0.00         1\n",
      "       45341       0.00      0.00      0.00         3\n",
      "       45372       0.00      0.00      0.00         1\n",
      "        4538       0.00      0.00      0.00         2\n",
      "       45382       0.00      0.00      0.00         0\n",
      "       45389       0.00      0.00      0.00         1\n",
      "        4541       0.00      0.00      0.00         1\n",
      "        4550       0.00      0.00      0.00         1\n",
      "        4552       0.00      0.00      0.00         1\n",
      "        4559       0.00      0.00      0.00         1\n",
      "       45621       0.00      0.00      0.00         4\n",
      "        4568       0.00      0.00      0.00         2\n",
      "        4571       0.00      0.00      0.00         1\n",
      "        4580       0.00      0.00      0.00         2\n",
      "        4581       0.00      0.00      0.00         0\n",
      "       45829       0.00      0.00      0.00         8\n",
      "        4589       0.00      0.00      0.00         5\n",
      "        4592       0.00      0.00      0.00         1\n",
      "       45981       0.00      0.00      0.00         5\n",
      "       45989       0.00      0.00      0.00         0\n",
      "        4659       0.00      0.00      0.00         2\n",
      "        4739       0.00      0.00      0.00         1\n",
      "        4770       0.00      0.00      0.00         1\n",
      "        4778       0.00      0.00      0.00         1\n",
      "        4779       0.00      0.00      0.00         2\n",
      "       47819       0.00      0.00      0.00         1\n",
      "       47831       0.00      0.00      0.00         1\n",
      "        4785       0.00      0.00      0.00         2\n",
      "       48230       0.00      0.00      0.00         1\n",
      "       48241       0.00      0.00      0.00         1\n",
      "       48242       0.00      0.00      0.00         1\n",
      "        4829       0.00      0.00      0.00         2\n",
      "         486       0.00      0.00      0.00        14\n",
      "       49121       0.00      0.00      0.00         3\n",
      "       49122       0.00      0.00      0.00         1\n",
      "        4928       0.00      0.00      0.00         1\n",
      "       49300       0.00      0.00      0.00         1\n",
      "       49320       0.00      0.00      0.00         3\n",
      "       49322       0.00      0.00      0.00         3\n",
      "       49390       0.00      0.00      0.00        18\n",
      "       49392       0.00      0.00      0.00         2\n",
      "        4940       0.00      0.00      0.00         2\n",
      "         496       0.00      0.00      0.00        19\n",
      "         501       0.00      0.00      0.00         1\n",
      "        5070       0.00      0.00      0.00         4\n",
      "        5109       0.00      0.00      0.00         2\n",
      "       51181       0.00      0.00      0.00         2\n",
      "       51189       0.00      0.00      0.00         3\n",
      "        5119       0.00      0.00      0.00         2\n",
      "        5120       0.00      0.00      0.00         1\n",
      "        5121       0.00      0.00      0.00         0\n",
      "        5130       0.00      0.00      0.00         1\n",
      "         514       0.00      0.00      0.00         1\n",
      "         515       0.00      0.00      0.00         4\n",
      "        5180       0.00      0.00      0.00         2\n",
      "        5184       0.00      0.00      0.00         1\n",
      "       51881       0.04      0.11      0.06         9\n",
      "       51882       0.00      0.00      0.00         0\n",
      "       51883       0.00      0.00      0.00         1\n",
      "       51889       0.00      0.00      0.00         5\n",
      "       51919       0.00      0.00      0.00         0\n",
      "        5194       0.00      0.00      0.00         1\n",
      "        5225       0.00      0.00      0.00         1\n",
      "       52460       0.00      0.00      0.00         1\n",
      "        5272       0.00      0.00      0.00         1\n",
      "        5279       0.00      0.00      0.00         1\n",
      "       52801       0.00      0.00      0.00         1\n",
      "       53011       0.00      0.00      0.00         1\n",
      "       53019       0.00      0.00      0.00         2\n",
      "       53020       0.00      0.00      0.00         1\n",
      "       53081       0.00      0.02      0.01        59\n",
      "       53084       0.00      0.00      0.00         1\n",
      "       53085       0.00      0.00      0.00         0\n",
      "       53140       0.00      0.00      0.00         1\n",
      "       53190       0.00      0.00      0.00         1\n",
      "       53240       0.00      0.00      0.00         1\n",
      "       53290       0.00      0.00      0.00         1\n",
      "       53540       0.00      0.00      0.00         2\n",
      "       53550       0.00      0.00      0.00         3\n",
      "       53560       0.00      0.00      0.00         2\n",
      "        5363       0.00      0.00      0.00         2\n",
      "       53782       0.00      0.00      0.00         1\n",
      "       53789       0.00      0.00      0.00         1\n",
      "        5401       0.00      0.00      0.00         1\n",
      "        5409       0.00      0.00      0.00         3\n",
      "        5439       0.00      0.00      0.00         1\n",
      "       55090       0.00      0.00      0.00         1\n",
      "        5531       0.00      0.00      0.00         1\n",
      "       55320       0.00      0.00      0.00         1\n",
      "       55321       0.00      0.00      0.00         4\n",
      "        5533       0.00      0.00      0.00         9\n",
      "        5550       0.00      0.00      0.00         1\n",
      "        5551       0.00      0.00      0.00         2\n",
      "        5559       0.00      0.00      0.00         1\n",
      "        5566       0.00      0.00      0.00         1\n",
      "        5569       0.00      0.00      0.00         4\n",
      "        5570       0.00      0.00      0.00         1\n",
      "        5589       0.00      0.00      0.00         1\n",
      "        5601       0.00      0.00      0.00         1\n",
      "       56081       0.00      0.00      0.00         1\n",
      "       56089       0.00      0.00      0.00         1\n",
      "        5609       0.00      0.00      0.00         3\n",
      "       56210       0.00      0.00      0.00         6\n",
      "       56400       0.00      0.00      0.00         8\n",
      "       56409       0.00      0.00      0.00         5\n",
      "        5641       0.00      0.00      0.00         4\n",
      "        5651       0.00      0.00      0.00         1\n",
      "         566       0.00      0.00      0.00         1\n",
      "       56723       0.00      0.00      0.00         1\n",
      "       56729       0.00      0.00      0.00         1\n",
      "        5680       0.00      0.00      0.00         3\n",
      "       56881       0.00      0.00      0.00         2\n",
      "       56969       0.00      0.00      0.00         1\n",
      "       56981       0.00      0.00      0.00         1\n",
      "       56984       0.00      0.00      0.00         0\n",
      "       56989       0.00      0.00      0.00         1\n",
      "         570       0.00      0.00      0.00         1\n",
      "        5712       0.12      0.20      0.15         5\n",
      "        5715       0.00      0.00      0.00         2\n",
      "        5716       0.00      0.00      0.00         1\n",
      "        5718       0.00      0.00      0.00         4\n",
      "        5720       0.00      0.00      0.00         2\n",
      "        5722       0.00      0.00      0.00         2\n",
      "        5723       0.00      0.00      0.00         2\n",
      "        5724       0.00      0.00      0.00         1\n",
      "        5733       0.00      0.00      0.00         2\n",
      "        5738       0.00      0.00      0.00         3\n",
      "        5739       0.00      0.00      0.00         1\n",
      "       57400       0.00      0.00      0.00         0\n",
      "       57410       0.00      0.00      0.00         1\n",
      "       57420       0.00      0.00      0.00         2\n",
      "       57450       0.00      0.00      0.00         1\n",
      "       57451       0.00      0.00      0.00         2\n",
      "       57471       0.00      0.00      0.00         1\n",
      "       57490       0.00      0.00      0.00         1\n",
      "        5758       0.00      0.00      0.00         1\n",
      "        5761       0.00      0.00      0.00         3\n",
      "        5762       0.00      0.00      0.00         4\n",
      "        5770       0.00      0.00      0.00         4\n",
      "        5771       0.09      0.14      0.11         7\n",
      "        5772       0.00      0.00      0.00         2\n",
      "        5778       0.00      0.00      0.00         2\n",
      "        5779       0.00      0.00      0.00         1\n",
      "        5781       0.00      0.00      0.00         3\n",
      "        5789       0.00      0.00      0.00         2\n",
      "        5790       0.00      0.00      0.00         2\n",
      "       58081       0.00      0.00      0.00         1\n",
      "       58089       0.00      0.00      0.00         1\n",
      "        5830       0.00      0.00      0.00         1\n",
      "       58381       0.00      0.00      0.00         4\n",
      "       58389       0.00      0.00      0.00         1\n",
      "        5845       0.00      0.00      0.00         6\n",
      "        5849       0.06      0.11      0.07        47\n",
      "        5852       0.00      0.00      0.00         3\n",
      "        5853       0.00      0.00      0.00         7\n",
      "        5854       0.00      0.00      0.00         1\n",
      "        5855       0.00      0.00      0.00         1\n",
      "        5856       0.08      0.08      0.08        12\n",
      "        5859       0.00      0.00      0.00        26\n",
      "       58881       0.00      0.00      0.00         1\n",
      "         591       0.00      0.00      0.00         4\n",
      "        5920       0.00      0.00      0.00         2\n",
      "        5934       0.00      0.00      0.00         1\n",
      "        5939       0.00      0.00      0.00         1\n",
      "        5960       0.00      0.00      0.00         2\n",
      "        5964       0.00      0.00      0.00         1\n",
      "       59651       0.00      0.00      0.00         1\n",
      "       59654       0.00      0.00      0.00         2\n",
      "       59659       0.00      0.00      0.00         1\n",
      "        5990       0.03      0.07      0.04        29\n",
      "       59970       0.00      0.00      0.00         2\n",
      "       59971       0.00      0.00      0.00         2\n",
      "       60000       0.00      0.00      0.00        15\n",
      "       60001       0.00      0.00      0.00         7\n",
      "         605       0.00      0.00      0.00         1\n",
      "       60783       0.00      0.00      0.00         1\n",
      "       61172       0.00      0.00      0.00         2\n",
      "        6150       0.00      0.00      0.00         1\n",
      "       61610       0.00      0.00      0.00         1\n",
      "        6171       0.00      0.00      0.00         1\n",
      "        6178       0.00      0.00      0.00         1\n",
      "       61804       0.00      0.00      0.00         0\n",
      "        6210       0.00      0.00      0.00         1\n",
      "        6238       0.00      0.00      0.00         1\n",
      "        6253       0.00      0.00      0.00         1\n",
      "        6262       0.00      0.00      0.00         1\n",
      "       63310       0.00      0.00      0.00         0\n",
      "        6390       0.00      0.00      0.00         1\n",
      "       64681       0.00      0.00      0.00         1\n",
      "       64841       0.00      0.00      0.00         1\n",
      "       64892       0.00      0.00      0.00         1\n",
      "       64893       1.00      1.00      1.00         1\n",
      "       64913       0.00      0.00      0.00         2\n",
      "       65101       0.00      0.00      0.00         1\n",
      "       65421       0.00      0.00      0.00         1\n",
      "       65441       0.00      0.00      0.00         0\n",
      "       65583       0.00      0.00      0.00         1\n",
      "       65971       0.00      0.00      0.00         1\n",
      "       66331       0.00      0.00      0.00         2\n",
      "       66411       0.00      0.00      0.00         1\n",
      "       66712       0.00      0.00      0.00         1\n",
      "       66982       0.00      0.00      0.00         1\n",
      "       67014       0.00      0.00      0.00         1\n",
      "        6803       0.00      0.00      0.00         1\n",
      "        6820       0.00      0.00      0.00         1\n",
      "        6822       0.00      0.00      0.00         2\n",
      "        6824       0.00      0.00      0.00         1\n",
      "        6826       0.00      0.00      0.00         5\n",
      "       68601       0.00      0.00      0.00         2\n",
      "        6929       0.00      0.00      0.00         2\n",
      "        6930       0.00      0.00      0.00         1\n",
      "        6960       0.00      0.00      0.00         1\n",
      "        6961       0.00      0.00      0.00         4\n",
      "        6988       0.00      0.00      0.00         1\n",
      "        7020       0.00      0.00      0.00         1\n",
      "       70583       0.00      0.00      0.00         1\n",
      "       70703       0.00      0.00      0.00         4\n",
      "       70707       0.00      0.00      0.00         2\n",
      "       70711       0.00      0.00      0.00         1\n",
      "       70715       0.25      0.17      0.20         6\n",
      "       70719       0.00      0.00      0.00         2\n",
      "       70720       0.00      0.00      0.00         1\n",
      "       70721       0.00      0.00      0.00         3\n",
      "       70722       0.00      0.00      0.00         4\n",
      "       70724       0.00      0.00      0.00         2\n",
      "       70725       0.00      0.00      0.00         1\n",
      "        7078       0.00      0.00      0.00         1\n",
      "        7099       0.00      0.00      0.00         1\n",
      "        7100       0.00      0.00      0.00         0\n",
      "        7101       0.00      0.00      0.00         1\n",
      "        7131       0.00      0.00      0.00         1\n",
      "        7140       0.00      0.00      0.00         2\n",
      "       71481       0.00      0.00      0.00         1\n",
      "       71534       0.00      0.00      0.00         1\n",
      "       71535       0.00      0.00      0.00         2\n",
      "       71536       0.00      0.00      0.00         8\n",
      "       71590       0.00      0.00      0.00         8\n",
      "       71595       0.00      0.00      0.00         2\n",
      "       71596       0.00      0.00      0.00         1\n",
      "       71690       0.00      0.00      0.00         2\n",
      "       71847       0.00      0.00      0.00         1\n",
      "       71885       0.00      0.00      0.00         1\n",
      "       71906       0.00      0.00      0.00         2\n",
      "       71941       0.00      0.00      0.00         1\n",
      "       71942       0.00      0.00      0.00         1\n",
      "       71943       0.00      0.00      0.00         1\n",
      "       71945       0.00      0.00      0.00         4\n",
      "       71946       0.00      0.00      0.00         3\n",
      "       71947       0.00      0.00      0.00         1\n",
      "        7197       0.00      0.00      0.00         1\n",
      "        7210       0.00      0.00      0.00         1\n",
      "        7212       0.00      0.00      0.00         1\n",
      "        7213       0.00      0.00      0.00         2\n",
      "       72190       0.00      0.00      0.00         1\n",
      "       72210       0.00      0.00      0.00         2\n",
      "        7226       0.00      0.00      0.00         2\n",
      "        7231       0.00      0.00      0.00         1\n",
      "        7234       0.00      0.00      0.00         0\n",
      "       72400       0.00      0.00      0.00         2\n",
      "       72402       0.00      0.00      0.00         1\n",
      "        7242       0.00      0.00      0.00         6\n",
      "        7243       0.00      0.00      0.00         1\n",
      "        7245       0.00      0.00      0.00         6\n",
      "        7246       0.00      0.00      0.00         1\n",
      "         725       0.00      0.00      0.00         1\n",
      "       72610       0.00      0.00      0.00         1\n",
      "       72665       0.00      0.00      0.00         1\n",
      "       72690       0.00      0.00      0.00         1\n",
      "       72741       0.00      0.00      0.00         1\n",
      "        7280       0.00      0.00      0.00         1\n",
      "       72885       0.00      0.00      0.00         1\n",
      "       72888       0.00      0.00      0.00         2\n",
      "       72889       0.00      0.00      0.00         3\n",
      "        7291       0.00      0.00      0.00        10\n",
      "        7295       0.00      0.00      0.00         7\n",
      "       72989       0.00      0.00      0.00         6\n",
      "       72992       0.00      0.00      0.00         1\n",
      "       73007       0.00      0.00      0.00         1\n",
      "       73018       0.00      0.00      0.00         1\n",
      "       73027       0.00      0.00      0.00         1\n",
      "       73028       0.00      0.00      0.00         0\n",
      "        7318       0.00      0.00      0.00         0\n",
      "       73300       0.00      0.00      0.00        22\n",
      "       73313       0.00      0.00      0.00         3\n",
      "       73349       0.00      0.00      0.00         1\n",
      "       73382       0.00      0.00      0.00         1\n",
      "       73390       0.00      0.00      0.00        11\n",
      "       73679       0.00      0.00      0.00         1\n",
      "       73730       0.00      0.00      0.00         3\n",
      "        7464       0.00      0.00      0.00         1\n",
      "       74761       0.00      0.00      0.00         1\n",
      "       74769       0.00      0.00      0.00         1\n",
      "       75612       0.00      0.00      0.00         0\n",
      "        7587       0.00      0.00      0.00         1\n",
      "       75989       0.00      0.00      0.00         1\n",
      "       78009       0.00      0.00      0.00         3\n",
      "        7802       0.00      0.00      0.00         7\n",
      "       78039       0.00      0.00      0.00         3\n",
      "        7804       0.00      0.00      0.00         4\n",
      "       78052       0.00      0.00      0.00         8\n",
      "       78057       0.00      0.00      0.00         2\n",
      "       78060       0.00      0.00      0.00         6\n",
      "       78061       0.00      0.00      0.00         3\n",
      "       78062       0.00      0.00      0.00         2\n",
      "       78064       0.00      0.00      0.00         1\n",
      "       78079       0.00      0.00      0.00         6\n",
      "       78093       0.00      0.00      0.00         1\n",
      "       78097       0.00      0.00      0.00         4\n",
      "        7810       0.00      0.00      0.00         2\n",
      "        7812       0.00      0.00      0.00         3\n",
      "        7818       0.00      0.00      0.00         0\n",
      "       78194       0.00      0.00      0.00         1\n",
      "        7820       0.00      0.00      0.00         0\n",
      "        7821       0.00      0.00      0.00         1\n",
      "        7822       0.00      0.00      0.00         1\n",
      "        7823       0.00      0.00      0.00         1\n",
      "        7824       0.00      0.00      0.00         2\n",
      "       78321       0.00      0.00      0.00         4\n",
      "        7837       0.00      0.00      0.00         4\n",
      "        7840       0.00      0.00      0.00         6\n",
      "        7843       0.00      0.00      0.00         1\n",
      "       78459       0.00      0.00      0.00         1\n",
      "        7847       0.00      0.00      0.00         3\n",
      "       78492       0.00      0.00      0.00         1\n",
      "        7850       0.00      0.00      0.00         6\n",
      "        7854       0.00      0.00      0.00         2\n",
      "       78550       0.00      0.00      0.00         1\n",
      "       78551       0.00      0.00      0.00         3\n",
      "       78552       0.00      0.00      0.00         3\n",
      "       78559       0.00      0.00      0.00         1\n",
      "        7856       0.00      0.00      0.00         4\n",
      "       78603       0.00      0.00      0.00         1\n",
      "       78604       0.00      0.00      0.00         0\n",
      "       78605       0.00      0.00      0.00         1\n",
      "       78606       0.00      0.00      0.00         1\n",
      "       78609       0.00      0.00      0.00         3\n",
      "        7862       0.00      0.00      0.00         1\n",
      "       78650       0.00      0.00      0.00         5\n",
      "       78651       0.00      0.00      0.00         1\n",
      "       78659       0.00      0.00      0.00         8\n",
      "        7866       0.00      0.00      0.00         0\n",
      "        7869       0.00      0.00      0.00         1\n",
      "       78701       0.00      0.00      0.00         7\n",
      "       78720       0.00      0.00      0.00         1\n",
      "       78729       0.00      0.00      0.00         3\n",
      "        7873       0.00      0.00      0.00         1\n",
      "        7876       0.00      0.00      0.00         1\n",
      "       78760       0.00      0.00      0.00         1\n",
      "       78791       0.00      0.00      0.00        12\n",
      "       78820       0.00      0.00      0.00         9\n",
      "       78821       0.00      0.00      0.00         1\n",
      "       78829       0.00      0.00      0.00         1\n",
      "       78830       0.00      0.00      0.00         9\n",
      "       78832       0.00      0.00      0.00         1\n",
      "        7885       0.00      0.00      0.00         1\n",
      "       78900       0.00      0.00      0.00         3\n",
      "       78902       0.00      0.00      0.00         2\n",
      "       78904       0.00      0.00      0.00         1\n",
      "       78906       0.00      0.00      0.00         5\n",
      "       78907       0.00      0.00      0.00         2\n",
      "       78909       0.00      0.00      0.00         4\n",
      "       78959       0.00      0.00      0.00         9\n",
      "       79001       0.00      0.00      0.00         1\n",
      "       79029       0.00      0.00      0.00         5\n",
      "        7904       0.00      0.00      0.00         1\n",
      "        7906       0.00      0.00      0.00         3\n",
      "        7907       0.00      0.00      0.00         7\n",
      "       79092       0.00      0.00      0.00         6\n",
      "       79099       0.00      0.00      0.00         1\n",
      "        7910       0.00      0.00      0.00         1\n",
      "        7919       0.00      0.00      0.00         1\n",
      "        7921       0.00      0.00      0.00         1\n",
      "        7931       0.00      0.00      0.00         1\n",
      "       79311       0.00      0.00      0.00         2\n",
      "       79319       0.00      0.00      0.00         3\n",
      "        7955       0.00      0.00      0.00         1\n",
      "       79551       0.00      0.00      0.00         0\n",
      "        7961       0.00      0.00      0.00         1\n",
      "        7962       0.00      0.00      0.00         2\n",
      "       79902       0.00      0.00      0.00        11\n",
      "        7994       0.00      0.00      0.00         2\n",
      "       80025       0.00      0.00      0.00         2\n",
      "       80125       0.00      0.00      0.00         1\n",
      "       80126       0.00      0.00      0.00         1\n",
      "        8020       0.00      0.00      0.00         3\n",
      "       80228       0.00      0.00      0.00         1\n",
      "       80238       0.00      0.00      0.00         1\n",
      "        8028       0.00      0.00      0.00         1\n",
      "       80326       0.00      0.00      0.00         1\n",
      "       80502       0.00      0.00      0.00         1\n",
      "        8052       0.00      0.00      0.00         1\n",
      "        8054       0.00      0.00      0.00         1\n",
      "        8056       0.00      0.00      0.00         1\n",
      "       80701       0.00      0.00      0.00         2\n",
      "       80703       0.00      0.00      0.00         2\n",
      "       80704       0.00      0.00      0.00         1\n",
      "       80705       0.00      0.00      0.00         1\n",
      "        8080       0.00      0.00      0.00         1\n",
      "        8082       0.00      0.00      0.00         1\n",
      "       80841       0.00      0.00      0.00         1\n",
      "       81323       0.00      0.00      0.00         0\n",
      "       81342       0.00      0.00      0.00         1\n",
      "       81612       0.00      0.00      0.00         1\n",
      "       82021       0.00      0.00      0.00         2\n",
      "       82022       0.00      0.00      0.00         1\n",
      "        8208       0.00      0.00      0.00         1\n",
      "       82101       0.00      0.00      0.00         1\n",
      "       82121       0.00      0.00      0.00         1\n",
      "       82130       0.00      0.00      0.00         1\n",
      "        8242       0.00      0.00      0.00         3\n",
      "        8248       0.00      0.00      0.00         1\n",
      "        8470       0.00      0.00      0.00         1\n",
      "       85102       0.00      0.00      0.00         0\n",
      "       85182       0.00      0.00      0.00         1\n",
      "       85185       0.00      0.00      0.00         1\n",
      "       85206       0.00      0.00      0.00         1\n",
      "       85221       0.00      0.00      0.00         1\n",
      "        8600       0.00      0.00      0.00         1\n",
      "       86389       0.00      0.00      0.00         1\n",
      "       86403       0.00      0.00      0.00         1\n",
      "       86405       0.00      0.00      0.00         1\n",
      "       86502       0.00      0.00      0.00         1\n",
      "        8730       0.00      0.00      0.00         2\n",
      "       87320       0.00      0.00      0.00         1\n",
      "       87342       0.00      0.00      0.00         2\n",
      "       87364       0.00      0.00      0.00         1\n",
      "        8821       0.00      0.00      0.00         2\n",
      "        8911       0.00      0.00      0.00         1\n",
      "        9092       0.00      0.00      0.00         1\n",
      "        9100       0.00      0.00      0.00         2\n",
      "        9110       0.00      0.00      0.00         0\n",
      "         920       0.00      0.00      0.00         1\n",
      "       92303       0.00      0.00      0.00         1\n",
      "       92410       0.00      0.00      0.00         1\n",
      "        9349       0.00      0.00      0.00         1\n",
      "       95203       0.00      0.00      0.00         1\n",
      "       95208       0.00      0.00      0.00         1\n",
      "       96509       0.00      0.00      0.00         2\n",
      "        9694       0.00      0.00      0.00         1\n",
      "       99592       0.00      0.00      0.00         5\n",
      "       99601       0.00      0.00      0.00         1\n",
      "       99602       0.00      0.00      0.00         1\n",
      "       99639       0.00      0.00      0.00         2\n",
      "       99662       0.00      0.00      0.00         1\n",
      "       99664       0.00      0.00      0.00         1\n",
      "       99667       0.00      0.00      0.00         3\n",
      "       99672       0.00      0.00      0.00         1\n",
      "       99674       0.00      0.00      0.00         1\n",
      "       99677       0.00      0.00      0.00         1\n",
      "       99681       0.00      0.00      0.00         4\n",
      "       99685       0.00      0.00      0.00         2\n",
      "       99702       0.00      0.00      0.00         1\n",
      "        9971       0.00      0.00      0.00         6\n",
      "       99731       0.00      0.00      0.00         1\n",
      "       99739       0.00      0.00      0.00         1\n",
      "        9974       0.00      0.00      0.00         4\n",
      "       99749       0.00      0.00      0.00         2\n",
      "        9975       0.00      0.00      0.00         2\n",
      "       99811       0.00      0.00      0.00         5\n",
      "       99812       0.00      0.00      0.00         2\n",
      "       99813       0.00      0.00      0.00         2\n",
      "       99832       0.00      0.00      0.00         0\n",
      "       99859       0.00      0.00      0.00         5\n",
      "       99881       0.00      0.00      0.00         1\n",
      "       99883       0.00      0.00      0.00         2\n",
      "       99889       0.00      0.00      0.00         1\n",
      "       99931       0.00      0.00      0.00         1\n",
      "        A047       0.00      0.00      0.00         3\n",
      "       A0472       0.00      0.00      0.00         3\n",
      "        A084       0.00      0.00      0.00         1\n",
      "        A401       0.00      0.00      0.00         1\n",
      "       A4101       0.00      0.00      0.00         3\n",
      "       A4151       0.00      0.00      0.00         3\n",
      "       A4152       0.00      0.00      0.00         2\n",
      "       A4181       0.00      0.00      0.00         1\n",
      "       A4189       0.00      0.00      0.00         1\n",
      "        A419       0.00      0.00      0.00         5\n",
      "       B0229       0.00      0.00      0.00         1\n",
      "        B027       0.00      0.00      0.00         1\n",
      "        B028       0.00      0.00      0.00         1\n",
      "       B1081       0.00      0.00      0.00         1\n",
      "        B182       0.00      0.00      0.00         1\n",
      "       B1910       0.00      0.00      0.00         3\n",
      "       B1920       0.00      0.00      0.00         3\n",
      "         B20       0.00      0.00      0.00         3\n",
      "        B259       0.00      0.00      0.00         1\n",
      "        B350       0.00      0.00      0.00         1\n",
      "        B356       0.00      0.00      0.00         1\n",
      "        B370       0.00      0.00      0.00         1\n",
      "       B3781       0.00      0.00      0.00         1\n",
      "       B3789       0.00      0.00      0.00         1\n",
      "        B589       0.00      0.00      0.00         1\n",
      "        B951       0.00      0.00      0.00         1\n",
      "        B952       0.00      0.00      0.00         4\n",
      "        B954       0.00      0.00      0.00         1\n",
      "       B9561       0.00      0.00      0.00         1\n",
      "       B9562       0.00      0.00      0.00         1\n",
      "        B957       0.00      0.00      0.00         2\n",
      "        B961       0.00      0.00      0.00         2\n",
      "       B9620       0.00      0.00      0.00         4\n",
      "        B964       0.00      0.00      0.00         2\n",
      "       B9681       0.00      0.00      0.00         1\n",
      "       B9689       0.00      0.00      0.00         2\n",
      "        C169       0.00      0.00      0.00         1\n",
      "        C180       0.00      0.00      0.00         0\n",
      "        C187       0.00      0.00      0.00         2\n",
      "         C19       0.00      0.00      0.00         1\n",
      "         C20       0.00      0.00      0.00         1\n",
      "        C220       0.00      0.00      0.00         0\n",
      "        C252       0.00      0.00      0.00         1\n",
      "        C258       0.00      0.00      0.00         1\n",
      "       C3412       0.00      0.00      0.00         1\n",
      "       C3481       0.00      0.00      0.00         1\n",
      "       C3490       0.00      0.00      0.00         1\n",
      "         C37       0.00      0.00      0.00         1\n",
      "       C4339       0.00      0.00      0.00         1\n",
      "      C50911       0.00      0.00      0.00         1\n",
      "      C50912       0.00      0.00      0.00         1\n",
      "         C61       0.00      0.00      0.00         1\n",
      "        C642       0.00      0.00      0.00         1\n",
      "        C679       0.00      0.00      0.00         1\n",
      "        C710       0.00      0.00      0.00         1\n",
      "         C73       0.00      0.00      0.00         1\n",
      "        C771       0.00      0.00      0.00         1\n",
      "        C772       0.00      0.00      0.00         1\n",
      "        C779       0.00      0.00      0.00         1\n",
      "       C7800       0.00      0.00      0.00         1\n",
      "       C7801       0.00      0.00      0.00         0\n",
      "        C782       0.00      0.00      0.00         1\n",
      "       C7839       0.00      0.00      0.00         1\n",
      "        C784       0.00      0.00      0.00         1\n",
      "        C786       0.00      0.00      0.00         1\n",
      "        C787       0.00      0.00      0.00         1\n",
      "       C7889       0.00      0.00      0.00         1\n",
      "       C7931       0.00      0.00      0.00         0\n",
      "       C7949       0.00      0.00      0.00         1\n",
      "       C7951       0.00      0.00      0.00         2\n",
      "       C7960       0.00      0.00      0.00         1\n",
      "       C7970       0.00      0.00      0.00         1\n",
      "       C7982       0.00      0.00      0.00         1\n",
      "       C7989       0.00      0.00      0.00         2\n",
      "        C799       0.00      0.00      0.00         1\n",
      "       C8338       0.00      0.00      0.00         1\n",
      "       C8599       0.00      0.00      0.00         1\n",
      "       C9000       0.00      0.00      0.00         3\n",
      "       C9200       0.00      0.00      0.00         1\n",
      "        D124       0.00      0.00      0.00         1\n",
      "        D259       0.00      0.00      0.00         1\n",
      "        D320       0.00      0.00      0.00         1\n",
      "        D421       0.00      0.00      0.00         1\n",
      "       D4410       0.00      0.00      0.00         1\n",
      "        D469       0.00      0.00      0.00         3\n",
      "        D472       0.00      0.00      0.00         2\n",
      "        D473       0.00      0.00      0.00         3\n",
      "        D500       0.00      0.00      0.00         2\n",
      "        D509       0.00      0.00      0.00         8\n",
      "        D519       0.00      0.00      0.00         1\n",
      "        D539       0.00      0.00      0.00         3\n",
      "        D591       0.00      0.00      0.00         1\n",
      "        D592       0.00      0.00      0.00         1\n",
      "      D61818       0.00      0.00      0.00         2\n",
      "         D62       0.00      0.00      0.00        16\n",
      "        D630       0.00      0.00      0.00         2\n",
      "        D631       0.00      0.00      0.00         6\n",
      "        D638       0.00      0.00      0.00         4\n",
      "       D6481       0.00      0.00      0.00         3\n",
      "       D6489       0.00      0.00      0.00         1\n",
      "        D649       0.00      0.00      0.00        19\n",
      "         D65       0.00      0.00      0.00         1\n",
      "        D680       0.00      0.00      0.00         2\n",
      "        D682       0.00      0.00      0.00         1\n",
      "       D6832       0.00      0.00      0.00         1\n",
      "        D684       0.00      0.00      0.00         1\n",
      "       D6851       0.00      0.00      0.00         1\n",
      "       D6861       0.00      0.00      0.00         1\n",
      "        D689       0.00      0.00      0.00         7\n",
      "       D6959       0.00      0.00      0.00         9\n",
      "        D696       0.00      0.00      0.00         7\n",
      "        D701       0.00      0.00      0.00         1\n",
      "        D702       0.00      0.00      0.00         1\n",
      "        D708       0.00      0.00      0.00         1\n",
      "        D709       0.00      0.00      0.00         1\n",
      "      D72820       0.00      0.00      0.00         1\n",
      "      D72828       0.00      0.00      0.00         1\n",
      "      D72829       0.00      0.00      0.00         5\n",
      "        D751       0.00      0.00      0.00         1\n",
      "        D801       0.00      0.00      0.00         1\n",
      "        D803       0.00      0.00      0.00         1\n",
      "        D869       0.00      0.00      0.00         1\n",
      "      D89810       0.00      0.00      0.00         0\n",
      "      D89811       0.00      0.00      0.00         1\n",
      "       E0009       0.00      0.00      0.00         0\n",
      "        E038       0.00      0.00      0.00         1\n",
      "        E039       0.00      0.00      0.00        21\n",
      "        E042       0.00      0.00      0.00         1\n",
      "       E0500       0.00      0.00      0.00         1\n",
      "       E1022       0.00      0.00      0.00         1\n",
      "      E10319       0.00      0.00      0.00         2\n",
      "     E103592       0.00      0.00      0.00         1\n",
      "       E1040       0.00      0.00      0.00         1\n",
      "       E1042       0.00      0.00      0.00         1\n",
      "       E1043       0.00      0.00      0.00         2\n",
      "      E10610       0.00      0.00      0.00         1\n",
      "      E10649       0.00      0.00      0.00         1\n",
      "       E1065       0.00      0.00      0.00         0\n",
      "       E1121       0.00      0.00      0.00         3\n",
      "       E1122       0.00      0.00      0.00        13\n",
      "      E11319       0.00      0.00      0.00         4\n",
      "       E1136       0.00      0.00      0.00         1\n",
      "       E1140       0.00      0.00      0.00         6\n",
      "       E1142       0.00      0.00      0.00         1\n",
      "       E1151       0.00      0.00      0.00         3\n",
      "       E1152       0.00      0.00      0.00         3\n",
      "      E11610       0.00      0.00      0.00         1\n",
      "      E11621       0.00      0.00      0.00         2\n",
      "      E11649       0.00      0.00      0.00         2\n",
      "       E1165       0.00      0.00      0.00         6\n",
      "       E1169       0.00      0.00      0.00         3\n",
      "        E118       0.00      0.00      0.00         2\n",
      "        E119       0.00      0.00      0.00        18\n",
      "        E213       0.00      0.00      0.00         1\n",
      "        E222       0.00      0.00      0.00         1\n",
      "        E232       0.00      0.00      0.00         1\n",
      "       E2740       0.00      0.00      0.00         2\n",
      "        E291       0.00      0.00      0.00         1\n",
      "         E43       0.00      0.00      0.00         7\n",
      "        E440       0.00      0.00      0.00         4\n",
      "         E46       0.00      0.00      0.00         3\n",
      "        E538       0.00      0.00      0.00         1\n",
      "        E559       0.00      0.00      0.00         2\n",
      "       E6601       0.00      0.00      0.00         8\n",
      "        E662       0.00      0.00      0.00         1\n",
      "        E669       0.00      0.00      0.00        12\n",
      "      E70331       0.00      0.00      0.00         1\n",
      "        E780       0.00      0.00      0.00         4\n",
      "       E7800       0.00      0.00      0.00         6\n",
      "        E781       0.00      0.00      0.00         1\n",
      "       E7849       0.00      0.00      0.00         1\n",
      "        E785       0.03      0.11      0.04        72\n",
      "        E806       0.00      0.00      0.00         2\n",
      "       E8120       0.00      0.00      0.00         1\n",
      "       E8147       0.00      0.00      0.00         0\n",
      "       E8160       0.00      0.00      0.00         1\n",
      "       E8261       0.00      0.00      0.00         1\n",
      "       E8339       0.00      0.00      0.00         5\n",
      "       E8342       0.00      0.00      0.00         4\n",
      "       E8351       0.00      0.00      0.00         2\n",
      "       E8352       0.00      0.00      0.00         1\n",
      "       E8359       0.00      0.00      0.00         1\n",
      "        E849       0.00      0.00      0.00         1\n",
      "       E8490       0.00      0.00      0.00         4\n",
      "       E8495       0.00      0.00      0.00         0\n",
      "       E8497       0.00      0.00      0.00        11\n",
      "       E8499       0.00      0.00      0.00         5\n",
      "       E8504       0.00      0.00      0.00         1\n",
      "        E851       0.00      0.00      0.00         1\n",
      "        E854       0.00      0.00      0.00         2\n",
      "        E860       0.00      0.00      0.00         8\n",
      "        E861       0.00      0.00      0.00         4\n",
      "        E870       0.00      0.00      0.00         8\n",
      "        E871       0.00      0.00      0.00        14\n",
      "        E872       0.00      0.00      0.00        16\n",
      "        E873       0.00      0.00      0.00         2\n",
      "        E875       0.00      0.00      0.00         8\n",
      "        E876       0.00      0.00      0.00         5\n",
      "       E8770       0.00      0.00      0.00         2\n",
      "        E878       0.00      0.00      0.00         2\n",
      "       E8780       0.00      0.00      0.00         2\n",
      "       E8781       0.00      0.00      0.00         5\n",
      "       E8782       0.00      0.00      0.00         4\n",
      "       E8783       0.00      0.00      0.00         2\n",
      "       E8784       0.00      0.00      0.00         1\n",
      "       E8785       0.00      0.00      0.00         1\n",
      "       E8786       0.00      0.00      0.00         4\n",
      "       E8788       0.00      0.00      0.00         4\n",
      "       E8790       0.00      0.00      0.00         1\n",
      "       E8791       0.00      0.00      0.00         2\n",
      "       E8792       0.00      0.00      0.00         1\n",
      "       E8794       0.00      0.00      0.00         1\n",
      "       E8796       0.00      0.00      0.00         1\n",
      "       E8797       0.00      0.00      0.00         1\n",
      "       E8798       0.00      0.00      0.00         5\n",
      "       E8801       0.00      0.00      0.00         0\n",
      "       E8809       0.00      0.00      0.00         4\n",
      "       E8810       0.00      0.00      0.00         1\n",
      "        E882       0.00      0.00      0.00         3\n",
      "       E8842       0.00      0.00      0.00         1\n",
      "       E8844       0.00      0.00      0.00         1\n",
      "       E8846       0.00      0.00      0.00         1\n",
      "       E8849       0.00      0.00      0.00         2\n",
      "       E8859       0.00      0.00      0.00         5\n",
      "        E887       0.00      0.00      0.00         1\n",
      "       E8888       0.00      0.00      0.00         1\n",
      "       E8889       0.00      0.00      0.00         3\n",
      "        E890       0.00      0.00      0.00         1\n",
      "        E891       0.00      0.00      0.00         1\n",
      "        E892       0.00      0.00      0.00         0\n",
      "       E9060       0.00      0.00      0.00         1\n",
      "        E912       0.00      0.00      0.00         1\n",
      "       E9289       0.00      0.00      0.00         4\n",
      "       E9293       0.00      0.00      0.00         1\n",
      "       E9295       0.00      0.00      0.00         1\n",
      "       E9308       0.00      0.00      0.00         3\n",
      "       E9317       0.00      0.00      0.00         1\n",
      "       E9320       0.00      0.00      0.00         1\n",
      "       E9329       0.00      0.00      0.00         1\n",
      "       E9331       0.00      0.00      0.00         6\n",
      "       E9342       0.00      0.00      0.00         2\n",
      "       E9352       0.00      0.00      0.00         1\n",
      "       E9358       0.00      0.00      0.00         1\n",
      "       E9359       0.00      0.00      0.00         1\n",
      "       E9361       0.00      0.00      0.00         1\n",
      "       E9384       0.00      0.00      0.00         2\n",
      "       E9393       0.00      0.00      0.00         1\n",
      "       E9394       0.00      0.00      0.00         0\n",
      "       E9398       0.00      0.00      0.00         1\n",
      "       E9413       0.00      0.00      0.00         1\n",
      "       E9420       0.00      0.00      0.00         1\n",
      "       E9425       0.00      0.00      0.00         0\n",
      "       E9430       0.00      0.00      0.00         1\n",
      "       E9443       0.00      0.00      0.00         1\n",
      "       E9444       0.00      0.00      0.00         2\n",
      "       E9478       0.00      0.00      0.00         2\n",
      "       E9500       0.00      0.00      0.00         0\n",
      "       E9504       0.00      0.00      0.00         1\n",
      "       E9600       0.00      0.00      0.00         1\n",
      "        E966       0.00      0.00      0.00         1\n",
      "       F0280       0.00      0.00      0.00         2\n",
      "       F0281       0.00      0.00      0.00         1\n",
      "       F0390       0.00      0.00      0.00         1\n",
      "         F05       0.00      0.00      0.00         2\n",
      "       F1010       0.00      0.00      0.00         2\n",
      "       F1011       0.00      0.00      0.00         3\n",
      "      F10188       0.00      0.00      0.00         1\n",
      "       F1021       0.00      0.00      0.00         1\n",
      "      F10239       0.00      0.00      0.00         2\n",
      "       F1110       0.00      0.00      0.00         1\n",
      "       F1120       0.00      0.00      0.00         3\n",
      "       F1290       0.00      0.00      0.00         2\n",
      "       F1399       0.00      0.00      0.00         1\n",
      "       F1410       0.00      0.00      0.00         3\n",
      "       F1421       0.00      0.00      0.00         1\n",
      "      F17200       0.00      0.00      0.00         1\n",
      "      F17210       0.00      0.00      0.00        15\n",
      "      F17211       0.00      0.00      0.00         0\n",
      "      F17220       0.00      0.00      0.00         0\n",
      "       F1920       0.00      0.00      0.00         1\n",
      "        F200       0.00      0.00      0.00         2\n",
      "        F209       0.00      0.00      0.00         2\n",
      "         F22       0.00      0.00      0.00         1\n",
      "        F312       0.00      0.00      0.00         0\n",
      "       F3181       0.00      0.00      0.00         1\n",
      "        F319       0.00      0.00      0.00         4\n",
      "        F329       0.01      0.03      0.01        29\n",
      "        F332       0.00      0.00      0.00         0\n",
      "      F40240       0.00      0.00      0.00         1\n",
      "        F410       0.00      0.00      0.00         1\n",
      "        F418       0.00      0.00      0.00         3\n",
      "        F419       0.00      0.00      0.00        25\n",
      "       F4310       0.00      0.00      0.00         1\n",
      "       F4320       0.00      0.00      0.00         1\n",
      "        F459       0.00      0.00      0.00         2\n",
      "       F6810       0.00      0.00      0.00         1\n",
      "        F909       0.00      0.00      0.00         4\n",
      "        F918       0.00      0.00      0.00         1\n",
      "        G030       0.00      0.00      0.00         1\n",
      "         G20       0.00      0.00      0.00         2\n",
      "        G251       0.00      0.00      0.00         1\n",
      "       G2581       0.00      0.00      0.00         1\n",
      "        G309       0.00      0.00      0.00         1\n",
      "       G3109       0.00      0.00      0.00         1\n",
      "        G312       0.00      0.00      0.00         1\n",
      "       G3189       0.00      0.00      0.00         1\n",
      "      G40401       0.00      0.00      0.00         1\n",
      "      G40409       0.00      0.00      0.00         2\n",
      "      G40419       0.00      0.00      0.00         1\n",
      "      G40801       0.00      0.00      0.00         1\n",
      "      G40802       0.00      0.00      0.00         1\n",
      "      G40909       0.00      0.00      0.00         5\n",
      "      G43909       0.00      0.00      0.00         8\n",
      "        G464       0.00      0.00      0.00         1\n",
      "       G4700       0.00      0.00      0.00         6\n",
      "       G4730       0.00      0.00      0.00         3\n",
      "       G4733       0.00      0.00      0.00        16\n",
      "       G4736       0.00      0.00      0.00         1\n",
      "        G510       0.00      0.00      0.00         1\n",
      "        G546       0.00      0.00      0.00         1\n",
      "        G588       0.00      0.00      0.00         1\n",
      "        G610       0.00      0.00      0.00         1\n",
      "       G6181       0.00      0.00      0.00         1\n",
      "        G629       0.00      0.00      0.00         5\n",
      "       G7000       0.00      0.00      0.00         1\n",
      "       G7001       0.00      0.00      0.00         1\n",
      "       G7089       0.00      0.00      0.00         1\n",
      "        G713       0.00      0.00      0.00         1\n",
      "        G808       0.00      0.00      0.00         1\n",
      "       G8194       0.00      0.00      0.00         1\n",
      "       G8220       0.00      0.00      0.00         1\n",
      "       G8918       0.00      0.00      0.00         1\n",
      "       G8929       0.00      0.00      0.00         4\n",
      "        G893       0.00      0.00      0.00         2\n",
      "        G911       0.00      0.00      0.00         1\n",
      "        G919       0.00      0.00      0.00         1\n",
      "         G92       0.00      0.00      0.00         5\n",
      "        G931       0.00      0.00      0.00         1\n",
      "       G9340       0.00      0.00      0.00         2\n",
      "       G9341       0.00      0.00      0.00         1\n",
      "        G935       0.00      0.00      0.00         2\n",
      "        G936       0.00      0.00      0.00         3\n",
      "         G94       0.00      0.00      0.00         1\n",
      "       G9589       0.00      0.00      0.00         2\n",
      "       H3530       0.00      0.00      0.00         2\n",
      "        H409       0.00      0.00      0.00         6\n",
      "       H4902       0.00      0.00      0.00         1\n",
      "       H5440       0.00      0.00      0.00         1\n",
      "       H5441       0.00      0.00      0.00         1\n",
      "       H5461       0.00      0.00      0.00         1\n",
      "        H547       0.00      0.00      0.00         1\n",
      "       H8110       0.00      0.00      0.00         1\n",
      "        I071       0.00      0.00      0.00         3\n",
      "        I083       0.00      0.00      0.00         1\n",
      "         I10       0.03      0.12      0.05        58\n",
      "        I110       0.00      0.00      0.00         9\n",
      "        I120       0.00      0.00      0.00         1\n",
      "        I129       0.00      0.00      0.00        15\n",
      "        I130       0.00      0.00      0.00         7\n",
      "        I132       0.00      0.00      0.00         4\n",
      "        I160       0.00      0.00      0.00         3\n",
      "        I161       0.00      0.00      0.00         1\n",
      "       I2111       0.00      0.00      0.00         0\n",
      "       I2119       0.00      0.00      0.00         1\n",
      "        I214       0.00      0.00      0.00         9\n",
      "       I21A1       0.00      0.00      0.00         3\n",
      "        I248       0.00      0.00      0.00         2\n",
      "        I249       0.00      0.00      0.00         1\n",
      "       I2510       0.00      0.00      0.00        32\n",
      "      I25110       0.00      0.00      0.00         5\n",
      "      I25118       0.00      0.00      0.00         2\n",
      "      I25119       0.00      0.00      0.00         4\n",
      "        I252       0.00      0.00      0.00         8\n",
      "        I255       0.00      0.00      0.00         2\n",
      "      I25810       0.00      0.00      0.00         1\n",
      "       I2699       0.00      0.00      0.00         1\n",
      "        I270       0.00      0.00      0.00         1\n",
      "        I272       0.00      0.00      0.00         3\n",
      "       I2720       0.00      0.00      0.00         4\n",
      "       I2721       0.00      0.00      0.00         1\n",
      "        I314       0.00      0.00      0.00         1\n",
      "        I318       0.00      0.00      0.00         1\n",
      "        I330       0.00      0.00      0.00         3\n",
      "        I339       0.00      0.00      0.00         1\n",
      "        I340       0.00      0.00      0.00         4\n",
      "        I341       0.00      0.00      0.00         2\n",
      "        I350       0.00      0.00      0.00         2\n",
      "        I351       0.00      0.00      0.00         0\n",
      "        I420       0.00      0.00      0.00         2\n",
      "        I428       0.00      0.00      0.00         3\n",
      "        I429       0.00      0.00      0.00         1\n",
      "        I440       0.00      0.00      0.00         1\n",
      "        I441       0.00      0.00      0.00         1\n",
      "        I442       0.00      0.00      0.00         2\n",
      "        I447       0.00      0.00      0.00         2\n",
      "       I4581       0.00      0.00      0.00         2\n",
      "        I469       0.00      0.00      0.00         1\n",
      "        I471       0.00      0.00      0.00         3\n",
      "        I472       0.00      0.00      0.00         1\n",
      "        I480       0.00      0.00      0.00         9\n",
      "        I481       0.00      0.00      0.00         1\n",
      "        I482       0.00      0.00      0.00         5\n",
      "       I4891       0.00      0.00      0.00        19\n",
      "       I4892       0.00      0.00      0.00         1\n",
      "       I4901       0.00      0.00      0.00         0\n",
      "        I493       0.00      0.00      0.00         0\n",
      "        I495       0.00      0.00      0.00         1\n",
      "        I499       0.00      0.00      0.00         1\n",
      "        I501       0.00      0.00      0.00         2\n",
      "       I5020       0.00      0.00      0.00         1\n",
      "       I5021       0.00      0.00      0.00         2\n",
      "       I5022       0.00      0.00      0.00         5\n",
      "       I5023       0.00      0.00      0.00         3\n",
      "       I5031       0.00      0.00      0.00         1\n",
      "       I5032       0.00      0.00      0.00         7\n",
      "       I5033       0.00      0.00      0.00         7\n",
      "       I5041       0.00      0.00      0.00         1\n",
      "       I5043       0.00      0.00      0.00         2\n",
      "        I509       0.00      0.00      0.00         7\n",
      "        I517       0.00      0.00      0.00         1\n",
      "       I5181       0.00      0.00      0.00         1\n",
      "        I609       0.00      0.00      0.00         1\n",
      "        I612       0.00      0.00      0.00         1\n",
      "       I6201       0.00      0.00      0.00         1\n",
      "       I6302       0.00      0.00      0.00         1\n",
      "      I63032       0.00      0.00      0.00         1\n",
      "       I6310       0.00      0.00      0.00         1\n",
      "      I63132       0.00      0.00      0.00         1\n",
      "      I63232       0.00      0.00      0.00         1\n",
      "      I63311       0.00      0.00      0.00         1\n",
      "       I6339       0.00      0.00      0.00         1\n",
      "      I63411       0.00      0.00      0.00         1\n",
      "      I63412       0.00      0.00      0.00         1\n",
      "      I63511       0.00      0.00      0.00         1\n",
      "       I6389       0.00      0.00      0.00         1\n",
      "       I6522       0.00      0.00      0.00         1\n",
      "        I671       0.00      0.00      0.00         1\n",
      "       I6789       0.00      0.00      0.00         1\n",
      "      I69198       0.00      0.00      0.00         1\n",
      "      I69351       0.00      0.00      0.00         1\n",
      "      I69354       0.00      0.00      0.00         1\n",
      "      I69398       0.00      0.00      0.00         2\n",
      "        I700       0.00      0.00      0.00         1\n",
      "      I70222       0.00      0.00      0.00         1\n",
      "      I70245       0.00      0.00      0.00         1\n",
      "      I70261       0.00      0.00      0.00         1\n",
      "      I70291       0.00      0.00      0.00         1\n",
      "       I7101       0.00      0.00      0.00         1\n",
      "        I712       0.00      0.00      0.00         2\n",
      "        I714       0.00      0.00      0.00         2\n",
      "        I723       0.00      0.00      0.00         1\n",
      "       I7300       0.00      0.00      0.00         1\n",
      "        I739       0.00      0.00      0.00         8\n",
      "        I742       0.00      0.00      0.00         1\n",
      "        I776       0.00      0.00      0.00         1\n",
      "      I77819       0.00      0.00      0.00         1\n",
      "         I81       0.00      0.00      0.00         1\n",
      "      I82220       0.00      0.00      0.00         1\n",
      "      I82432       0.00      0.00      0.00         0\n",
      "      I82491       0.00      0.00      0.00         1\n",
      "      I824Z1       0.00      0.00      0.00         1\n",
      "      I82521       0.00      0.00      0.00         1\n",
      "      I82611       0.00      0.00      0.00         1\n",
      "      I82612       0.00      0.00      0.00         1\n",
      "      I82622       0.00      0.00      0.00         1\n",
      "      I82722       0.00      0.00      0.00         0\n",
      "       I8500       0.00      0.00      0.00         1\n",
      "       I8510       0.00      0.00      0.00         2\n",
      "        I862       0.00      0.00      0.00         0\n",
      "        I878       0.00      0.00      0.00         0\n",
      "        I890       0.00      0.00      0.00         0\n",
      "        I951       0.00      0.00      0.00         4\n",
      "       I9581       0.00      0.00      0.00         1\n",
      "       I9589       0.00      0.00      0.00         1\n",
      "        I959       0.00      0.00      0.00        10\n",
      "         I96       0.00      0.00      0.00         3\n",
      "      I97191       0.00      0.00      0.00         1\n",
      "      I97611       0.00      0.00      0.00         0\n",
      "      I97618       0.00      0.00      0.00         1\n",
      "       I9789       0.00      0.00      0.00         0\n",
      "        J040       0.00      0.00      0.00         1\n",
      "        J069       0.00      0.00      0.00         1\n",
      "        J101       0.00      0.00      0.00         1\n",
      "       J1108       0.00      0.00      0.00         1\n",
      "        J122       0.00      0.00      0.00         0\n",
      "        J150       0.00      0.00      0.00         1\n",
      "        J159       0.00      0.00      0.00         1\n",
      "         J17       0.00      0.00      0.00         1\n",
      "        J189       0.00      0.00      0.00         6\n",
      "        J208       0.00      0.00      0.00         1\n",
      "        J302       0.00      0.00      0.00         1\n",
      "        J309       0.00      0.00      0.00         1\n",
      "        J329       0.00      0.00      0.00         1\n",
      "        J342       0.00      0.00      0.00         1\n",
      "         J40       0.00      0.00      0.00         1\n",
      "        J439       0.00      0.00      0.00         2\n",
      "        J440       0.00      0.00      0.00         2\n",
      "        J441       0.00      0.00      0.00         6\n",
      "        J449       0.00      0.00      0.00        10\n",
      "       J4520       0.00      0.00      0.00         1\n",
      "       J4530       0.00      0.00      0.00         1\n",
      "      J45901       0.00      0.00      0.00         1\n",
      "      J45909       0.00      0.00      0.00        13\n",
      "        J690       0.00      0.00      0.00         2\n",
      "        J701       0.00      0.00      0.00         1\n",
      "        J810       0.00      0.00      0.00         1\n",
      "        J811       0.00      0.00      0.00         1\n",
      "        J849       0.00      0.00      0.00         1\n",
      "        J850       0.00      0.00      0.00         1\n",
      "        J869       0.00      0.00      0.00         1\n",
      "         J90       0.00      0.00      0.00         3\n",
      "        J910       0.00      0.00      0.00         1\n",
      "        J918       0.00      0.00      0.00         1\n",
      "        J948       0.00      0.00      0.00         1\n",
      "      J95851       0.00      0.00      0.00         4\n",
      "       J9600       0.00      0.00      0.00         2\n",
      "       J9601       0.00      0.00      0.00         7\n",
      "       J9602       0.00      0.00      0.00         1\n",
      "       J9610       0.00      0.00      0.00         1\n",
      "       J9621       0.00      0.00      0.00         4\n",
      "       J9622       0.00      0.00      0.00         1\n",
      "       J9692       0.00      0.00      0.00         1\n",
      "       J9811       0.00      0.00      0.00         1\n",
      "        J984       0.00      0.00      0.00         1\n",
      "       J9859       0.00      0.00      0.00         0\n",
      "        K029       0.00      0.00      0.00         1\n",
      "        K045       0.00      0.00      0.00         1\n",
      "        K047       0.00      0.00      0.00         1\n",
      "        K209       0.00      0.00      0.00         1\n",
      "        K219       0.01      0.05      0.02        44\n",
      "        K222       0.00      0.00      0.00         1\n",
      "        K224       0.00      0.00      0.00         2\n",
      "       K2270       0.00      0.00      0.00         1\n",
      "        K254       0.00      0.00      0.00         3\n",
      "        K259       0.00      0.00      0.00         2\n",
      "        K264       0.00      0.00      0.00         0\n",
      "        K279       0.00      0.00      0.00         1\n",
      "        K289       0.00      0.00      0.00         1\n",
      "       K2901       0.00      0.00      0.00         1\n",
      "       K2970       0.00      0.00      0.00         6\n",
      "       K2980       0.00      0.00      0.00         0\n",
      "         K30       0.00      0.00      0.00         1\n",
      "      K31811       0.00      0.00      0.00         2\n",
      "      K31819       0.00      0.00      0.00         1\n",
      "       K3184       0.00      0.00      0.00         5\n",
      "       K3189       0.00      0.00      0.00         4\n",
      "        K353       0.00      0.00      0.00         1\n",
      "       K3580       0.00      0.00      0.00         1\n",
      "      K35890       0.00      0.00      0.00         1\n",
      "        K429       0.00      0.00      0.00         3\n",
      "        K430       0.00      0.00      0.00         0\n",
      "        K432       0.00      0.00      0.00         1\n",
      "        K449       0.00      0.00      0.00         3\n",
      "        K469       0.00      0.00      0.00         1\n",
      "       K5090       0.00      0.00      0.00         1\n",
      "      K50912       0.00      0.00      0.00         1\n",
      "       K5190       0.00      0.00      0.00         2\n",
      "      K51911       0.00      0.00      0.00         1\n",
      "        K521       0.00      0.00      0.00         1\n",
      "        K529       0.00      0.00      0.00         3\n",
      "        K551       0.00      0.00      0.00         1\n",
      "        K565       0.00      0.00      0.00         1\n",
      "       K5650       0.00      0.00      0.00         1\n",
      "        K567       0.00      0.00      0.00         3\n",
      "       K5730       0.00      0.00      0.00         2\n",
      "       K5790       0.00      0.00      0.00         1\n",
      "        K589       0.00      0.00      0.00         3\n",
      "       K5900       0.00      0.00      0.00        13\n",
      "       K5909       0.00      0.00      0.00         1\n",
      "        K625       0.00      0.00      0.00         1\n",
      "        K648       0.00      0.00      0.00         1\n",
      "        K649       0.00      0.00      0.00         1\n",
      "        K658       0.00      0.00      0.00         1\n",
      "        K660       0.00      0.00      0.00         1\n",
      "        K661       0.00      0.00      0.00         1\n",
      "       K6811       0.00      0.00      0.00         2\n",
      "       K7030       0.00      0.00      0.00         3\n",
      "       K7031       0.00      0.00      0.00         1\n",
      "       K7040       0.00      0.00      0.00         1\n",
      "        K710       0.00      0.00      0.00         1\n",
      "       K7200       0.00      0.00      0.00         1\n",
      "       K7290       0.00      0.00      0.00         1\n",
      "        K740       0.00      0.00      0.00         1\n",
      "       K7460       0.00      0.00      0.00         3\n",
      "       K7469       0.00      0.00      0.00         1\n",
      "       K7581       0.00      0.00      0.00         1\n",
      "        K759       0.00      0.00      0.00         1\n",
      "        K760       0.00      0.00      0.00         3\n",
      "        K766       0.00      0.00      0.00         4\n",
      "       K8010       0.00      0.00      0.00         2\n",
      "       K8012       0.00      0.00      0.00         0\n",
      "       K8013       0.00      0.00      0.00         1\n",
      "       K8020       0.00      0.00      0.00         2\n",
      "       K8051       0.00      0.00      0.00         2\n",
      "        K819       0.00      0.00      0.00         1\n",
      "        K830       0.00      0.00      0.00         2\n",
      "       K8309       0.00      0.00      0.00         1\n",
      "        K831       0.00      0.00      0.00         5\n",
      "        K838       0.00      0.00      0.00         3\n",
      "       K8520       0.00      0.00      0.00         1\n",
      "       K8590       0.00      0.00      0.00         1\n",
      "       K8591       0.00      0.00      0.00         1\n",
      "        K860       0.00      0.00      0.00         1\n",
      "        K861       0.00      0.00      0.00         2\n",
      "       K8689       0.00      0.00      0.00         1\n",
      "        K912       0.00      0.00      0.00         1\n",
      "       K9161       0.00      0.00      0.00         1\n",
      "       K9181       0.00      0.00      0.00         1\n",
      "      K91841       0.00      0.00      0.00         1\n",
      "       K9186       0.00      0.00      0.00         2\n",
      "       K9189       0.00      0.00      0.00         1\n",
      "        K920       0.00      0.00      0.00         2\n",
      "        K921       0.00      0.00      0.00         2\n",
      "        K922       0.00      0.00      0.00         2\n",
      "      L02412       0.00      0.00      0.00         1\n",
      "      L03113       0.00      0.00      0.00         1\n",
      "      L03116       0.00      0.00      0.00         1\n",
      "      L03211       0.00      0.00      0.00         1\n",
      "      L03213       0.00      0.00      0.00         1\n",
      "      L03311       0.00      0.00      0.00         2\n",
      "        L089       0.00      0.00      0.00         1\n",
      "        L111       0.00      0.00      0.00         1\n",
      "        L209       0.00      0.00      0.00         1\n",
      "        L299       0.00      0.00      0.00         1\n",
      "        L309       0.00      0.00      0.00         2\n",
      "       L4050       0.00      0.00      0.00         1\n",
      "        L409       0.00      0.00      0.00         1\n",
      "        L732       0.00      0.00      0.00         1\n",
      "       L7632       0.00      0.00      0.00         1\n",
      "      L89153       0.00      0.00      0.00         1\n",
      "      L89154       0.00      0.00      0.00         1\n",
      "      L89221       0.00      0.00      0.00         1\n",
      "      L89611       0.00      0.00      0.00         1\n",
      "      L97319       0.00      0.00      0.00         1\n",
      "      L97429       0.00      0.00      0.00         1\n",
      "      L97509       0.00      0.00      0.00         1\n",
      "      L97529       0.00      0.00      0.00         1\n",
      "        L982       0.00      0.00      0.00         1\n",
      "      L98498       0.00      0.00      0.00         1\n",
      "      L98499       0.00      0.00      0.00         1\n",
      "      M00261       0.00      0.00      0.00         1\n",
      "        M059       0.00      0.00      0.00         1\n",
      "        M069       0.00      0.00      0.00         4\n",
      "        M109       0.00      0.00      0.00         1\n",
      "       M1380       0.00      0.00      0.00         1\n",
      "       M1610       0.00      0.00      0.00         1\n",
      "        M170       0.00      0.00      0.00         1\n",
      "       M1711       0.00      0.00      0.00         1\n",
      "      M19041       0.00      0.00      0.00         1\n",
      "       M1990       0.00      0.00      0.00         7\n",
      "     M1A9XX0       0.00      0.00      0.00         1\n",
      "      M21372       0.00      0.00      0.00         1\n",
      "      M24542       0.00      0.00      0.00         1\n",
      "      M24661       0.00      0.00      0.00         1\n",
      "      M25512       0.00      0.00      0.00         1\n",
      "      M25519       0.00      0.00      0.00         1\n",
      "      M25531       0.00      0.00      0.00         1\n",
      "      M25561       0.00      0.00      0.00         1\n",
      "        M310       0.00      0.00      0.00         1\n",
      "        M329       0.00      0.00      0.00         1\n",
      "        M419       0.00      0.00      0.00         1\n",
      "       M4316       0.00      0.00      0.00         2\n",
      "        M461       0.00      0.00      0.00         2\n",
      "       M4627       0.00      0.00      0.00         1\n",
      "       M4628       0.00      0.00      0.00         1\n",
      "       M4646       0.00      0.00      0.00         1\n",
      "       M4712       0.00      0.00      0.00         1\n",
      "      M47815       0.00      0.00      0.00         0\n",
      "      M47892       0.00      0.00      0.00         2\n",
      "        M479       0.00      0.00      0.00         1\n",
      "       M4802       0.00      0.00      0.00         1\n",
      "       M4806       0.00      0.00      0.00         2\n",
      "      M48061       0.00      0.00      0.00         1\n",
      "      M48062       0.00      0.00      0.00         1\n",
      "     M4854XA       0.00      0.00      0.00         1\n",
      "     M4856XA       0.00      0.00      0.00         1\n",
      "       M5033       0.00      0.00      0.00         1\n",
      "       M5416       0.00      0.00      0.00         2\n",
      "       M5417       0.00      0.00      0.00         1\n",
      "        M542       0.00      0.00      0.00         1\n",
      "       M5430       0.00      0.00      0.00         1\n",
      "       M5432       0.00      0.00      0.00         1\n",
      "       M5440       0.00      0.00      0.00         1\n",
      "        M545       0.00      0.00      0.00         2\n",
      "        M549       0.00      0.00      0.00         1\n",
      "      M60001       0.00      0.00      0.00         1\n",
      "       M6281       0.00      0.00      0.00         1\n",
      "       M6282       0.00      0.00      0.00         1\n",
      "      M79602       0.00      0.00      0.00         1\n",
      "      M79621       0.00      0.00      0.00         1\n",
      "      M79671       0.00      0.00      0.00         1\n",
      "        M797       0.00      0.00      0.00         3\n",
      "       M7989       0.00      0.00      0.00         1\n",
      "        M810       0.00      0.00      0.00         9\n",
      "     M8448XD       0.00      0.00      0.00         1\n",
      "       M8580       0.00      0.00      0.00         2\n",
      "      M86652       0.00      0.00      0.00         1\n",
      "        M869       0.00      0.00      0.00         0\n",
      "      M87851       0.00      0.00      0.00         1\n",
      "      M898X9       0.00      0.00      0.00         1\n",
      "        M952       0.00      0.00      0.00         1\n",
      "        N049       0.00      0.00      0.00         1\n",
      "        N131       0.00      0.00      0.00         1\n",
      "       N1330       0.00      0.00      0.00         2\n",
      "        N138       0.00      0.00      0.00         1\n",
      "        N141       0.00      0.00      0.00         1\n",
      "        N170       0.00      0.00      0.00         4\n",
      "        N179       0.01      0.05      0.02        21\n",
      "        N182       0.00      0.00      0.00         1\n",
      "        N183       0.00      0.00      0.00         7\n",
      "        N184       0.00      0.00      0.00         2\n",
      "        N186       0.00      0.00      0.00         4\n",
      "        N189       0.00      0.00      0.00        11\n",
      "        N201       0.00      0.00      0.00         1\n",
      "       N2581       0.00      0.00      0.00         1\n",
      "       N2589       0.00      0.00      0.00         1\n",
      "       N2889       0.00      0.00      0.00         2\n",
      "       N3081       0.00      0.00      0.00         1\n",
      "       N3090       0.00      0.00      0.00         2\n",
      "        N318       0.00      0.00      0.00         1\n",
      "        N319       0.00      0.00      0.00         2\n",
      "        N320       0.00      0.00      0.00         1\n",
      "        N321       0.00      0.00      0.00         1\n",
      "        N329       0.00      0.00      0.00         1\n",
      "        N390       0.03      0.06      0.04        16\n",
      "       N3941       0.00      0.00      0.00         1\n",
      "        N400       0.00      0.00      0.00         7\n",
      "        N401       0.00      0.00      0.00         7\n",
      "       N4883       0.00      0.00      0.00         1\n",
      "      N50819       0.00      0.00      0.00         1\n",
      "       N7093       0.00      0.00      0.00         1\n",
      "        N736       0.00      0.00      0.00         1\n",
      "        N809       0.00      0.00      0.00         1\n",
      "       N8112       0.00      0.00      0.00         1\n",
      "        N858       0.00      0.00      0.00         1\n",
      "      O24013       0.00      0.00      0.00         1\n",
      "      O26891       0.00      0.00      0.00         1\n",
      "        O723       0.00      0.00      0.00         1\n",
      "         O76       0.00      0.00      0.00         1\n",
      "        O770       0.00      0.00      0.00         1\n",
      "       O9989       0.00      0.00      0.00         1\n",
      "        Q211       0.00      0.00      0.00         3\n",
      "        Q231       0.00      0.00      0.00         1\n",
      "       Q2733       0.00      0.00      0.00         1\n",
      "        Q282       0.00      0.00      0.00         1\n",
      "        Q604       0.00      0.00      0.00         1\n",
      "        Q605       0.00      0.00      0.00         1\n",
      "        Q613       0.00      0.00      0.00         1\n",
      "        Q798       0.00      0.00      0.00         1\n",
      "      Q87410       0.00      0.00      0.00         1\n",
      "        R000       0.00      0.00      0.00         2\n",
      "        R001       0.00      0.00      0.00         7\n",
      "        R002       0.00      0.00      0.00         0\n",
      "        R040       0.00      0.00      0.00         1\n",
      "        R042       0.00      0.00      0.00         3\n",
      "         R05       0.00      0.00      0.00         1\n",
      "       R0602       0.00      0.00      0.00         1\n",
      "       R0689       0.00      0.00      0.00         1\n",
      "       R0789       0.00      0.00      0.00         2\n",
      "        R079       0.00      0.00      0.00         2\n",
      "       R0902       0.00      0.00      0.00         3\n",
      "       R1011       0.00      0.00      0.00         2\n",
      "       R1030       0.00      0.00      0.00         1\n",
      "       R1032       0.00      0.00      0.00         2\n",
      "        R109       0.00      0.00      0.00         4\n",
      "        R110       0.00      0.00      0.00         2\n",
      "       R1110       0.00      0.00      0.00         1\n",
      "        R112       0.00      0.00      0.00         4\n",
      "       R1310       0.00      0.00      0.00         3\n",
      "       R1312       0.00      0.00      0.00         2\n",
      "        R140       0.00      0.00      0.00         1\n",
      "        R152       0.00      0.00      0.00         1\n",
      "         R17       0.00      0.00      0.00         1\n",
      "        R180       0.00      0.00      0.00         2\n",
      "        R188       0.00      0.00      0.00         3\n",
      "        R195       0.00      0.00      0.00         1\n",
      "        R197       0.00      0.00      0.00         5\n",
      "        R198       0.00      0.00      0.00         1\n",
      "        R200       0.00      0.00      0.00         1\n",
      "        R202       0.00      0.00      0.00         2\n",
      "         R21       0.00      0.00      0.00         0\n",
      "        R232       0.00      0.00      0.00         1\n",
      "        R251       0.00      0.00      0.00         2\n",
      "        R253       0.00      0.00      0.00         1\n",
      "        R260       0.00      0.00      0.00         1\n",
      "       R2681       0.00      0.00      0.00         2\n",
      "        R269       0.00      0.00      0.00         1\n",
      "      R29701       0.00      0.00      0.00         1\n",
      "      R29810       0.00      0.00      0.00         5\n",
      "        R310       0.00      0.00      0.00         2\n",
      "        R319       0.00      0.00      0.00         1\n",
      "         R32       0.00      0.00      0.00         1\n",
      "        R338       0.00      0.00      0.00         4\n",
      "        R339       0.00      0.00      0.00         5\n",
      "         R34       0.00      0.00      0.00         0\n",
      "        R350       0.00      0.00      0.00         2\n",
      "       R3915       0.00      0.00      0.00         1\n",
      "       R4020       0.00      0.00      0.00         1\n",
      "     R402112       0.00      0.00      0.00         1\n",
      "     R402222       0.00      0.00      0.00         0\n",
      "     R402243       0.00      0.00      0.00         0\n",
      "     R402252       0.00      0.00      0.00         3\n",
      "     R402343       0.00      0.00      0.00         0\n",
      "     R402362       0.00      0.00      0.00         1\n",
      "     R402432       0.00      0.00      0.00         1\n",
      "        R410       0.00      0.00      0.00         3\n",
      "        R413       0.00      0.00      0.00         2\n",
      "        R414       0.00      0.00      0.00         3\n",
      "         R42       0.00      0.00      0.00         4\n",
      "        R438       0.00      0.00      0.00         1\n",
      "        R443       0.00      0.00      0.00         1\n",
      "        R451       0.00      0.00      0.00         1\n",
      "      R45851       0.00      0.00      0.00         4\n",
      "       R4689       0.00      0.00      0.00         1\n",
      "       R4701       0.00      0.00      0.00         1\n",
      "       R5081       0.00      0.00      0.00         2\n",
      "        R509       0.00      0.00      0.00         2\n",
      "         R51       0.00      0.00      0.00         3\n",
      "        R530       0.00      0.00      0.00         1\n",
      "        R531       0.00      0.00      0.00         2\n",
      "        R532       0.00      0.00      0.00         1\n",
      "       R5381       0.00      0.00      0.00         1\n",
      "       R5383       0.00      0.00      0.00         1\n",
      "         R55       0.00      0.00      0.00         0\n",
      "        R570       0.00      0.00      0.00         2\n",
      "        R600       0.00      0.00      0.00         6\n",
      "         R61       0.00      0.00      0.00         1\n",
      "        R630       0.00      0.00      0.00         1\n",
      "        R634       0.00      0.00      0.00         1\n",
      "       R6521       0.00      0.00      0.00         2\n",
      "        R739       0.00      0.00      0.00         1\n",
      "        R740       0.00      0.00      0.00         9\n",
      "        R748       0.00      0.00      0.00         2\n",
      "       R7611       0.00      0.00      0.00         1\n",
      "       R7881       0.00      0.00      0.00         2\n",
      "        R791       0.00      0.00      0.00         5\n",
      "       R7989       0.00      0.00      0.00         2\n",
      "        R808       0.00      0.00      0.00         1\n",
      "       R8271       0.00      0.00      0.00         1\n",
      "        R918       0.00      0.00      0.00         1\n",
      "      R93421       0.00      0.00      0.00         1\n",
      "        R970       0.00      0.00      0.00         1\n",
      "     S01122A       0.00      0.00      0.00         1\n",
      "     S0181XA       0.00      0.00      0.00         1\n",
      "     S02412A       0.00      0.00      0.00         1\n",
      "     S02622A       0.00      0.00      0.00         1\n",
      "     S0264XA       0.00      0.00      0.00         1\n",
      "     S0502XA       0.00      0.00      0.00         1\n",
      "     S062X0A       0.00      0.00      0.00         1\n",
      "     S06350A       0.00      0.00      0.00         1\n",
      "     S065X0A       0.00      0.00      0.00         1\n",
      "     S12110A       0.00      0.00      0.00         1\n",
      "     S12121A       0.00      0.00      0.00         1\n",
      "     S12400A       0.00      0.00      0.00         1\n",
      "     S12600A       0.00      0.00      0.00         1\n",
      "     S134XXA       0.00      0.00      0.00         1\n",
      "     S22040A       0.00      0.00      0.00         1\n",
      "     S22049A       0.00      0.00      0.00         1\n",
      "     S22079A       0.00      0.00      0.00         1\n",
      "     S2241XA       0.00      0.00      0.00         2\n",
      "     S2242XA       0.00      0.00      0.00         0\n",
      "     S2242XD       0.00      0.00      0.00         1\n",
      "     S2249XD       0.00      0.00      0.00         1\n",
      "     S301XXA       0.00      0.00      0.00         0\n",
      "     S31615A       0.00      0.00      0.00         1\n",
      "     S32011A       0.00      0.00      0.00         1\n",
      "     S32018A       0.00      0.00      0.00         1\n",
      "     S32029A       0.00      0.00      0.00         1\n",
      "     S32401A       0.00      0.00      0.00         1\n",
      "     S32425A       0.00      0.00      0.00         0\n",
      "     S32501A       0.00      0.00      0.00         0\n",
      "     S32810D       0.00      0.00      0.00         1\n",
      "     S36113A       0.00      0.00      0.00         1\n",
      "     S3730XA       0.00      0.00      0.00         1\n",
      "     S42122A       0.00      0.00      0.00         1\n",
      "     S46011S       0.00      0.00      0.00         0\n",
      "     S46911D       0.00      0.00      0.00         1\n",
      "     S5012XA       0.00      0.00      0.00         1\n",
      "     S52611A       0.00      0.00      0.00         1\n",
      "     S7001XA       0.00      0.00      0.00         1\n",
      "     S71111A       0.00      0.00      0.00         0\n",
      "     S72111A       0.00      0.00      0.00         1\n",
      "     S72141A       0.00      0.00      0.00         1\n",
      "     S7221XA       0.00      0.00      0.00         1\n",
      "     S7222XA       0.00      0.00      0.00         1\n",
      "     S73004A       0.00      0.00      0.00         1\n",
      "     S8255XA       0.00      0.00      0.00         1\n",
      "     S82851A       0.00      0.00      0.00         1\n",
      "     T368X5A       0.00      0.00      0.00         2\n",
      "     T380X5A       0.00      0.00      0.00         1\n",
      "     T391X5A       0.00      0.00      0.00         1\n",
      "     T402X1A       0.00      0.00      0.00         1\n",
      "     T402X5A       0.00      0.00      0.00         1\n",
      "     T40605A       0.00      0.00      0.00         2\n",
      "     T426X2A       0.00      0.00      0.00         1\n",
      "     T426X5A       0.00      0.00      0.00         1\n",
      "     T428X6A       0.00      0.00      0.00         0\n",
      "     T43595A       0.00      0.00      0.00         1\n",
      "     T43625A       0.00      0.00      0.00         2\n",
      "     T450X5A       0.00      0.00      0.00         1\n",
      "     T451X1A       0.00      0.00      0.00         1\n",
      "     T451X5A       0.00      0.00      0.00         5\n",
      "     T451X5S       0.00      0.00      0.00         1\n",
      "     T45525A       0.00      0.00      0.00         1\n",
      "     T464X5A       0.00      0.00      0.00         1\n",
      "     T481X5A       0.00      0.00      0.00         1\n",
      "     T501X5A       0.00      0.00      0.00         1\n",
      "     T502X6A       0.00      0.00      0.00         1\n",
      "     T508X5A       0.00      0.00      0.00         1\n",
      "     T50906A       0.00      0.00      0.00         1\n",
      "     T783XXA       0.00      0.00      0.00         0\n",
      "     T796XXA       0.00      0.00      0.00         1\n",
      "     T8110XA       0.00      0.00      0.00         1\n",
      "     T8119XA       0.00      0.00      0.00         1\n",
      "     T814XXA       0.00      0.00      0.00         3\n",
      "     T826XXA       0.00      0.00      0.00         1\n",
      "     T82855A       0.00      0.00      0.00         1\n",
      "     T82856A       0.00      0.00      0.00         1\n",
      "     T82868A       0.00      0.00      0.00         2\n",
      "     T83518A       0.00      0.00      0.00         1\n",
      "     T8579XA       0.00      0.00      0.00         2\n",
      "       T8613       0.00      0.00      0.00         1\n",
      "       T8619       0.00      0.00      0.00         1\n",
      "        T865       0.00      0.00      0.00         3\n",
      "     V00891A       0.00      0.00      0.00         1\n",
      "       V0179       0.00      0.00      0.00         1\n",
      "       V0259       0.00      0.00      0.00         2\n",
      "       V0381       0.00      0.00      0.00         0\n",
      "       V0382       0.00      0.00      0.00         1\n",
      "       V0481       0.00      0.00      0.00         3\n",
      "        V066       0.00      0.00      0.00         2\n",
      "        V070       0.00      0.00      0.00         1\n",
      "         V08       0.00      0.00      0.00         3\n",
      "       V0980       0.00      0.00      0.00         1\n",
      "       V1002       0.00      0.00      0.00         1\n",
      "       V1003       0.00      0.00      0.00         1\n",
      "       V1005       0.00      0.00      0.00         3\n",
      "       V1007       0.00      0.00      0.00         2\n",
      "       V1009       0.00      0.00      0.00         2\n",
      "       V1011       0.00      0.00      0.00         3\n",
      "       V1021       0.00      0.00      0.00         2\n",
      "        V103       0.00      0.00      0.00        11\n",
      "       V1041       0.00      0.00      0.00         2\n",
      "       V1042       0.00      0.00      0.00         1\n",
      "       V1043       0.00      0.00      0.00         1\n",
      "       V1046       0.00      0.00      0.00        10\n",
      "       V1047       0.00      0.00      0.00         1\n",
      "       V1051       0.00      0.00      0.00         1\n",
      "       V1052       0.00      0.00      0.00         1\n",
      "       V1072       0.00      0.00      0.00         1\n",
      "       V1081       0.00      0.00      0.00         1\n",
      "       V1082       0.00      0.00      0.00         4\n",
      "       V1083       0.00      0.00      0.00         7\n",
      "       V1085       0.00      0.00      0.00         1\n",
      "       V1087       0.00      0.00      0.00         2\n",
      "        V113       0.00      0.00      0.00         2\n",
      "       V1201       0.00      0.00      0.00         3\n",
      "       V1204       0.00      0.00      0.00         4\n",
      "       V1229       0.00      0.00      0.00         1\n",
      "       V1251       0.00      0.00      0.00        10\n",
      "       V1252       0.00      0.00      0.00         2\n",
      "       V1253       0.00      0.00      0.00         1\n",
      "       V1254       0.17      0.08      0.11        13\n",
      "       V1255       0.00      0.00      0.00         6\n",
      "       V1261       0.00      0.00      0.00         1\n",
      "       V1271       0.00      0.00      0.00         2\n",
      "       V1272       0.00      0.00      0.00         5\n",
      "       V1279       0.00      0.00      0.00         3\n",
      "       V1301       0.00      0.00      0.00         3\n",
      "       V1302       0.00      0.00      0.00         1\n",
      "       V1351       0.00      0.00      0.00         1\n",
      "        V140       0.00      0.00      0.00         1\n",
      "       V1505       0.00      0.00      0.00         1\n",
      "        V153       0.04      0.14      0.06         7\n",
      "       V1541       0.00      0.00      0.00         1\n",
      "       V1559       0.00      0.00      0.00         1\n",
      "       V1581       0.00      0.00      0.00         8\n",
      "       V1582       0.01      0.03      0.02        37\n",
      "       V1588       0.00      0.00      0.00         5\n",
      "        V160       0.00      0.00      0.00         4\n",
      "        V161       0.00      0.00      0.00         2\n",
      "        V163       0.00      0.00      0.00         0\n",
      "       V1642       0.00      0.00      0.00         1\n",
      "        V173       0.00      0.00      0.00         4\n",
      "        V180       0.00      0.00      0.00         3\n",
      "        V182       0.00      0.00      0.00         1\n",
      "       V1869       0.00      0.00      0.00         1\n",
      "        V198       0.00      0.00      0.00         1\n",
      "        V270       1.00      0.20      0.33         5\n",
      "        V420       0.00      0.00      0.00         3\n",
      "        V422       0.00      0.00      0.00         1\n",
      "        V427       0.00      0.00      0.00         3\n",
      "       V4282       0.00      0.00      0.00         3\n",
      "       V4283       0.00      0.00      0.00         1\n",
      "        V433       0.00      0.00      0.00         2\n",
      "     V4352XA       0.00      0.00      0.00         1\n",
      "       V4364       0.00      0.00      0.00         4\n",
      "       V4365       0.00      0.00      0.00         8\n",
      "       V4389       0.00      0.00      0.00         1\n",
      "        V440       0.00      0.00      0.00         2\n",
      "        V441       0.00      0.00      0.00         5\n",
      "        V442       0.00      0.00      0.00         4\n",
      "        V443       0.00      0.00      0.00         2\n",
      "        V444       0.00      0.00      0.00         1\n",
      "        V446       0.00      0.00      0.00         1\n",
      "       V4501       0.00      0.00      0.00        10\n",
      "       V4502       0.00      0.00      0.00         2\n",
      "       V4511       0.00      0.00      0.00         8\n",
      "        V453       0.00      0.00      0.00         1\n",
      "        V454       0.00      0.00      0.00         2\n",
      "       V4561       0.00      0.00      0.00         1\n",
      "       V4571       0.00      0.00      0.00         2\n",
      "       V4572       0.00      0.00      0.00         3\n",
      "       V4573       0.00      0.00      0.00         4\n",
      "       V4574       0.00      0.00      0.00         1\n",
      "       V4576       0.00      0.00      0.00         1\n",
      "       V4577       0.00      0.00      0.00         1\n",
      "       V4579       0.00      0.00      0.00         7\n",
      "       V4581       0.00      0.00      0.00        20\n",
      "       V4582       0.00      0.00      0.00        17\n",
      "       V4586       0.00      0.00      0.00         3\n",
      "       V4589       0.00      0.00      0.00         1\n",
      "        V462       0.00      0.00      0.00         3\n",
      "        V463       0.00      0.00      0.00         1\n",
      "     V470XXA       0.00      0.00      0.00         1\n",
      "     V4950XA       0.00      0.00      0.00         1\n",
      "       V4962       0.00      0.00      0.00         1\n",
      "       V4971       0.00      0.00      0.00         0\n",
      "       V4972       0.00      0.00      0.00         1\n",
      "       V4975       0.00      0.00      0.00         3\n",
      "       V4983       0.00      0.00      0.00         2\n",
      "       V4984       0.00      0.00      0.00         1\n",
      "       V4986       0.00      0.00      0.00        14\n",
      "       V4987       0.00      0.00      0.00         3\n",
      "       V5412       0.00      0.00      0.00         1\n",
      "       V5413       0.00      0.00      0.00         1\n",
      "        V550       0.00      0.00      0.00         1\n",
      "     V575XXA       0.00      0.00      0.00         1\n",
      "       V5811       0.00      0.00      0.00         3\n",
      "       V5861       0.00      0.00      0.00        22\n",
      "       V5863       0.00      0.00      0.00         7\n",
      "       V5864       0.00      0.00      0.00         1\n",
      "       V5865       0.00      0.00      0.00         4\n",
      "       V5866       0.00      0.00      0.00        15\n",
      "       V5867       0.01      0.05      0.02        21\n",
      "       V5869       0.00      0.00      0.00         3\n",
      "       V5883       0.00      0.00      0.00         2\n",
      "        V600       0.00      0.00      0.00         4\n",
      "       V6284       0.00      0.00      0.00         1\n",
      "       V6409       0.00      0.00      0.00         0\n",
      "        V641       0.00      0.00      0.00         1\n",
      "        V642       0.00      0.00      0.00         1\n",
      "       V6441       0.00      0.00      0.00         2\n",
      "        V667       0.00      0.00      0.00         4\n",
      "        V707       0.00      0.00      0.00         3\n",
      "        V850       0.00      0.00      0.00         4\n",
      "        V851       0.00      0.00      0.00         2\n",
      "       V8522       0.00      0.00      0.00         1\n",
      "       V8524       0.00      0.00      0.00         1\n",
      "       V8525       0.00      0.00      0.00         1\n",
      "       V8530       0.00      0.00      0.00         1\n",
      "       V8532       0.00      0.00      0.00         3\n",
      "       V8534       0.00      0.00      0.00         1\n",
      "       V8535       0.00      0.00      0.00         1\n",
      "       V8537       0.00      0.00      0.00         1\n",
      "       V8538       0.00      0.00      0.00         1\n",
      "       V8539       0.00      0.00      0.00         1\n",
      "       V8541       0.00      0.00      0.00         1\n",
      "       V8542       0.00      0.00      0.00         3\n",
      "       V8543       0.00      0.00      0.00         0\n",
      "        V860       0.00      0.00      0.00         2\n",
      "     V8661XA       0.00      0.00      0.00         0\n",
      "       V8741       0.00      0.00      0.00         8\n",
      "       V8801       0.00      0.00      0.00         2\n",
      "       V9103       0.00      0.00      0.00         1\n",
      "     W010XXA       0.00      0.00      0.00         2\n",
      "     W01198A       0.00      0.00      0.00         1\n",
      "     W108XXA       0.00      0.00      0.00         1\n",
      "     W109XXA       0.00      0.00      0.00         0\n",
      "     W11XXXA       0.00      0.00      0.00         1\n",
      "     W1830XA       0.00      0.00      0.00         1\n",
      "     W1830XD       0.00      0.00      0.00         1\n",
      "     W1839XA       0.00      0.00      0.00         1\n",
      "     W19XXXA       0.00      0.00      0.00         2\n",
      "     W881XXS       0.00      0.00      0.00         1\n",
      "     X503XXA       0.00      0.00      0.00         1\n",
      "     X58XXXA       0.00      0.00      0.00         2\n",
      "        Y711       0.00      0.00      0.00         1\n",
      "        Y713       0.00      0.00      0.00         1\n",
      "        Y828       0.00      0.00      0.00         1\n",
      "        Y830       0.00      0.00      0.00         3\n",
      "        Y831       0.00      0.00      0.00         3\n",
      "        Y832       0.00      0.00      0.00         1\n",
      "        Y834       0.00      0.00      0.00         1\n",
      "        Y835       0.00      0.00      0.00         2\n",
      "        Y838       0.00      0.00      0.00         4\n",
      "        Y839       0.00      0.00      0.00         2\n",
      "        Y841       0.00      0.00      0.00         1\n",
      "        Y848       0.00      0.00      0.00         5\n",
      "        Y908       0.00      0.00      0.00         1\n",
      "      Y92002       0.00      0.00      0.00         1\n",
      "      Y92003       0.00      0.00      0.00         1\n",
      "      Y92007       0.00      0.00      0.00         1\n",
      "      Y92009       0.00      0.00      0.00         9\n",
      "      Y92019       0.00      0.00      0.00         3\n",
      "      Y92038       0.00      0.00      0.00         1\n",
      "      Y92230       0.00      0.00      0.00        10\n",
      "      Y92234       0.00      0.00      0.00         3\n",
      "      Y92238       0.00      0.00      0.00         1\n",
      "      Y92239       0.00      0.00      0.00        12\n",
      "      Y92480       0.00      0.00      0.00         0\n",
      "      Y92530       0.00      0.00      0.00         1\n",
      "       Y9289       0.00      0.00      0.00         2\n",
      "        Y929       0.00      0.00      0.00        17\n",
      "        Y990       0.00      0.00      0.00         1\n",
      "        Z006       0.00      0.00      0.00         4\n",
      "       Z1611       0.00      0.00      0.00         1\n",
      "       Z1624       0.00      0.00      0.00         1\n",
      "        Z206       0.00      0.00      0.00         1\n",
      "         Z21       0.00      0.00      0.00         2\n",
      "      Z22322       0.00      0.00      0.00         1\n",
      "       Z2239       0.00      0.00      0.00         1\n",
      "         Z23       0.00      0.00      0.00         7\n",
      "      Z30431       0.00      0.00      0.00         1\n",
      "        Z370       0.00      0.00      0.00         1\n",
      "       Z3A08       0.00      0.00      0.00         1\n",
      "       Z3A24       0.00      0.00      0.00         1\n",
      "       Z3A29       0.00      0.00      0.00         1\n",
      "       Z3A33       0.00      0.00      0.00         1\n",
      "       Z3A40       0.00      0.00      0.00         0\n",
      "        Z421       0.00      0.00      0.00         1\n",
      "        Z434       0.00      0.00      0.00         2\n",
      "      Z45018       0.00      0.00      0.00         2\n",
      "        Z451       0.00      0.00      0.00         1\n",
      "       Z5111       0.00      0.00      0.00         2\n",
      "        Z515       0.00      0.00      0.00         4\n",
      "       Z5309       0.00      0.00      0.00         2\n",
      "       Z5329       0.00      0.00      0.00         2\n",
      "        Z538       0.00      0.00      0.00         1\n",
      "        Z590       0.00      0.00      0.00         4\n",
      "         Z66       0.00      0.00      0.00        11\n",
      "        Z681       0.00      0.00      0.00         8\n",
      "       Z6820       0.00      0.00      0.00         1\n",
      "       Z6821       0.00      0.00      0.00         4\n",
      "       Z6822       0.00      0.00      0.00         1\n",
      "       Z6826       0.00      0.00      0.00         0\n",
      "       Z6828       0.00      0.00      0.00         1\n",
      "       Z6830       0.00      0.00      0.00         1\n",
      "       Z6831       0.00      0.00      0.00         0\n",
      "       Z6832       0.00      0.00      0.00         0\n",
      "       Z6833       0.00      0.00      0.00         1\n",
      "       Z6834       0.00      0.00      0.00         3\n",
      "       Z6836       0.00      0.00      0.00         1\n",
      "       Z6837       0.00      0.00      0.00         1\n",
      "       Z6838       0.00      0.00      0.00         3\n",
      "       Z6839       0.00      0.00      0.00         1\n",
      "       Z6841       0.00      0.00      0.00         4\n",
      "       Z6842       0.00      0.00      0.00         3\n",
      "       Z6843       0.00      0.00      0.00         3\n",
      "       Z6844       0.00      0.00      0.00         1\n",
      "        Z720       0.00      0.00      0.00         2\n",
      "       Z7401       0.00      0.00      0.00         1\n",
      "       Z7682       0.00      0.00      0.00         1\n",
      "        Z781       0.00      0.00      0.00         4\n",
      "       Z7901       0.00      0.00      0.00        24\n",
      "       Z7902       0.00      0.00      0.00        13\n",
      "        Z794       0.00      0.00      0.00        26\n",
      "       Z7982       0.00      0.00      0.00         2\n",
      "       Z7984       0.00      0.00      0.00         3\n",
      "      Z79899       0.00      0.00      0.00         4\n",
      "        Z800       0.00      0.00      0.00         2\n",
      "        Z801       0.00      0.00      0.00         2\n",
      "        Z806       0.00      0.00      0.00         1\n",
      "        Z807       0.00      0.00      0.00         1\n",
      "        Z808       0.00      0.00      0.00         2\n",
      "        Z818       0.00      0.00      0.00         1\n",
      "       Z8249       0.00      0.00      0.00         7\n",
      "       Z8489       0.00      0.00      0.00         1\n",
      "      Z85038       0.00      0.00      0.00         4\n",
      "      Z85118       0.00      0.00      0.00         1\n",
      "        Z853       0.00      0.00      0.00         6\n",
      "       Z8542       0.00      0.00      0.00         6\n",
      "       Z8543       0.00      0.00      0.00         1\n",
      "       Z8546       0.00      0.00      0.00         3\n",
      "       Z8547       0.00      0.00      0.00         1\n",
      "       Z8551       0.00      0.00      0.00         1\n",
      "      Z85528       0.00      0.00      0.00         2\n",
      "        Z856       0.00      0.00      0.00         1\n",
      "       Z8572       0.00      0.00      0.00         1\n",
      "      Z85820       0.00      0.00      0.00         2\n",
      "      Z85828       0.00      0.00      0.00         9\n",
      "      Z85850       0.00      0.00      0.00         1\n",
      "       Z8589       0.00      0.00      0.00         1\n",
      "      Z86008       0.00      0.00      0.00         1\n",
      "       Z8612       0.00      0.00      0.00         1\n",
      "      Z86711       0.00      0.00      0.00         8\n",
      "      Z86718       0.00      0.00      0.00         7\n",
      "       Z8673       0.00      0.00      0.00         4\n",
      "       Z8674       0.00      0.00      0.00         2\n",
      "       Z8701       0.00      0.00      0.00         1\n",
      "       Z8719       0.00      0.00      0.00         2\n",
      "      Z87440       0.00      0.00      0.00         2\n",
      "      Z87442       0.00      0.00      0.00         2\n",
      "      Z87820       0.00      0.00      0.00         1\n",
      "      Z87891       0.01      0.07      0.02        43\n",
      "      Z89431       0.00      0.00      0.00         1\n",
      "      Z89511       0.00      0.00      0.00         1\n",
      "      Z89612       0.00      0.00      0.00         1\n",
      "       Z9012       0.00      0.00      0.00         1\n",
      "        Z902       0.00      0.00      0.00         1\n",
      "       Z9049       0.00      0.00      0.00         1\n",
      "        Z906       0.00      0.00      0.00         1\n",
      "      Z90710       0.00      0.00      0.00         2\n",
      "       Z9079       0.00      0.00      0.00         1\n",
      "       Z9081       0.00      0.00      0.00         1\n",
      "      Z91120       0.00      0.00      0.00         1\n",
      "      Z91128       0.00      0.00      0.00         2\n",
      "       Z9114       0.00      0.00      0.00         3\n",
      "       Z9119       0.00      0.00      0.00         2\n",
      "       Z9181       0.00      0.00      0.00         2\n",
      "       Z9221       0.00      0.00      0.00         2\n",
      "        Z923       0.00      0.00      0.00         2\n",
      "       Z9282       0.00      0.00      0.00         0\n",
      "        Z930       0.00      0.00      0.00         1\n",
      "        Z931       0.00      0.00      0.00         1\n",
      "        Z932       0.00      0.00      0.00         3\n",
      "        Z944       0.00      0.00      0.00         2\n",
      "       Z9484       0.00      0.00      0.00         1\n",
      "        Z950       0.00      0.00      0.00         3\n",
      "        Z951       0.00      0.00      0.00        11\n",
      "        Z952       0.00      0.00      0.00         6\n",
      "        Z955       0.00      0.00      0.00         7\n",
      "      Z95810       0.00      0.00      0.00         3\n",
      "      Z95820       0.00      0.00      0.00         1\n",
      "      Z95828       0.00      0.00      0.00         1\n",
      "        Z961       0.00      0.00      0.00         1\n",
      "       Z9641       0.00      0.00      0.00         1\n",
      "      Z96611       0.00      0.00      0.00         0\n",
      "      Z96641       0.00      0.00      0.00         1\n",
      "      Z96649       0.00      0.00      0.00         2\n",
      "      Z96651       0.00      0.00      0.00         2\n",
      "      Z96652       0.00      0.00      0.00         1\n",
      "      Z96653       0.00      0.00      0.00         1\n",
      "        Z980       0.00      0.00      0.00         3\n",
      "        Z981       0.00      0.00      0.00         1\n",
      "       Z9861       0.00      0.00      0.00         3\n",
      "       Z9862       0.00      0.00      0.00         1\n",
      "       Z9911       0.00      0.00      0.00         1\n",
      "        Z992       0.00      0.00      0.00         8\n",
      "        Z993       0.00      0.00      0.00         5\n",
      "       Z9981       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.02      6000\n",
      "   macro avg       0.00      0.00      0.00      6000\n",
      "weighted avg       0.01      0.02      0.01      6000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/NLP_project/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/envs/NLP_project/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/envs/NLP_project/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/envs/NLP_project/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/envs/NLP_project/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/envs/NLP_project/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = '/Users/benjamintan/Downloads/mimic-iv-3.1/hosp/extracted_sections_sampled.csv'  # Replace with your CSV file path\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Preprocess: Combine columns of interest into a single text field\n",
    "df['combined_text'] = (\n",
    "    df['History of Present Illness'].fillna('') + ' ' +\n",
    "    df['Past Medical History'].fillna('') + ' ' +\n",
    "    df['Physical Exam'].fillna('')\n",
    ")\n",
    "\n",
    "# Load ClinicalBERT model and tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\")\n",
    "model = AutoModel.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\")\n",
    "\n",
    "# Function to generate embeddings using ClinicalBERT\n",
    "def get_embedding(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    # Use the [CLS] token representation as the sentence embedding\n",
    "    embedding = outputs.last_hidden_state[:, 0, :].squeeze().numpy()\n",
    "    return embedding\n",
    "\n",
    "# Generate embeddings for each row (this may take a while for a large dataset)\n",
    "embeddings = []\n",
    "for text in tqdm(df['combined_text'], desc=\"Generating Embeddings\"):\n",
    "    embeddings.append(get_embedding(text))\n",
    "\n",
    "# Convert embeddings to a DataFrame\n",
    "embeddings_df = pd.DataFrame(embeddings)\n",
    "\n",
    "# Prepare the labels and features\n",
    "X = embeddings_df\n",
    "y = df['icd_code']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a classifier (e.g., Logistic Regression) to predict ICD codes\n",
    "classifier = LogisticRegression(max_iter=1000)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PcJUc61qaaCY"
   },
   "source": [
    "# NER Feature Extraction then feed the features into SVM for training to predict ICD code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-08T13:08:43.361241Z",
     "iopub.status.busy": "2024-12-08T13:08:43.360753Z",
     "iopub.status.idle": "2024-12-08T13:08:48.108579Z",
     "shell.execute_reply": "2024-12-08T13:08:48.108273Z",
     "shell.execute_reply.started": "2024-12-08T13:08:43.361206Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "import scispacy\n",
    "from spacy import displacy\n",
    "from spacy.matcher import PhraseMatcher\n",
    "from spacy.tokens import Span\n",
    "from negspacy.negation import Negex\n",
    "\n",
    "# Load scispaCy models\n",
    "nlp0 = spacy.load(\"en_core_sci_sm\")\n",
    "nlp1 = spacy.load(\"en_ner_bc5cdr_md\")\n",
    "\n",
    "def lemmatize(note, nlp):\n",
    "    \"\"\"\n",
    "    Lemmatize the input text using the specified spaCy model\n",
    "    \n",
    "    Args:\n",
    "        note (str): Input text to lemmatize\n",
    "        nlp (spacy.lang.en.English): spaCy language model\n",
    "    \n",
    "    Returns:\n",
    "        str: Lemmatized text\n",
    "    \"\"\"\n",
    "    doc = nlp(note)\n",
    "    lemNote = [wd.lemma_ for wd in doc]\n",
    "    return \" \".join(lemNote)\n",
    "\n",
    "def get_entity_options():\n",
    "    \"\"\"\n",
    "    Define visualization options for Named Entities\n",
    "    \n",
    "    Returns:\n",
    "        dict: Visualization options for displaCy\n",
    "    \"\"\"\n",
    "    entities = [\"DISEASE\", \"CHEMICAL\", \"NEG_ENTITY\"]\n",
    "    colors = {\n",
    "        'DISEASE': 'linear-gradient(180deg, #66ffcc, #abf763)', \n",
    "        'CHEMICAL': 'linear-gradient(90deg, #aa9cfc, #fc9ce7)', \n",
    "        \"NEG_ENTITY\":'linear-gradient(90deg, #ffff66, #ff6600)'\n",
    "    }\n",
    "    return {\"ents\": entities, \"colors\": colors}\n",
    "\n",
    "def neg_model(nlp_model):\n",
    "    \"\"\"\n",
    "    Create a negation detection pipeline\n",
    "    \n",
    "    Args:\n",
    "        nlp_model (str): Path to spaCy model\n",
    "    \n",
    "    Returns:\n",
    "        spacy.lang.en.English: spaCy model with negation detection\n",
    "    \"\"\"\n",
    "    nlp = spacy.load(nlp_model, disable=['parser'])\n",
    "    nlp.add_pipe(nlp.create_pipe('sentencizer'))\n",
    "    \n",
    "    # Enhanced negation detection with custom patterns\n",
    "    negex = Negex(nlp)\n",
    "    negex.preceding_patterns += [nlp('deny'), nlp('refuse'), nlp('neither'), nlp('nor')]\n",
    "    negex.following_patterns += [nlp('absent'), nlp('deny'), nlp('decline')]\n",
    "    \n",
    "    nlp.add_pipe(negex)\n",
    "    return nlp\n",
    "\n",
    "def negation_handling(nlp_model, note, neg_model_func):\n",
    "    \"\"\"\n",
    "    Identify negated entities in the text\n",
    "    \n",
    "    Args:\n",
    "        nlp_model (str): Path to spaCy model\n",
    "        note (str): Input text\n",
    "        neg_model_func (function): Function to create negation model\n",
    "    \n",
    "    Returns:\n",
    "        list: Negated entities\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    nlp = neg_model_func(nlp_model)\n",
    "    \n",
    "    # Sentence tokenization\n",
    "    note_sentences = [n.strip() for n in note.split(\".\")]\n",
    "    \n",
    "    for sentence in note_sentences:\n",
    "        doc = nlp(sentence)\n",
    "        for entity in doc.ents:\n",
    "            if entity._.negex:\n",
    "                results.append(entity.text)\n",
    "    \n",
    "    return results\n",
    "\n",
    "def match(nlp, terms, label):\n",
    "    \"\"\"\n",
    "    Create a PhraseMatcher for specified terms\n",
    "    \n",
    "    Args:\n",
    "        nlp (spacy.lang.en.English): spaCy language model\n",
    "        terms (list): List of terms to match\n",
    "        label (str): Label for matched terms\n",
    "    \n",
    "    Returns:\n",
    "        spacy.matcher.PhraseMatcher: Configured phrase matcher\n",
    "    \"\"\"\n",
    "    patterns = [nlp.make_doc(text) for text in terms]\n",
    "    matcher = PhraseMatcher(nlp.vocab)\n",
    "    matcher.add(label, None, *patterns)\n",
    "    return matcher\n",
    "\n",
    "def overwrite_ent_lbl(matcher, doc):\n",
    "    \"\"\"\n",
    "    Update entity labels for matched terms\n",
    "    \n",
    "    Args:\n",
    "        matcher (spacy.matcher.PhraseMatcher): Phrase matcher\n",
    "        doc (spacy.tokens.Doc): spaCy document\n",
    "    \n",
    "    Returns:\n",
    "        spacy.tokens.Doc: Updated document with new entity labels\n",
    "    \"\"\"\n",
    "    matches = matcher(doc)\n",
    "    seen_tokens = set()\n",
    "    new_entities = []\n",
    "    entities = doc.ents\n",
    "    \n",
    "    for match_id, start, end in matches:\n",
    "        if start not in seen_tokens and end - 1 not in seen_tokens:\n",
    "            new_entities.append(Span(doc, start, end, label=match_id))\n",
    "            entities = [\n",
    "                e for e in entities if not (e.start < end and e.end > start)\n",
    "            ]\n",
    "            seen_tokens.update(range(start, end))\n",
    "    \n",
    "    doc.ents = tuple(entities) + tuple(new_entities)\n",
    "    return doc\n",
    "\n",
    "def process_clinical_notes(file_path):\n",
    "    \"\"\"\n",
    "    Main processing function for clinical notes in CSV\n",
    "    \n",
    "    Args:\n",
    "        file_path (str): Path to CSV file\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: Processed dataframe with NLP features\n",
    "    \"\"\"\n",
    "    # Load the CSV file\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Preprocess: Combine columns of interest\n",
    "    df['combined_text'] = (\n",
    "        df['History of Present Illness'].fillna('') + ' ' +\n",
    "        df['Past Medical History'].fillna('') + ' ' +\n",
    "        df['Physical Exam'].fillna('')\n",
    "    )\n",
    "    \n",
    "    # Lemmatize the combined text\n",
    "    df['lemmatized_text'] = df['combined_text'].apply(lambda x: lemmatize(x, nlp0))\n",
    "    \n",
    "    # Prepare visualization options\n",
    "    options = get_entity_options()\n",
    "    \n",
    "    # Process each note\n",
    "    def process_note(note):\n",
    "        try:\n",
    "            # Named Entity Recognition\n",
    "            doc = nlp1(note)\n",
    "            \n",
    "            # Negation Detection\n",
    "            neg_results = negation_handling(\"en_ner_bc5cdr_md\", note, neg_model)\n",
    "            \n",
    "            # Update entity labels\n",
    "            if neg_results:\n",
    "                matcher = match(nlp1, neg_results, \"NEG_ENTITY\")\n",
    "                doc = overwrite_ent_lbl(matcher, doc)\n",
    "            \n",
    "            # Render entities (this would typically be displayed or saved)\n",
    "            # displacy.render(doc, style='ent', options=options)\n",
    "            \n",
    "            return doc\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing note: {e}\")\n",
    "            return None\n",
    "    \n",
    "    # Apply processing to lemmatized text\n",
    "    df['processed_doc'] = df['lemmatized_text'].apply(process_note)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-08T13:17:23.855941Z",
     "iopub.status.busy": "2024-12-08T13:17:23.855573Z",
     "iopub.status.idle": "2024-12-08T13:17:28.588214Z",
     "shell.execute_reply": "2024-12-08T13:17:28.587963Z",
     "shell.execute_reply.started": "2024-12-08T13:17:23.855916Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "import scispacy\n",
    "from spacy import displacy\n",
    "from spacy.matcher import PhraseMatcher\n",
    "from spacy.tokens import Span\n",
    "from negspacy.negation import Negex\n",
    "\n",
    "# Load scispaCy models\n",
    "nlp0 = spacy.load(\"en_core_sci_sm\")\n",
    "nlp1 = spacy.load(\"en_ner_bc5cdr_md\")\n",
    "\n",
    "def lemmatize(note, nlp):\n",
    "    \"\"\"Lemmatize the input text\"\"\"\n",
    "    doc = nlp(note)\n",
    "    lemNote = [wd.lemma_ for wd in doc]\n",
    "    return \" \".join(lemNote)\n",
    "\n",
    "def get_entity_options():\n",
    "    \"\"\"Define visualization options for Named Entities\"\"\"\n",
    "    entities = [\"DISEASE\", \"CHEMICAL\", \"NEG_ENTITY\"]\n",
    "    colors = {\n",
    "        'DISEASE': 'linear-gradient(180deg, #66ffcc, #abf763)', \n",
    "        'CHEMICAL': 'linear-gradient(90deg, #aa9cfc, #fc9ce7)', \n",
    "        \"NEG_ENTITY\":'linear-gradient(90deg, #ffff66, #ff6600)'\n",
    "    }\n",
    "    return {\"ents\": entities, \"colors\": colors}\n",
    "\n",
    "def process_single_note(file_path, row_index):\n",
    "    \"\"\"\n",
    "    Process and visualize a single note from the CSV\n",
    "    \n",
    "    Args:\n",
    "        file_path (str): Path to CSV file\n",
    "        row_index (int): Index of the row to process\n",
    "    \"\"\"\n",
    "    # Load the CSV file\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Combine columns of interest\n",
    "    combined_text = (\n",
    "        df['History of Present Illness'].fillna('').iloc[row_index] + ' ' +\n",
    "        df['Past Medical History'].fillna('').iloc[row_index] + ' ' +\n",
    "        df['Physical Exam'].fillna('').iloc[row_index]\n",
    "    )\n",
    "    \n",
    "    # Lemmatize the text\n",
    "    lemmatized_text = lemmatize(combined_text, nlp0)\n",
    "    \n",
    "    # Prepare visualization options\n",
    "    options = get_entity_options()\n",
    "    \n",
    "    # Process the note with NER\n",
    "    doc = nlp1(lemmatized_text)\n",
    "    \n",
    "    # Print original entities\n",
    "    print(\"Original Named Entities:\")\n",
    "    for ent in doc.ents:\n",
    "        print(f\"{ent.text} - {ent.label_}\")\n",
    "    \n",
    "    # Negation Detection\n",
    "    def custom_neg_handling(doc):\n",
    "        \"\"\"\n",
    "        Custom negation detection with predefined negation terms\n",
    "        \"\"\"\n",
    "        # Common negation terms\n",
    "        negation_terms = [\n",
    "            'no', 'not', 'neither', 'never', 'none', \n",
    "            'denied', 'deny', 'absence', 'without', \n",
    "            'rule out', 'ruled out'\n",
    "        ]\n",
    "        \n",
    "        negated_entities = []\n",
    "        \n",
    "        # Iterate through sentences\n",
    "        for sent in doc.sents:\n",
    "            # Check for negation terms near entities\n",
    "            for ent in sent.ents:\n",
    "                # Look at surrounding tokens for negation\n",
    "                context = [token.lower_ for token in sent if abs(token.idx - ent.start_char) < 20]\n",
    "                if any(neg in context for neg in negation_terms):\n",
    "                    negated_entities.append(ent.text)\n",
    "        \n",
    "        return negated_entities\n",
    "    \n",
    "    # Get negated entities using custom method\n",
    "    neg_results = []\n",
    "    try:\n",
    "        # Try custom negation detection\n",
    "        neg_results = custom_neg_handling(doc)\n",
    "    except Exception as e:\n",
    "        print(f\"Error in negation detection: {e}\")\n",
    "    \n",
    "    print(\"\\nNegated Entities:\")\n",
    "    print(neg_results)\n",
    "    \n",
    "    # Prepare entity information\n",
    "    entity_info = []\n",
    "    for ent in doc.ents:\n",
    "        entity_info.append({\n",
    "            'text': ent.text,\n",
    "            'label': ent.label_,\n",
    "            'negated': ent.text in neg_results\n",
    "        })\n",
    "    \n",
    "    # Print detailed entity information\n",
    "    print(\"\\nDetailed Entity Information:\")\n",
    "    for info in entity_info:\n",
    "        print(f\"Entity: {info['text']} (Type: {info['label']}, Negated: {info['negated']})\")\n",
    "    \n",
    "    # Visualize entities\n",
    "    print(\"\\nEntity Visualization:\")\n",
    "    try:\n",
    "        displacy.serve(doc, style='ent', options=options)\n",
    "    except Exception as e:\n",
    "        print(f\"Visualization error: {e}\")\n",
    "    \n",
    "    # Return the processed document and entity information\n",
    "    return doc, entity_info\n",
    "\n",
    "# Uncomment and run\n",
    "# process_single_note('extracted_sections_sampled.csv', 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-08T13:17:28.588883Z",
     "iopub.status.busy": "2024-12-08T13:17:28.588803Z",
     "iopub.status.idle": "2024-12-08T13:17:29.093496Z",
     "shell.execute_reply": "2024-12-08T13:17:29.093254Z",
     "shell.execute_reply.started": "2024-12-08T13:17:28.588876Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Named Entities:\n",
      "heart failure - DISEASE\n",
      "pulmonary hypertension - DISEASE\n",
      "MCA stroke - CHEMICAL\n",
      "l hemiparesis - DISEASE\n",
      "seizure - DISEASE\n",
      "s/p decease donor renal transplant - DISEASE\n",
      "htn - DISEASE\n",
      "Pain - DISEASE\n",
      "inferior ischemia - DISEASE\n",
      "leave hemiparesis - DISEASE\n",
      "seizure - DISEASE\n",
      "ESRD - DISEASE\n",
      "hypertension - DISEASE\n",
      "depression - DISEASE\n",
      "anxiety - DISEASE\n",
      "pain - DISEASE\n",
      "osteomyelitis - DISEASE\n",
      "CAD - DISEASE\n",
      "arthritis - DISEASE\n",
      "Father - colorectal cancer - DISEASE\n",
      "erythema - DISEASE\n",
      "tenderness - DISEASE\n",
      "infection - DISEASE\n",
      "redness - DISEASE\n",
      "perrl - DISEASE\n",
      "\n",
      "Negated Entities:\n",
      "['redness']\n",
      "\n",
      "Detailed Entity Information:\n",
      "Entity: heart failure (Type: DISEASE, Negated: False)\n",
      "Entity: pulmonary hypertension (Type: DISEASE, Negated: False)\n",
      "Entity: MCA stroke (Type: CHEMICAL, Negated: False)\n",
      "Entity: l hemiparesis (Type: DISEASE, Negated: False)\n",
      "Entity: seizure (Type: DISEASE, Negated: False)\n",
      "Entity: s/p decease donor renal transplant (Type: DISEASE, Negated: False)\n",
      "Entity: htn (Type: DISEASE, Negated: False)\n",
      "Entity: Pain (Type: DISEASE, Negated: False)\n",
      "Entity: inferior ischemia (Type: DISEASE, Negated: False)\n",
      "Entity: leave hemiparesis (Type: DISEASE, Negated: False)\n",
      "Entity: seizure (Type: DISEASE, Negated: False)\n",
      "Entity: ESRD (Type: DISEASE, Negated: False)\n",
      "Entity: hypertension (Type: DISEASE, Negated: False)\n",
      "Entity: depression (Type: DISEASE, Negated: False)\n",
      "Entity: anxiety (Type: DISEASE, Negated: False)\n",
      "Entity: pain (Type: DISEASE, Negated: False)\n",
      "Entity: osteomyelitis (Type: DISEASE, Negated: False)\n",
      "Entity: CAD (Type: DISEASE, Negated: False)\n",
      "Entity: arthritis (Type: DISEASE, Negated: False)\n",
      "Entity: Father - colorectal cancer (Type: DISEASE, Negated: False)\n",
      "Entity: erythema (Type: DISEASE, Negated: False)\n",
      "Entity: tenderness (Type: DISEASE, Negated: False)\n",
      "Entity: infection (Type: DISEASE, Negated: False)\n",
      "Entity: redness (Type: DISEASE, Negated: True)\n",
      "Entity: perrl (Type: DISEASE, Negated: False)\n",
      "\n",
      "Entity Visualization:\n",
      "Visualization error: [E1050] Port 5000 is already in use. Please specify an available port with `displacy.serve(doc, port=port)` or use `auto_select_port=True` to pick an available port automatically.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(_ _ _ be a _ _ _ year old female with history of chronic \n",
       "  diastolic heart failure , pulmonary hypertension , cad , partial r \n",
       "  MCA stroke ( mild l hemiparesis and seizure disorder _ _ _ , \n",
       "  esrd ( s/p decease donor renal transplant at _ _ _ [ _ _ _ ] \n",
       "  complicated by ckd ) , htn , Depression/Anxiety , Chronic Pain \n",
       "  ( recently find to have violate opiate contract ) , and new \n",
       "  diagnosis of esrd ( now on hd _ _ _ who present for evaluation \n",
       "  of weakness . - chronic diastolic heart failure \n",
       "  - pah with rv dilation \n",
       "  - stable cad w/reversible inferior ischemia on stress test \n",
       "  ( _ _ _ ) \n",
       "  - Partial R MCA stroke w/ mild leave hemiparesis and seizure d/o \n",
       "  ( _ _ _ ) \n",
       "  - ESRD s/p ddrt at _ _ _ ( _ _ _ ) c/b ckd stage iv \n",
       "  - hypertension \n",
       "  - depression and anxiety \n",
       "  - chronic lle pain \n",
       "  - leave tkr _ _ _ c/b mssa pji s/p hardware removal , \n",
       "  antibiotic spacer , and multiple washout . \n",
       "  - Pathological left tibia fracture _ _ _ ( presumed \n",
       "  osteomyelitis ) ; fail conservative therapy with _ _ _ , s/p \n",
       "  orif _ _ _ with gpc/gpr find in wound . \n",
       "  \n",
       "  social history : \n",
       "  _ _ _ \n",
       "  Family history : \n",
       "  Mother - CAD , _ _ _ , arthritis \n",
       "  Father - colorectal cancer \n",
       "  sister - _ _ _ = = = = = = = = = = = = = = = = = = = = \n",
       "  ADMISSION exam \n",
       "  = = = = = = = = = = = = = = = = = = = = \n",
       "  Vitals : t : 99.5   bp : 108/71 p : 86 r : 14 o2 : 94 % on ra \n",
       "  GENERAL : lie across bed with _ _ _ off , alert & orient x3 , \n",
       "  moaning  \n",
       "  heent : Sclera anicteric , dry mm , oropharynx clear  \n",
       "  neck : supple \n",
       "  lung : clear to auscultation bilaterally  \n",
       "  cv : regular rate and rhythm , normal s1 s2 , no murmur , rub , \n",
       "  gallop  \n",
       "  abd : soft , non-tender , non-distended , bowel sound present \n",
       "  chest : left ij tunnel line without significant erythema or \n",
       "  discharge . tender over line site . \n",
       "  ext : right hip with tenderness to palpation but able to move leg \n",
       "  without difficulty . warm , well perfused , left knee with bony \n",
       "  malformation , leave low leg with bone spur , surgical scar over \n",
       "  left knee and leave low leg .   \n",
       "  skin :   right thigh with site of prior infection well heal , no \n",
       "  redness or warmth over site . \n",
       "  neuro : move all four extremity without difficulty , perrl , \n",
       "  eomi,\n",
       " [{'text': 'heart failure', 'label': 'DISEASE', 'negated': False},\n",
       "  {'text': 'pulmonary hypertension', 'label': 'DISEASE', 'negated': False},\n",
       "  {'text': 'MCA stroke', 'label': 'CHEMICAL', 'negated': False},\n",
       "  {'text': 'l hemiparesis', 'label': 'DISEASE', 'negated': False},\n",
       "  {'text': 'seizure', 'label': 'DISEASE', 'negated': False},\n",
       "  {'text': 's/p decease donor renal transplant',\n",
       "   'label': 'DISEASE',\n",
       "   'negated': False},\n",
       "  {'text': 'htn', 'label': 'DISEASE', 'negated': False},\n",
       "  {'text': 'Pain', 'label': 'DISEASE', 'negated': False},\n",
       "  {'text': 'inferior ischemia', 'label': 'DISEASE', 'negated': False},\n",
       "  {'text': 'leave hemiparesis', 'label': 'DISEASE', 'negated': False},\n",
       "  {'text': 'seizure', 'label': 'DISEASE', 'negated': False},\n",
       "  {'text': 'ESRD', 'label': 'DISEASE', 'negated': False},\n",
       "  {'text': 'hypertension', 'label': 'DISEASE', 'negated': False},\n",
       "  {'text': 'depression', 'label': 'DISEASE', 'negated': False},\n",
       "  {'text': 'anxiety', 'label': 'DISEASE', 'negated': False},\n",
       "  {'text': 'pain', 'label': 'DISEASE', 'negated': False},\n",
       "  {'text': 'osteomyelitis', 'label': 'DISEASE', 'negated': False},\n",
       "  {'text': 'CAD', 'label': 'DISEASE', 'negated': False},\n",
       "  {'text': 'arthritis', 'label': 'DISEASE', 'negated': False},\n",
       "  {'text': 'Father - colorectal cancer', 'label': 'DISEASE', 'negated': False},\n",
       "  {'text': 'erythema', 'label': 'DISEASE', 'negated': False},\n",
       "  {'text': 'tenderness', 'label': 'DISEASE', 'negated': False},\n",
       "  {'text': 'infection', 'label': 'DISEASE', 'negated': False},\n",
       "  {'text': 'redness', 'label': 'DISEASE', 'negated': True},\n",
       "  {'text': 'perrl', 'label': 'DISEASE', 'negated': False}])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_single_note('extracted_sections_sampled.csv', 90)\n",
    "\n",
    "#processed_df = process_clinical_notes('extracted_sections_sampled.csv')\n",
    "#processed_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T08:30:39.087411Z",
     "iopub.status.busy": "2024-12-10T08:30:39.086698Z",
     "iopub.status.idle": "2024-12-10T08:30:45.511272Z",
     "shell.execute_reply": "2024-12-10T08:30:45.511040Z",
     "shell.execute_reply.started": "2024-12-10T08:30:39.087369Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV Columns: ['hadm_id', 'admission_type', 'admit_provider_id', 'admission_location', 'marital_status', 'race', 'seq_num', 'icd_code', 'icd_version', 'note_id', 'subject_id', 'note_type', 'note_seq', 'History of Present Illness', 'Past Medical History', 'Physical Exam']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/NLP_project/lib/python3.12/site-packages/spacy/language.py:2195: FutureWarning: Possible set union at position 6328\n",
      "  deserializers[\"tokenizer\"] = lambda p: self.tokenizer.from_disk(  # type: ignore[union-attr]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Negation Analysis:\n",
      "Negated Entities: ['respiratory distress', 'wheeze', 'rash']\n",
      "\n",
      "Detailed Negation Information:\n",
      "Entity: respiratory distress (Type: DISEASE)\n",
      "Context: : appear in no respiratory distress , clear\n",
      "Negation Type: direct\n",
      "\n",
      "Entity: wheeze (Type: DISEASE)\n",
      "Context: , no crackle , wheeze , or rhonchi \n",
      "  gastrointestinal\n",
      "Negation Type: direct\n",
      "\n",
      "Entity: rash (Type: DISEASE)\n",
      "Context: \n",
      "  skin : no significant rash\n",
      "Negation Type: direct\n",
      "\n",
      "\n",
      "Detected Entities:\n",
      "pancreatic cancer (Type: DISEASE)\n",
      "gemcitabine (Type: CHEMICAL)\n",
      "pain (Type: DISEASE)\n",
      "cancer (Type: DISEASE)\n",
      "-lumbar disc disease (Type: DISEASE)\n",
      "sciatica (Type: DISEASE)\n",
      "-anxiety (Type: DISEASE)\n",
      "femur fracture (Type: DISEASE)\n",
      "perll (Type: CHEMICAL)\n",
      "respiratory distress (Type: NEG_ENTITY)\n",
      "wheeze (Type: NEG_ENTITY)\n",
      "rhonchi (Type: DISEASE)\n",
      "edema (Type: DISEASE)\n",
      "rash (Type: NEG_ENTITY)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><!DOCTYPE html>\n",
       "<html lang=\"en\">\n",
       "    <head>\n",
       "        <title>displaCy</title>\n",
       "    </head>\n",
       "\n",
       "    <body style=\"font-size: 16px; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol'; padding: 4rem 2rem; direction: ltr\">\n",
       "<figure style=\"margin-bottom: 6rem\">\n",
       "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">_ _ _ be a _ _ _ year old woman with borderline resectable <br> \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(180deg, #66ffcc, #abf763); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    pancreatic cancer\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DISEASE</span>\n",
       "</mark>\n",
       " , currently on single agent \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(90deg, #aa9cfc, #fc9ce7); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    gemcitabine\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CHEMICAL</span>\n",
       "</mark>\n",
       " , who be <br> admit from the _ _ _ with rigor , acute on chronic abdominal <br> \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(180deg, #66ffcc, #abf763); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    pain\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DISEASE</span>\n",
       "</mark>\n",
       " <br> and malaise . -pancreatic \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(180deg, #66ffcc, #abf763); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    cancer\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DISEASE</span>\n",
       "</mark>\n",
       " <br> -dm2 <br> -HTN <br> -hypothyroidism <br> -osteoporosis <br> -knee oa <br> \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(180deg, #66ffcc, #abf763); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    -lumbar disc disease\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DISEASE</span>\n",
       "</mark>\n",
       " with l \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(180deg, #66ffcc, #abf763); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    sciatica\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DISEASE</span>\n",
       "</mark>\n",
       " <br> \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(180deg, #66ffcc, #abf763); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    -anxiety\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DISEASE</span>\n",
       "</mark>\n",
       " <br> -s/p l \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(180deg, #66ffcc, #abf763); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    femur fracture\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DISEASE</span>\n",
       "</mark>\n",
       " with surgical repair ( _ _ _ ) <br> -s/p hysterectomy ( _ _ _ ) <br> -s/p remote tonsillectomy . admission physical exam :  <br> v : t 98.2 hr 80 bp 112/70 rr 18 sat   100 % o2 on ra <br> GENERAL : pleasant woman lay in bed in no distress <br> eyes : Anicteric sclerea , \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(90deg, #aa9cfc, #fc9ce7); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    perll\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CHEMICAL</span>\n",
       "</mark>\n",
       " , eomi ; <br> ent : oropharynx clear without lesion , JVD not elevated <br> cardiovascular : regular rate and rhythm , no murmur , rub , or <br> gallop ; <br> RESPIRATORY : appear in no \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(90deg, #ffff66, #ff6600); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    respiratory distress\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NEG_ENTITY</span>\n",
       "</mark>\n",
       " , clear to <br> auscultation bilaterally , no crackle , \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(90deg, #ffff66, #ff6600); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    wheeze\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NEG_ENTITY</span>\n",
       "</mark>\n",
       " , or \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(180deg, #66ffcc, #abf763); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    rhonchi\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DISEASE</span>\n",
       "</mark>\n",
       " <br> gastrointestinal : Obsese . normal bowel sound ; nondistended ; <br> tender in epigastrum without rebound . no _ _ _ sign . <br> muskuloskelatal : normal bulk . 2 + pit \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(180deg, #66ffcc, #abf763); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    edema\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DISEASE</span>\n",
       "</mark>\n",
       " in leg up to <br> thigh and in hand bilaterally <br> neuro : Alert although have some increase speech latency , <br> orient , cn ii-xii intact , motor and sensory function grossly <br> intact but be generally weak throughout <br> skin : no significant \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(90deg, #ffff66, #ff6600); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    rash\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NEG_ENTITY</span>\n",
       "</mark>\n",
       "</div>\n",
       "</figure>\n",
       "</body>\n",
       "</html></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Visualization saved to: ner_visualizations/ner_visualization_row_20.html\n",
      "\n",
      "Open the HTML file at: ner_visualizations/ner_visualization_row_20.html\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "import scispacy\n",
    "from spacy import displacy\n",
    "from spacy.matcher import PhraseMatcher\n",
    "from spacy.tokens import Span\n",
    "import os\n",
    "\n",
    "def lemmatize(note, nlp):\n",
    "    \"\"\"Lemmatize the input text to capture different word forms\"\"\"\n",
    "    doc = nlp(note)\n",
    "    lemNote = [wd.lemma_ for wd in doc]\n",
    "    return \" \".join(lemNote)\n",
    "\n",
    "def get_entity_options():\n",
    "    \"\"\"Define visualization options for Named Entities\"\"\"\n",
    "    entities = [\"DISEASE\", \"CHEMICAL\", \"NEG_ENTITY\"]\n",
    "    colors = {\n",
    "        'DISEASE': 'linear-gradient(180deg, #66ffcc, #abf763)', \n",
    "        'CHEMICAL': 'linear-gradient(90deg, #aa9cfc, #fc9ce7)', \n",
    "        \"NEG_ENTITY\": 'linear-gradient(90deg, #ffff66, #ff6600)'\n",
    "    }\n",
    "    return {\"ents\": entities, \"colors\": colors}\n",
    "\n",
    "def custom_neg_handling(doc):\n",
    "    \"\"\"\n",
    "    Enhanced negation detection with comprehensive context analysis\n",
    "    \n",
    "    Args:\n",
    "        doc (spacy.tokens.Doc): Processed spaCy document\n",
    "    \n",
    "    Returns:\n",
    "        dict: A dictionary with detailed negation information\n",
    "    \"\"\"\n",
    "    # Comprehensive negation terms and patterns\n",
    "    negation_terms = {\n",
    "        'direct': [\n",
    "            'no', 'not', 'never', 'neither', 'none', \n",
    "            'absence', 'absent', 'denied', 'deny', \n",
    "            'rule out', 'ruled out', 'without', 'hasn\\'t', \n",
    "            'haven\\'t', 'didn\\'t', 'don\\'t', 'cannot', \n",
    "            'can\\'t', 'no evidence', 'negates', 'negative'\n",
    "        ],\n",
    "        'pre_modifiers': [\n",
    "            'unlikely', 'improbable', 'doubtful', \n",
    "            'unconfirmed', 'unconvinced'\n",
    "        ],\n",
    "        'post_modifiers': [\n",
    "            'free', 'clear', 'resolved', 'eliminated'\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    negation_results = {\n",
    "        'negated_entities': [],\n",
    "        'detailed_negations': []\n",
    "    }\n",
    "    \n",
    "    # Iterate through sentences\n",
    "    for sent in doc.sents:\n",
    "        for ent in sent.ents:\n",
    "            # Wider context window for negation detection\n",
    "            context_window = 25  # characters before and after the entity\n",
    "            \n",
    "            # Extract context tokens\n",
    "            context_tokens = [\n",
    "                token for token in sent \n",
    "                if abs(token.idx - ent.start_char) < context_window\n",
    "            ]\n",
    "            \n",
    "            # Convert context to lowercase for easier matching\n",
    "            context_lower = [token.lower_ for token in context_tokens]\n",
    "            \n",
    "            # Check for direct negation terms\n",
    "            is_negated = any(neg in context_lower for neg in negation_terms['direct'])\n",
    "            \n",
    "            # Check for pre and post negation modifiers\n",
    "            pre_neg = any(mod in context_lower[:3] for mod in negation_terms['pre_modifiers'])\n",
    "            post_neg = any(mod in context_lower[-3:] for mod in negation_terms['post_modifiers'])\n",
    "            \n",
    "            # Detailed negation analysis\n",
    "            if is_negated or pre_neg or post_neg:\n",
    "                negation_details = {\n",
    "                    'entity': ent.text,\n",
    "                    'type': ent.label_,\n",
    "                    'context': ' '.join([token.text for token in context_tokens]),\n",
    "                    'negation_type': 'direct' if is_negated else 'modified'\n",
    "                }\n",
    "                \n",
    "                negation_results['negated_entities'].append(ent.text)\n",
    "                negation_results['detailed_negations'].append(negation_details)\n",
    "    \n",
    "    return negation_results\n",
    "\n",
    "def print_negation_analysis(negation_results):\n",
    "    \"\"\"\n",
    "    Print a detailed analysis of negated entities\n",
    "    \n",
    "    Args:\n",
    "        negation_results (dict): Negation analysis results\n",
    "    \"\"\"\n",
    "    print(\"\\nNegation Analysis:\")\n",
    "    if not negation_results['negated_entities']:\n",
    "        print(\"No negated entities found.\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Negated Entities: {negation_results['negated_entities']}\")\n",
    "    print(\"\\nDetailed Negation Information:\")\n",
    "    for neg in negation_results['detailed_negations']:\n",
    "        print(f\"Entity: {neg['entity']} (Type: {neg['type']})\")\n",
    "        print(f\"Context: {neg['context']}\")\n",
    "        print(f\"Negation Type: {neg['negation_type']}\\n\")\n",
    "\n",
    "def process_single_note(file_path, row_index, output_dir='ner_visualizations'):\n",
    "    \"\"\"\n",
    "    Process and visualize a single note from the CSV with enhanced output\n",
    "    \n",
    "    Args:\n",
    "        file_path (str): Path to CSV file\n",
    "        row_index (int): Index of the row to process\n",
    "        output_dir (str): Directory to save visualization output\n",
    "    \"\"\"\n",
    "    # Load scispaCy models\n",
    "    try:\n",
    "        nlp0 = spacy.load(\"en_core_sci_sm\")\n",
    "        nlp1 = spacy.load(\"en_ner_bc5cdr_md\")\n",
    "    except OSError as e:\n",
    "        print(f\"Error loading spaCy models: {e}\")\n",
    "        print(\"Make sure you have installed the models using:\")\n",
    "        print(\"python -m spacy download en_core_sci_sm\")\n",
    "        print(\"python -m spacy download en_ner_bc5cdr_md\")\n",
    "        raise\n",
    "\n",
    "    # Create output directory if it doesn't exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Load the CSV file\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Combine columns of interest\n",
    "    try:\n",
    "        combined_text = (\n",
    "            df['History of Present Illness'].fillna('').iloc[row_index] + ' ' +\n",
    "            df['Past Medical History'].fillna('').iloc[row_index] + ' ' +\n",
    "            df['Physical Exam'].fillna('').iloc[row_index]\n",
    "        )\n",
    "    except KeyError as e:\n",
    "        print(f\"Column not found in the CSV: {e}\")\n",
    "        print(\"Available columns:\", list(df.columns))\n",
    "        raise\n",
    "    except IndexError:\n",
    "        print(f\"Row index {row_index} is out of bounds. Total rows: {len(df)}\")\n",
    "        raise\n",
    "\n",
    "    # Lemmatize the text\n",
    "    lemmatized_text = lemmatize(combined_text, nlp0)\n",
    "    \n",
    "    # Prepare visualization options\n",
    "    options = get_entity_options()\n",
    "    \n",
    "    # Process the note with NER\n",
    "    doc = nlp1(lemmatized_text)\n",
    "    \n",
    "    # Get negated entities\n",
    "    neg_results = custom_neg_handling(doc)\n",
    "    \n",
    "    # Print negation analysis\n",
    "    print_negation_analysis(neg_results)\n",
    "    \n",
    "    # Modify entities to include negation\n",
    "    negated_entities = neg_results['negated_entities']\n",
    "    neg_entity_label = \"NEG_ENTITY\"\n",
    "\n",
    "    if neg_entity_label not in doc.vocab.strings:\n",
    "      doc.vocab.strings.add(neg_entity_label)\n",
    "    # Create a new list of entities to replace the existing ones\n",
    "    modified_entities = []\n",
    "    for ent in doc.ents:\n",
    "        if ent.text in negated_entities:\n",
    "            # Create a new span with NEG_ENTITY label\n",
    "            new_ent = Span(doc, ent.start, ent.end, label=doc.vocab.strings[\"NEG_ENTITY\"])\n",
    "            modified_entities.append(new_ent)\n",
    "        else:\n",
    "            modified_entities.append(ent)\n",
    "    \n",
    "    # Replace the document's entities\n",
    "    doc.ents = tuple(modified_entities)\n",
    "    \n",
    "    # Diagnostic print for entities\n",
    "    print(\"\\nDetected Entities:\")\n",
    "    for ent in doc.ents:\n",
    "        print(f\"{ent.text} (Type: {ent.label_})\")\n",
    "\n",
    "    # Prepare the HTML visualization with explicit parameters\n",
    "    try:\n",
    "        html = displacy.render(doc, style='ent', options=options, page=True)\n",
    "        \n",
    "        # Ensure html is a string \n",
    "        if not isinstance(html, str):\n",
    "            html = str(html)\n",
    "        \n",
    "        # Generate output file path\n",
    "        output_file = os.path.join(output_dir, f'ner_visualization_row_{row_index}.html')\n",
    "        \n",
    "        # Write the visualization to an HTML file\n",
    "        with open(output_file, 'w', encoding='utf-8') as f:\n",
    "            f.write(html)\n",
    "        \n",
    "        print(f\"\\nVisualization saved to: {output_file}\")\n",
    "        \n",
    "        return doc, output_file\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating HTML visualization: {e}\")\n",
    "        raise\n",
    "\n",
    "# Diagnostic function to check CSV contents\n",
    "def preview_csv(file_path, num_rows=5):\n",
    "    \"\"\"\n",
    "    Preview the contents of the CSV file\n",
    "    \n",
    "    Args:\n",
    "        file_path (str): Path to the CSV file\n",
    "        num_rows (int): Number of rows to preview\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(file_path)\n",
    "    print(\"CSV Columns:\", list(df.columns))\n",
    "\n",
    "# Example usage with error handling\n",
    "def main():\n",
    "    try:\n",
    "        # First, preview the CSV to understand its structure\n",
    "        preview_csv('extracted_sections_sampled.csv')\n",
    "        \n",
    "        # Then attempt to process a specific row\n",
    "        doc, output_file = process_single_note('extracted_sections_sampled.csv', 20)\n",
    "        print(f\"\\nOpen the HTML file at: {output_file}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use this to extract the diseases into a new column. Save the new file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T08:37:40.316142Z",
     "iopub.status.busy": "2024-12-11T08:37:40.315774Z",
     "iopub.status.idle": "2024-12-11T12:16:02.850757Z",
     "shell.execute_reply": "2024-12-11T12:16:02.850378Z",
     "shell.execute_reply.started": "2024-12-11T08:37:40.316115Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 50000 rows...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50000/50000 [3:38:15<00:00,  3.82it/s]      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed CSV saved to: extracted_sections_with_diseases.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "import scispacy\n",
    "import os\n",
    "from tqdm import tqdm  # For progress tracking\n",
    "\n",
    "def extract_diseases_from_note(note, nlp0, nlp1):\n",
    "    \"\"\"\n",
    "    Extract diseases from a medical note using NER with negation handling.\n",
    "\n",
    "    Args:\n",
    "        note (str): Medical note text\n",
    "        nlp0 (spacy.language.Language): Lemmatization model\n",
    "        nlp1 (spacy.language.Language): NER model\n",
    "\n",
    "    Returns:\n",
    "        list: List of unique disease entities\n",
    "    \"\"\"\n",
    "    # Lemmatize the text\n",
    "    lemmatized_text = lemmatize(note, nlp0)\n",
    "    \n",
    "    # Process the note with NER\n",
    "    doc = nlp1(lemmatized_text)\n",
    "\n",
    "    # Add NEG_ENTITY label to StringStore\n",
    "    neg_entity_label = \"NEG_ENTITY\"\n",
    "    if neg_entity_label not in doc.vocab.strings:\n",
    "        doc.vocab.strings.add(neg_entity_label)\n",
    "\n",
    "    # Detect negated entities\n",
    "    neg_results = custom_neg_handling(doc)\n",
    "\n",
    "    # Extract unique diseases excluding negated entities\n",
    "    negated_entities = neg_results['negated_entities']\n",
    "    diseases = set(ent.text for ent in doc.ents if ent.label_ == 'DISEASE' and ent.text not in negated_entities)\n",
    "\n",
    "    return list(diseases)\n",
    "\n",
    "def lemmatize(note, nlp):\n",
    "    \"\"\"Lemmatize the input text\"\"\"\n",
    "    doc = nlp(note)\n",
    "    return \" \".join([wd.lemma_ for wd in doc])\n",
    "\n",
    "def custom_neg_handling(doc):\n",
    "    \"\"\"\n",
    "    Perform custom negation detection on a spaCy document.\n",
    "\n",
    "    Args:\n",
    "        doc (spacy.tokens.Doc): Processed spaCy document.\n",
    "\n",
    "    Returns:\n",
    "        dict: Dictionary with negated entities and detailed negation information.\n",
    "    \"\"\"\n",
    "    negation_terms = {\n",
    "        'direct': [\n",
    "            'no', 'not', 'never', 'neither', 'none', \n",
    "            'absence', 'absent', 'denied', 'deny', 'denie',\n",
    "            'rule out', 'ruled out', 'without', 'hasn\\'t', \n",
    "            'haven\\'t', 'didn\\'t', 'don\\'t', 'cannot', \n",
    "            'can\\'t', 'no evidence', 'negates', 'negative'\n",
    "        ],\n",
    "        'pre_modifiers': [\n",
    "            'unlikely', 'improbable', 'doubtful', \n",
    "            'unconfirmed', 'unconvinced'\n",
    "        ],\n",
    "        'post_modifiers': [\n",
    "            'free', 'clear', 'resolved', 'eliminated'\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    negation_results = {\n",
    "        'negated_entities': [],\n",
    "        'detailed_negations': []\n",
    "    }\n",
    "    \n",
    "    for ent in doc.ents:\n",
    "        context_window = 25\n",
    "        context_tokens = [\n",
    "            token.text.lower() for token in doc[max(0, ent.start - 5): min(len(doc), ent.end + 5)]\n",
    "        ]\n",
    "        if any(term in context_tokens for term in negation_terms):\n",
    "            negation_results['negated_entities'].append(ent.text)\n",
    "\n",
    "    return negation_results\n",
    "\n",
    "def process_csv_with_ner(input_file, output_file):\n",
    "    \"\"\"\n",
    "    Process entire CSV file and extract diseases for each row.\n",
    "\n",
    "    Args:\n",
    "        input_file (str): Path to input CSV.\n",
    "        output_file (str): Path to output CSV.\n",
    "    \"\"\"\n",
    "    # Load scispaCy models\n",
    "    try:\n",
    "        nlp0 = spacy.load(\"en_core_sci_sm\")\n",
    "        nlp1 = spacy.load(\"en_ner_bc5cdr_md\")\n",
    "    except OSError as e:\n",
    "        print(f\"Error loading spaCy models: {e}\")\n",
    "        raise\n",
    "\n",
    "    # Load the CSV file\n",
    "    df = pd.read_csv(input_file)\n",
    "    \n",
    "    # Add new column for extracted diseases\n",
    "    df['extracted_diseases'] = None\n",
    "\n",
    "    print(f\"Processing {len(df)} rows...\")\n",
    "    for index, row in tqdm(df.iterrows(), total=len(df)):\n",
    "        try:\n",
    "            clinical_notes = row['clinical_notes']  # Correctly reference the clinical_notes column\n",
    "          \n",
    "            # Extract diseases\n",
    "            diseases = extract_diseases_from_note(clinical_notes, nlp0, nlp1)\n",
    "            \n",
    "            # Save diseases to the new column\n",
    "            df.at[index, 'extracted_diseases'] = '; '.join(diseases) if diseases else None\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing row {index}: {e}\")\n",
    "    \n",
    "    # Save updated CSV\n",
    "    df.to_csv(output_file, index=False)\n",
    "    print(f\"\\nProcessed CSV saved to: {output_file}\")\n",
    "\n",
    "def main():\n",
    "    try:\n",
    "        input_file = 'df_sampled.csv'\n",
    "        output_file = 'extracted_sections_with_diseases.csv'\n",
    "        \n",
    "        process_csv_with_ner(input_file, output_file)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Added 'denie' into the neg_entity checker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T05:57:55.879106Z",
     "iopub.status.busy": "2024-12-11T05:57:55.878428Z",
     "iopub.status.idle": "2024-12-11T05:58:01.933982Z",
     "shell.execute_reply": "2024-12-11T05:58:01.933716Z",
     "shell.execute_reply.started": "2024-12-11T05:57:55.879066Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV Columns: ['hadm_id', 'admission_type', 'icd_code', 'icd_version', 'long_title', 'clinical_notes']\n",
      "\n",
      "Negation Analysis:\n",
      "Negated Entities: ['cough', 'diarrhea', 'fever', 'denie headache', 'denie shortness of breath', 'chest pain', 'denie vomiting', 'diarrhea', 'dysuria', 'denie arthralgia', 'myalgia', 'rash']\n",
      "\n",
      "Detailed Negation Information:\n",
      "Entity: cough (Type: DISEASE)\n",
      "Context: pain and a dry cough , but today he \n",
      "  deny\n",
      "Negation Type: direct\n",
      "\n",
      "Entity: diarrhea (Type: DISEASE)\n",
      "Context: he deny diarrhea , \n",
      "  fever , chill\n",
      "Negation Type: direct\n",
      "\n",
      "Entity: fever (Type: DISEASE)\n",
      "Context: he deny diarrhea , \n",
      "  fever , chill , or dysuria\n",
      "Negation Type: direct\n",
      "\n",
      "Entity: denie headache (Type: DISEASE)\n",
      "Context: denie headache , sinus \n",
      " \n",
      "Negation Type: direct\n",
      "\n",
      "Entity: denie shortness of breath (Type: DISEASE)\n",
      "Context: denie shortness of breath\n",
      "Negation Type: direct\n",
      "\n",
      "Entity: chest pain (Type: DISEASE)\n",
      "Context: denie chest pain , chest pressure\n",
      "Negation Type: direct\n",
      "\n",
      "Entity: denie vomiting (Type: DISEASE)\n",
      "Context: denie vomiting , diarrhea\n",
      "Negation Type: direct\n",
      "\n",
      "Entity: diarrhea (Type: DISEASE)\n",
      "Context: denie vomiting , diarrhea , constipation ,\n",
      "Negation Type: direct\n",
      "\n",
      "Entity: dysuria (Type: DISEASE)\n",
      "Context: denie dysuria , frequency , or\n",
      "Negation Type: direct\n",
      "\n",
      "Entity: denie arthralgia (Type: DISEASE)\n",
      "Context: denie arthralgia or myalgia\n",
      "Negation Type: direct\n",
      "\n",
      "Entity: myalgia (Type: DISEASE)\n",
      "Context: denie arthralgia or myalgia .\n",
      "Negation Type: direct\n",
      "\n",
      "Entity: rash (Type: DISEASE)\n",
      "Context: denie rash or skin \n",
      "  change .\n",
      "Negation Type: direct\n",
      "\n",
      "\n",
      "Detected Entities:\n",
      "hypotension (Type: DISEASE)\n",
      "renal cell carcinoma (Type: DISEASE)\n",
      "coumadin (Type: CHEMICAL)\n",
      "tumor (Type: DISEASE)\n",
      "hypotension (Type: DISEASE)\n",
      "septic shock (Type: DISEASE)\n",
      "pain (Type: DISEASE)\n",
      "thoracic cord compression (Type: DISEASE)\n",
      "pain (Type: DISEASE)\n",
      "cough (Type: NEG_ENTITY)\n",
      "diarrhea (Type: NEG_ENTITY)\n",
      "fever (Type: NEG_ENTITY)\n",
      "dysuria (Type: NEG_ENTITY)\n",
      "pneumonia (Type: DISEASE)\n",
      "ceftriaxone (Type: CHEMICAL)\n",
      "doxycycline (Type: CHEMICAL)\n",
      "hypotensive (Type: DISEASE)\n",
      "levophed (Type: CHEMICAL)\n",
      "levophed (Type: CHEMICAL)\n",
      "warfarin (Type: CHEMICAL)\n",
      "lactate (Type: CHEMICAL)\n",
      "vancomycin (Type: CHEMICAL)\n",
      "cefepime (Type: CHEMICAL)\n",
      "dilaudid (Type: CHEMICAL)\n",
      "chronic pain (Type: DISEASE)\n",
      "methadone (Type: CHEMICAL)\n",
      "fatigue (Type: DISEASE)\n",
      "chronic back pain (Type: DISEASE)\n",
      "denie headache (Type: NEG_ENTITY)\n",
      "tenderness (Type: DISEASE)\n",
      "rhinorrhea (Type: DISEASE)\n",
      "congestion (Type: DISEASE)\n",
      "denie shortness of breath (Type: NEG_ENTITY)\n",
      "wheezing (Type: DISEASE)\n",
      "chest pain (Type: NEG_ENTITY)\n",
      "palpitation (Type: DISEASE)\n",
      "denie vomiting (Type: NEG_ENTITY)\n",
      "diarrhea (Type: NEG_ENTITY)\n",
      "constipation (Type: DISEASE)\n",
      "abdominal \n",
      " pain (Type: DISEASE)\n",
      "dysuria (Type: NEG_ENTITY)\n",
      "denie arthralgia (Type: NEG_ENTITY)\n",
      "myalgia (Type: NEG_ENTITY)\n",
      "rash (Type: NEG_ENTITY)\n",
      "avastin (Type: CHEMICAL)\n",
      "axitinib (Type: CHEMICAL)\n",
      "chronic pain (Type: DISEASE)\n",
      "methadone (Type: CHEMICAL)\n",
      "hydromorphone (Type: CHEMICAL)\n",
      "hemoptysis (Type: DISEASE)\n",
      "multiple myeloma (Type: DISEASE)\n",
      "polycythemia (Type: DISEASE)\n",
      "levophed (Type: CHEMICAL)\n",
      "decrease bowel sound \n",
      " ext : Warm , well perfused , 2 + pulse , 1 + pit (Type: DISEASE)\n",
      "edema (Type: DISEASE)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><!DOCTYPE html>\n",
       "<html lang=\"en\">\n",
       "    <head>\n",
       "        <title>displaCy</title>\n",
       "    </head>\n",
       "\n",
       "    <body style=\"font-size: 16px; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol'; padding: 4rem 2rem; direction: ltr\">\n",
       "<figure style=\"margin-bottom: 6rem\">\n",
       "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: linear-gradient(180deg, #1ABC9C, #DAF7A6); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    hypotension\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DISEASE</span>\n",
       "</mark>\n",
       " <br> <br> major surgical or Invasive Procedure : <br> none <br> <br> history of Present Illness : <br> _ _ _ h/o \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(180deg, #1ABC9C, #DAF7A6); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    renal cell carcinoma\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DISEASE</span>\n",
       "</mark>\n",
       " met to brain , lung , rib , and <br> spine s/p t7 - 8 vertebrectomy with t5 - 11 posterior instrumented <br> fusion in _ _ _ , also with history of pe on \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(90deg, #3498DB, #fc9ce7); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    coumadin\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CHEMICAL</span>\n",
       "</mark>\n",
       " , and cord <br> compression from \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(180deg, #1ABC9C, #DAF7A6); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    tumor\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DISEASE</span>\n",
       "</mark>\n",
       " recurrence s/p t6-t8 laminectomy who <br> present from _ _ _ to _ _ _ ed with <br> \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(180deg, #1ABC9C, #DAF7A6); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    hypotension\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DISEASE</span>\n",
       "</mark>\n",
       " to _ _ _ , transfer to _ _ _ for \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(180deg, #1ABC9C, #DAF7A6); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    septic shock\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DISEASE</span>\n",
       "</mark>\n",
       " <br> with likely pulmonary source . <br><br> he be initially admit _ _ _ - _ _ _ for worsen back \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(180deg, #1ABC9C, #DAF7A6); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    pain\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DISEASE</span>\n",
       "</mark>\n",
       " , <br> find to have \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(180deg, #1ABC9C, #DAF7A6); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    thoracic cord compression\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DISEASE</span>\n",
       "</mark>\n",
       " and be s/p lamiectomy <br> and fusion . he be discharge to rehab . on _ _ _ his wife report <br> that he note abodminal \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(180deg, #1ABC9C, #DAF7A6); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    pain\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DISEASE</span>\n",
       "</mark>\n",
       " and a dry \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(90deg, #E74C3C, #ff6600); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    cough\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NEG_ENTITY</span>\n",
       "</mark>\n",
       " , but today he <br> deny any of these sypmtom as occur . he deny \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(90deg, #E74C3C, #ff6600); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    diarrhea\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NEG_ENTITY</span>\n",
       "</mark>\n",
       " , <br> \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(90deg, #E74C3C, #ff6600); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    fever\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NEG_ENTITY</span>\n",
       "</mark>\n",
       " , chill , or \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(90deg, #E74C3C, #ff6600); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    dysuria\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NEG_ENTITY</span>\n",
       "</mark>\n",
       " . his bp at rehab be check to be in <br> the _ _ _ . he be take to _ _ _ ED where a ct <br> chest be concern for \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(180deg, #1ABC9C, #DAF7A6); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    pneumonia\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DISEASE</span>\n",
       "</mark>\n",
       " . he be give \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(90deg, #3498DB, #fc9ce7); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    ceftriaxone\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CHEMICAL</span>\n",
       "</mark>\n",
       " and <br> \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(90deg, #3498DB, #fc9ce7); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    doxycycline\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CHEMICAL</span>\n",
       "</mark>\n",
       " . he be also give 1u PRBC for hct 26 ( baseline <br> low-mid _ _ _ . he be fluid resuscitate with 2l ns but remain <br> \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(180deg, #1ABC9C, #DAF7A6); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    hypotensive\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DISEASE</span>\n",
       "</mark>\n",
       " . he have a right ij cvl place , be start on <br> \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(90deg, #3498DB, #fc9ce7); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    levophed\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CHEMICAL</span>\n",
       "</mark>\n",
       " , and transfer to _ _ _ ed . <br> <br> on arrival to the _ _ _ ed , intial vs hr 79 bp 92/57 on <br> levpophed rr 18 . he be take off \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(90deg, #3498DB, #fc9ce7); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    levophed\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CHEMICAL</span>\n",
       "</mark>\n",
       " and full VS 98.1 83 <br> 86/53 18 85 % ra . he be place back on levophe and 2L NC with <br> sao2 improve to 97 % ( he be on intermittnet o2 at rehab ) and bp <br> 100s/60s . on exam , he be well-appearing , alert and orient , <br> and have decrease breath sound bilaterally with right-sided <br> rhonchi . he have ruq ttp and a small area of ulceration near his <br> surgical wound . initial lab notable for WBC 8.1 , h/h 8.7/28.3 , <br> inr 3.0 ( on \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(90deg, #3498DB, #fc9ce7); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    warfarin\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CHEMICAL</span>\n",
       "</mark>\n",
       " ) , Cr 1.3 . \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(90deg, #3498DB, #fc9ce7); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    lactate\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CHEMICAL</span>\n",
       "</mark>\n",
       " 2.0 , mvo2 be 86 % , and <br> VBG be 7.___. <br><br> he be give 500cc ns . he be give 1 mg iv \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(90deg, #3498DB, #fc9ce7); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    vancomycin\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CHEMICAL</span>\n",
       "</mark>\n",
       " and 2 mg iv <br> \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(90deg, #3498DB, #fc9ce7); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    cefepime\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CHEMICAL</span>\n",
       "</mark>\n",
       " . ruq US show no acute process . cxr show ... he have <br> not make urine but be refuse a straight cath or Foley so <br> neither be do . he be also give 0.5 mg iv \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(90deg, #3498DB, #fc9ce7); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    dilaudid\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CHEMICAL</span>\n",
       "</mark>\n",
       " for <br> \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(180deg, #1ABC9C, #DAF7A6); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    chronic pain\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DISEASE</span>\n",
       "</mark>\n",
       " . he be on \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(90deg, #3498DB, #fc9ce7); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    methadone\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CHEMICAL</span>\n",
       "</mark>\n",
       " at his rehab facility .  <br> <br> on arrival to the micu , VS be : he feel very \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(180deg, #1ABC9C, #DAF7A6); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    fatigue\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DISEASE</span>\n",
       "</mark>\n",
       " and his <br> \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(180deg, #1ABC9C, #DAF7A6); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    chronic back pain\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DISEASE</span>\n",
       "</mark>\n",
       " be bother he .   <br><br> review of system :  <br> ( + ) per hpi .  <br> ( - ) denie chill , night sweat . \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(90deg, #E74C3C, #ff6600); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    denie headache\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NEG_ENTITY</span>\n",
       "</mark>\n",
       " , sinus <br> \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(180deg, #1ABC9C, #DAF7A6); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    tenderness\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DISEASE</span>\n",
       "</mark>\n",
       " , \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(180deg, #1ABC9C, #DAF7A6); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    rhinorrhea\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DISEASE</span>\n",
       "</mark>\n",
       " or \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(180deg, #1ABC9C, #DAF7A6); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    congestion\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DISEASE</span>\n",
       "</mark>\n",
       " . \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(90deg, #E74C3C, #ff6600); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    denie shortness of breath\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NEG_ENTITY</span>\n",
       "</mark>\n",
       " <br> or \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(180deg, #1ABC9C, #DAF7A6); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    wheezing\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DISEASE</span>\n",
       "</mark>\n",
       " . denie \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(90deg, #E74C3C, #ff6600); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    chest pain\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NEG_ENTITY</span>\n",
       "</mark>\n",
       " , chest pressure , \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(180deg, #1ABC9C, #DAF7A6); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    palpitation\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DISEASE</span>\n",
       "</mark>\n",
       " , or <br> weakness . \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(90deg, #E74C3C, #ff6600); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    denie vomiting\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NEG_ENTITY</span>\n",
       "</mark>\n",
       " , \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(90deg, #E74C3C, #ff6600); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    diarrhea\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NEG_ENTITY</span>\n",
       "</mark>\n",
       " , \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(180deg, #1ABC9C, #DAF7A6); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    constipation\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DISEASE</span>\n",
       "</mark>\n",
       " , \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(180deg, #1ABC9C, #DAF7A6); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    abdominal \n",
       " pain\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DISEASE</span>\n",
       "</mark>\n",
       " , or change in bowel habit . denie \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(90deg, #E74C3C, #ff6600); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    dysuria\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NEG_ENTITY</span>\n",
       "</mark>\n",
       " , frequency , or <br> urgency . \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(90deg, #E74C3C, #ff6600); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    denie arthralgia\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NEG_ENTITY</span>\n",
       "</mark>\n",
       " or \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(90deg, #E74C3C, #ff6600); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    myalgia\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NEG_ENTITY</span>\n",
       "</mark>\n",
       " . denie \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(90deg, #E74C3C, #ff6600); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    rash\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NEG_ENTITY</span>\n",
       "</mark>\n",
       " or skin <br> change . <br> <br> past medical history : <br> - metastatic rcc ( dx _ _ _ <br> -- s/p tx with il-2 , \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(90deg, #3498DB, #fc9ce7); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    avastin\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CHEMICAL</span>\n",
       "</mark>\n",
       " , sutent in _ _ _ , protocol _ _ _ <br> with pd-1 inhibitor for 20 cycle w/ progression , new brain <br> lesion in <br> _ _ _ s/p CK , \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(90deg, #3498DB, #fc9ce7); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    axitinib\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CHEMICAL</span>\n",
       "</mark>\n",
       " 5 mg bid but with progression <br> -- he be follow by dr. _ _ _ in the _ _ _ care clinic . has <br> have worsen \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(180deg, #1ABC9C, #DAF7A6); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    chronic pain\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DISEASE</span>\n",
       "</mark>\n",
       " . during most recent admission be <br> dishcharge on \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(90deg, #3498DB, #fc9ce7); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    methadone\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CHEMICAL</span>\n",
       "</mark>\n",
       " and \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(90deg, #3498DB, #fc9ce7); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    hydromorphone\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CHEMICAL</span>\n",
       "</mark>\n",
       " prn <br> - thoracic cord compression - on _ _ _ , he have total <br> laminectomy of t6-t8 , fusion of t4-t12 , and revision and <br> application of new instrumentation t4-t12 <br> - h/o dvt/pe in _ _ _ , unclear circumstance surround this , <br> goal inr be 1.5 - 2.0 give a history of \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(180deg, #1ABC9C, #DAF7A6); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    hemoptysis\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DISEASE</span>\n",
       "</mark>\n",
       " <br> <br> social history : <br> _ _ _ <br> Family history : <br> his mother die of \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(180deg, #1ABC9C, #DAF7A6); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    multiple myeloma\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DISEASE</span>\n",
       "</mark>\n",
       " .   his father die of heart <br> and lung problem ; he have \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(180deg, #1ABC9C, #DAF7A6); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    polycythemia\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DISEASE</span>\n",
       "</mark>\n",
       " and clot . <br> <br> Physical Exam : <br> on Admission : <br> vital : t 97.8 hr 79 bp 118/67 ( 0.08 \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(90deg, #3498DB, #fc9ce7); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    levophed\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CHEMICAL</span>\n",
       "</mark>\n",
       " ) rr 21 sao2 95 % on <br> 3l NC cvp 10 <br> GENERAL : Cachectic , lie flat in bed , flat affect  <br> heent : Sclera anicteric , dry mm , oropharynx clear  <br> neck : supple , r ij cvl dress c/d/i  <br> lung : decrease breath sound r &gt; l , crackle at rul <br> cv : regular rate and rhythm , normal s1 s2 , s4 <br> abd : mildly tender to palpation , no rebound or guarding , <br> non-distended , slightly \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(180deg, #1ABC9C, #DAF7A6); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    decrease bowel sound \n",
       " ext : Warm , well perfused , 2 + pulse , 1 + pit\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DISEASE</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(180deg, #1ABC9C, #DAF7A6); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    edema\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DISEASE</span>\n",
       "</mark>\n",
       " to <br> mid-shin <br> skin : 1x1 cm area over thoracic incision with superficial <br> ulceration and good granulation tissue , no drainage <br> neuro : orient x 3 , strength be symmetric throughout <br><br> on Discharge : <br> expire</div>\n",
       "</figure>\n",
       "</body>\n",
       "</html></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Visualization saved to: ner_visualizations/ner_visualization_row_2.html\n",
      "\n",
      "Open the HTML file at: ner_visualizations/ner_visualization_row_2.html\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "import scispacy\n",
    "from spacy import displacy\n",
    "from spacy.matcher import PhraseMatcher\n",
    "from spacy.tokens import Span\n",
    "import os\n",
    "\n",
    "def lemmatize(note, nlp):\n",
    "    \"\"\"Lemmatize the input text to capture different word forms\"\"\"\n",
    "    doc = nlp(note)\n",
    "    lemNote = [wd.lemma_ for wd in doc]\n",
    "    return \" \".join(lemNote)\n",
    "\n",
    "def get_entity_options():\n",
    "    \"\"\"Define visualization options for Named Entities\"\"\"\n",
    "    entities = [\"DISEASE\", \"CHEMICAL\", \"NEG_ENTITY\"]\n",
    "    colors = {\n",
    "        'DISEASE': 'linear-gradient(180deg, #1ABC9C, #DAF7A6)', \n",
    "        'CHEMICAL': 'linear-gradient(90deg, #3498DB, #fc9ce7)', \n",
    "        \"NEG_ENTITY\": 'linear-gradient(90deg, #E74C3C, #ff6600)'\n",
    "    }\n",
    "    return {\"ents\": entities, \"colors\": colors}\n",
    "\n",
    "def custom_neg_handling(doc):\n",
    "    \"\"\"\n",
    "    Enhanced negation detection with comprehensive context analysis\n",
    "    \n",
    "    Args:\n",
    "        doc (spacy.tokens.Doc): Processed spaCy document\n",
    "    \n",
    "    Returns:\n",
    "        dict: A dictionary with detailed negation information\n",
    "    \"\"\"\n",
    "    # Comprehensive negation terms and patterns\n",
    "    negation_terms = {\n",
    "        'direct': [\n",
    "            'no', 'not', 'never', 'neither', 'none', \n",
    "            'absence', 'absent', 'denied', 'deny', 'denie',\n",
    "            'rule out', 'ruled out', 'without', 'hasn\\'t', \n",
    "            'haven\\'t', 'didn\\'t', 'don\\'t', 'cannot', \n",
    "            'can\\'t', 'no evidence', 'negates', 'negative'\n",
    "        ],\n",
    "        'pre_modifiers': [\n",
    "            'unlikely', 'improbable', 'doubtful', \n",
    "            'unconfirmed', 'unconvinced'\n",
    "        ],\n",
    "        'post_modifiers': [\n",
    "            'free', 'clear', 'resolved', 'eliminated'\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    negation_results = {\n",
    "        'negated_entities': [],\n",
    "        'detailed_negations': []\n",
    "    }\n",
    "    \n",
    "    # Iterate through sentences\n",
    "    for sent in doc.sents:\n",
    "        for ent in sent.ents:\n",
    "            # Wider context window for negation detection\n",
    "            context_window = 25  # characters before and after the entity\n",
    "            \n",
    "            # Extract context tokens\n",
    "            context_tokens = [\n",
    "                token for token in sent \n",
    "                if abs(token.idx - ent.start_char) < context_window\n",
    "            ]\n",
    "            \n",
    "            # Convert context to lowercase for easier matching\n",
    "            context_lower = [token.lower_ for token in context_tokens]\n",
    "            \n",
    "            # Check for direct negation terms\n",
    "            is_negated = any(neg in context_lower for neg in negation_terms['direct'])\n",
    "            \n",
    "            # Check for pre and post negation modifiers\n",
    "            pre_neg = any(mod in context_lower[:3] for mod in negation_terms['pre_modifiers'])\n",
    "            post_neg = any(mod in context_lower[-3:] for mod in negation_terms['post_modifiers'])\n",
    "            \n",
    "            # Detailed negation analysis\n",
    "            if is_negated or pre_neg or post_neg:\n",
    "                negation_details = {\n",
    "                    'entity': ent.text,\n",
    "                    'type': ent.label_,\n",
    "                    'context': ' '.join([token.text for token in context_tokens]),\n",
    "                    'negation_type': 'direct' if is_negated else 'modified'\n",
    "                }\n",
    "                \n",
    "                negation_results['negated_entities'].append(ent.text)\n",
    "                negation_results['detailed_negations'].append(negation_details)\n",
    "    \n",
    "    return negation_results\n",
    "\n",
    "def print_negation_analysis(negation_results):\n",
    "    \"\"\"\n",
    "    Print a detailed analysis of negated entities\n",
    "    \n",
    "    Args:\n",
    "        negation_results (dict): Negation analysis results\n",
    "    \"\"\"\n",
    "    print(\"\\nNegation Analysis:\")\n",
    "    if not negation_results['negated_entities']:\n",
    "        print(\"No negated entities found.\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Negated Entities: {negation_results['negated_entities']}\")\n",
    "    print(\"\\nDetailed Negation Information:\")\n",
    "    for neg in negation_results['detailed_negations']:\n",
    "        print(f\"Entity: {neg['entity']} (Type: {neg['type']})\")\n",
    "        print(f\"Context: {neg['context']}\")\n",
    "        print(f\"Negation Type: {neg['negation_type']}\\n\")\n",
    "\n",
    "def process_single_note(file_path, row_index, output_dir='ner_visualizations'):\n",
    "    \"\"\"\n",
    "    Process and visualize a single note from the CSV with enhanced output\n",
    "    \n",
    "    Args:\n",
    "        file_path (str): Path to CSV file\n",
    "        row_index (int): Index of the row to process\n",
    "        output_dir (str): Directory to save visualization output\n",
    "    \"\"\"\n",
    "    # Load scispaCy models\n",
    "    try:\n",
    "        nlp0 = spacy.load(\"en_core_sci_sm\")\n",
    "        nlp1 = spacy.load(\"en_ner_bc5cdr_md\")\n",
    "    except OSError as e:\n",
    "        print(f\"Error loading spaCy models: {e}\")\n",
    "        print(\"Make sure you have installed the models using:\")\n",
    "        print(\"python -m spacy download en_core_sci_sm\")\n",
    "        print(\"python -m spacy download en_ner_bc5cdr_md\")\n",
    "        raise\n",
    "\n",
    "    # Create output directory if it doesn't exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Load the CSV file\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Check if the row index is valid\n",
    "    if row_index >= len(df):\n",
    "        raise IndexError(f\"Row index {row_index} is out of bounds for the given CSV file.\")\n",
    "    \n",
    "    # Extract the note text\n",
    "    if 'clinical_notes' not in df.columns:\n",
    "        raise KeyError(\"The column 'clinical_notes' is not present in the CSV file.\")\n",
    "    \n",
    "    clinical_notes = df.loc[row_index, 'clinical_notes']\n",
    "    if pd.isna(clinical_notes):\n",
    "        raise ValueError(f\"The clinical notes at row {row_index} are missing or empty.\")\n",
    "    \n",
    "    # Lemmatize the text\n",
    "    lemmatized_text = lemmatize(clinical_notes, nlp0)\n",
    "    \n",
    "    # Prepare visualization options\n",
    "    options = get_entity_options()\n",
    "    \n",
    "    # Process the note with NER\n",
    "    doc = nlp1(lemmatized_text)\n",
    "    \n",
    "    # Get negated entities\n",
    "    neg_results = custom_neg_handling(doc)\n",
    "    \n",
    "    # Print negation analysis\n",
    "    print_negation_analysis(neg_results)\n",
    "    \n",
    "    # Modify entities to include negation\n",
    "    negated_entities = neg_results['negated_entities']\n",
    "    neg_entity_label = \"NEG_ENTITY\"\n",
    "\n",
    "    if neg_entity_label not in doc.vocab.strings:\n",
    "        doc.vocab.strings.add(neg_entity_label)\n",
    "    \n",
    "    # Create a new list of entities to replace the existing ones\n",
    "    modified_entities = []\n",
    "    for ent in doc.ents:\n",
    "        if ent.text in negated_entities:\n",
    "            # Create a new span with NEG_ENTITY label\n",
    "            new_ent = Span(doc, ent.start, ent.end, label=doc.vocab.strings[\"NEG_ENTITY\"])\n",
    "            modified_entities.append(new_ent)\n",
    "        else:\n",
    "            modified_entities.append(ent)\n",
    "    \n",
    "    # Replace the document's entities\n",
    "    doc.ents = tuple(modified_entities)\n",
    "    \n",
    "    # Diagnostic print for entities\n",
    "    print(\"\\nDetected Entities:\")\n",
    "    for ent in doc.ents:\n",
    "        print(f\"{ent.text} (Type: {ent.label_})\")\n",
    "\n",
    "    # Prepare the HTML visualization with explicit parameters\n",
    "    try:\n",
    "        html = displacy.render(doc, style='ent', options=options, page=True)\n",
    "        \n",
    "        # Ensure html is a string \n",
    "        if not isinstance(html, str):\n",
    "            html = str(html)\n",
    "        \n",
    "        # Generate output file path\n",
    "        output_file = os.path.join(output_dir, f'ner_visualization_row_{row_index}.html')\n",
    "        \n",
    "        # Write the visualization to an HTML file\n",
    "        with open(output_file, 'w', encoding='utf-8') as f:\n",
    "            f.write(html)\n",
    "        \n",
    "        print(f\"\\nVisualization saved to: {output_file}\")\n",
    "        \n",
    "        return doc, output_file\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating HTML visualization: {e}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "# Diagnostic function to check CSV contents\n",
    "def preview_csv(file_path, num_rows=5):\n",
    "    \"\"\"\n",
    "    Preview the contents of the CSV file\n",
    "    \n",
    "    Args:\n",
    "        file_path (str): Path to the CSV file\n",
    "        num_rows (int): Number of rows to preview\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(file_path)\n",
    "    print(\"CSV Columns:\", list(df.columns))\n",
    "\n",
    "# Example usage with error handling\n",
    "def main():\n",
    "    try:\n",
    "        # First, preview the CSV to understand its structure\n",
    "        preview_csv('df_sampled.csv')\n",
    "        \n",
    "        # Then attempt to process a specific row\n",
    "        doc, output_file = process_single_note('df_sampled.csv', 2)\n",
    "        print(f\"\\nOpen the HTML file at: {output_file}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start of ClinicalBert training:\n",
    "Fine-Tuning ClinicalBERT with Linear Classification Layer\n",
    "\n",
    "This model uses ClinicalBERT to process clinical notes and classify them into ICD-9 codes.\n",
    "\n",
    "Process clinical notes through ClinicalBERT to get embeddings\n",
    "Pass embeddings through a linear classification layer\n",
    "Use binary cross-entropy loss for multi-label classification\n",
    "Evaluate using AUROC, F1, Precision@k, and Recall@k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T14:21:50.477040Z",
     "iopub.status.busy": "2024-12-11T14:21:50.476483Z",
     "iopub.status.idle": "2024-12-11T14:21:51.715542Z",
     "shell.execute_reply": "2024-12-11T14:21:51.715327Z",
     "shell.execute_reply.started": "2024-12-11T14:21:50.477005Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset sizes:\n",
      "Train size: 13758, Test size: 3441\n",
      "Number of unique ICD codes: 50\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "\n",
    "# Load the dataset\n",
    "df_sampled = pd.read_csv('extracted_sections_with_diseases.csv')\n",
    "\n",
    "# Filter for the top 50 most frequent ICD codes\n",
    "top_50_codes = df_sampled['icd_code'].value_counts().head(50).index.tolist()\n",
    "df_top50 = df_sampled[df_sampled['icd_code'].isin(top_50_codes)]\n",
    "\n",
    "# Group by hadm_id and aggregate all related information\n",
    "df_grouped = df_top50.groupby('hadm_id').agg({\n",
    "    'extracted_diseases': 'first',  # Take the first extracted diseases (they should be same for each hadm_id)\n",
    "    'icd_code': lambda x: list(set(x)),  # Get unique list of ICD codes\n",
    "    'long_title': lambda x: list(set(x))  # Get unique list of descriptions\n",
    "}).reset_index()\n",
    "\n",
    "# Create multi-hot labels for the grouped data\n",
    "mlb = MultiLabelBinarizer(classes=sorted(top_50_codes))\n",
    "multi_hot_labels = mlb.fit_transform([set(codes) for codes in df_grouped['icd_code']])\n",
    "\n",
    "# Split the data using MultilabelStratifiedKFold\n",
    "mskf = MultilabelStratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "train_idx, test_idx = next(mskf.split(df_grouped, multi_hot_labels))\n",
    "\n",
    "# Create train and test datasets\n",
    "train_data = df_grouped.iloc[train_idx].reset_index(drop=True)\n",
    "test_data = df_grouped.iloc[test_idx].reset_index(drop=True)\n",
    "\n",
    "# Save the splits\n",
    "train_data.to_csv('train_top50.csv', index=False)\n",
    "test_data.to_csv('test_top50.csv', index=False)\n",
    "\n",
    "print(\"\\nDataset sizes:\")\n",
    "print(f\"Train size: {len(train_data)}, Test size: {len(test_data)}\")\n",
    "print(f\"Number of unique ICD codes: {len(top_50_codes)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T14:21:55.054886Z",
     "iopub.status.busy": "2024-12-11T14:21:55.054378Z",
     "iopub.status.idle": "2024-12-11T14:21:55.066905Z",
     "shell.execute_reply": "2024-12-11T14:21:55.066501Z",
     "shell.execute_reply.started": "2024-12-11T14:21:55.054849Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>extracted_diseases</th>\n",
       "      <th>icd_code</th>\n",
       "      <th>long_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20000057</td>\n",
       "      <td>gu-; sore throat; cataract; hematoma; nausea ,...</td>\n",
       "      <td>[4019]</td>\n",
       "      <td>[Unspecified essential hypertension]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20000235</td>\n",
       "      <td>sore throat; hypotension; bleed; asterixis; we...</td>\n",
       "      <td>[2449]</td>\n",
       "      <td>[Unspecified acquired hypothyroidism]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20001825</td>\n",
       "      <td>ecchymosis; knee pain; lung cancer; erythema; ...</td>\n",
       "      <td>[4019]</td>\n",
       "      <td>[Unspecified essential hypertension]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20002402</td>\n",
       "      <td>ulcer; heart \\n disease \\n\\n \\n Physical Exam ...</td>\n",
       "      <td>[53081]</td>\n",
       "      <td>[Esophageal reflux]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20002634</td>\n",
       "      <td>sore throat; denie leg weakness; cholelithiasi...</td>\n",
       "      <td>[53081]</td>\n",
       "      <td>[Esophageal reflux]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    hadm_id                                 extracted_diseases icd_code  \\\n",
       "0  20000057  gu-; sore throat; cataract; hematoma; nausea ,...   [4019]   \n",
       "1  20000235  sore throat; hypotension; bleed; asterixis; we...   [2449]   \n",
       "2  20001825  ecchymosis; knee pain; lung cancer; erythema; ...   [4019]   \n",
       "3  20002402  ulcer; heart \\n disease \\n\\n \\n Physical Exam ...  [53081]   \n",
       "4  20002634  sore throat; denie leg weakness; cholelithiasi...  [53081]   \n",
       "\n",
       "                              long_title  \n",
       "0   [Unspecified essential hypertension]  \n",
       "1  [Unspecified acquired hypothyroidism]  \n",
       "2   [Unspecified essential hypertension]  \n",
       "3                    [Esophageal reflux]  \n",
       "4                    [Esophageal reflux]  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_grouped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T14:22:00.673962Z",
     "iopub.status.busy": "2024-12-11T14:22:00.673308Z",
     "iopub.status.idle": "2024-12-11T15:47:40.748671Z",
     "shell.execute_reply": "2024-12-11T15:47:40.748282Z",
     "shell.execute_reply.started": "2024-12-11T14:22:00.673911Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at emilyalsentzer/Bio_ClinicalBERT and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Loss: 183.9885\n",
      "Epoch 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5, Loss: 170.7726\n",
      "Epoch 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/5, Loss: 169.8578\n",
      "Epoch 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/5, Loss: 169.8645\n",
      "Epoch 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5, Loss: 171.4136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClinicalBERT: AUROC=0.4683, F1=0.0000\n",
      "ClinicalBERT precision@5: 0.0583\n",
      "ClinicalBERT recall@5: 0.2768\n",
      "ClinicalBERT precision@10: 0.0441\n",
      "ClinicalBERT recall@10: 0.4181\n",
      "ClinicalBERT precision@20: 0.0345\n",
      "ClinicalBERT recall@20: 0.6525\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score, f1_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load the dataset\n",
    "train_data = pd.read_csv('train_top50.csv')\n",
    "test_data = pd.read_csv('test_top50.csv')\n",
    "\n",
    "# Ensure `extracted_diseases` contains strings and handle NaN\n",
    "train_data['extracted_diseases'] = train_data['extracted_diseases'].fillna(\"\").astype(str)\n",
    "test_data['extracted_diseases'] = test_data['extracted_diseases'].fillna(\"\").astype(str)\n",
    "\n",
    "# Define a custom Dataset for Clinical Notes\n",
    "class ClinicalNotesDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])  # Ensure the text is a string\n",
    "        label = self.labels[idx]\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            max_length=self.max_length,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        return {\n",
    "            \"input_ids\": encoding[\"input_ids\"].squeeze(0),\n",
    "            \"attention_mask\": encoding[\"attention_mask\"].squeeze(0),\n",
    "            \"labels\": torch.tensor(label, dtype=torch.float),\n",
    "        }\n",
    "\n",
    "# Generate multi-hot labels for train and test sets\n",
    "# Ensure multi_hot_labels, train_idx, and test_idx are defined\n",
    "train_labels = multi_hot_labels[train_idx]  # Use the same multi-hot labels for train set\n",
    "test_labels = multi_hot_labels[test_idx]    # Use the same multi-hot labels for test set\n",
    "\n",
    "unique_labels = top_50_codes \n",
    "\n",
    "# Unique labels for classification\n",
    "unique_labels = list(range(train_labels.shape[1]))\n",
    "\n",
    "# Load ClinicalBERT\n",
    "tokenizer = BertTokenizer.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\")\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    \"emilyalsentzer/Bio_ClinicalBERT\", num_labels=len(unique_labels)\n",
    ")\n",
    "\n",
    "# Prepare datasets\n",
    "train_dataset = ClinicalNotesDataset(\n",
    "    train_data[\"extracted_diseases\"].tolist(),\n",
    "    train_labels,\n",
    "    tokenizer,\n",
    "    max_length=128\n",
    ")\n",
    "test_dataset = ClinicalNotesDataset(\n",
    "    test_data[\"extracted_diseases\"].tolist(),\n",
    "    test_labels,\n",
    "    tokenizer,\n",
    "    max_length=128\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8)\n",
    "\n",
    "# Define optimizer and loss\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5)\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "# Fine-tune ClinicalBERT\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "epochs = 5\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    print(f\"Epoch {epoch + 1}/{epochs}\")\n",
    "    for batch in tqdm(train_loader, desc=\"Training\", leave=False):\n",
    "        optimizer.zero_grad()\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        labels = batch[\"labels\"].to(device)\n",
    "\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Epoch {epoch + 1}/{epochs}, Loss: {total_loss:.4f}\")\n",
    "\n",
    "# Evaluate ClinicalBERT\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_loader, desc=\"Evaluating\", leave=False):\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        labels = batch[\"labels\"].to(device)\n",
    "\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        preds = torch.sigmoid(outputs.logits).cpu().numpy()\n",
    "        all_preds.append(preds)\n",
    "        all_labels.append(labels.cpu().numpy())\n",
    "\n",
    "all_preds = np.vstack(all_preds)\n",
    "all_labels = np.vstack(all_labels)\n",
    "\n",
    "# Threshold predictions\n",
    "threshold = 0.5\n",
    "binary_preds = (all_preds > threshold).astype(int)\n",
    "\n",
    "# Compute evaluation metrics\n",
    "clinicalbert_auc = roc_auc_score(all_labels, all_preds, average=\"weighted\")\n",
    "clinicalbert_f1 = f1_score(all_labels, binary_preds, average=\"weighted\")\n",
    "print(f\"ClinicalBERT: AUROC={clinicalbert_auc:.4f}, F1={clinicalbert_f1:.4f}\")\n",
    "\n",
    "# Compute precision and recall at k\n",
    "def compute_precision_recall_at_k(y_true, y_pred_probs, k_values=[5, 10, 20]):\n",
    "    results = {}\n",
    "    for k in k_values:\n",
    "        # Get top k predictions for each sample\n",
    "        top_k_indices = np.argsort(y_pred_probs, axis=1)[:, -k:]\n",
    "        \n",
    "        # Create binary matrix for top k predictions\n",
    "        y_pred_k = np.zeros_like(y_pred_probs)\n",
    "        for i, indices in enumerate(top_k_indices):\n",
    "            y_pred_k[i, indices] = 1\n",
    "            \n",
    "        # Calculate precision and recall\n",
    "        precision = np.mean([np.sum(y_true[i, top_k_indices[i]]) / k \n",
    "                           for i in range(len(y_true))])\n",
    "        recall = np.mean([np.sum(y_true[i, top_k_indices[i]]) / np.sum(y_true[i])\n",
    "                         for i in range(len(y_true))])\n",
    "        \n",
    "        results[f'precision@{k}'] = precision\n",
    "        results[f'recall@{k}'] = recall\n",
    "    \n",
    "    return results\n",
    "\n",
    "pk_rk_metrics = compute_precision_recall_at_k(all_labels, all_preds)\n",
    "for metric, value in pk_rk_metrics.items():\n",
    "    print(f\"ClinicalBERT {metric}: {value:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T08:42:51.749452Z",
     "iopub.status.busy": "2024-12-10T08:42:51.748795Z",
     "iopub.status.idle": "2024-12-10T08:49:21.394348Z",
     "shell.execute_reply": "2024-12-10T08:49:21.393913Z",
     "shell.execute_reply.started": "2024-12-10T08:42:51.749412Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 4007409 rows...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2395/4007409 [05:58<166:34:28,  6.68it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 122\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 122\u001b[0m     main()\n",
      "Cell \u001b[0;32mIn[9], line 116\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    113\u001b[0m     input_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mextracted_sections_drop_empty.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    114\u001b[0m     output_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mextracted_sections_drop_empty_with_diseases.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 116\u001b[0m     process_csv_with_ner(input_file, output_file)\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[9], line 82\u001b[0m, in \u001b[0;36mprocess_csv_with_ner\u001b[0;34m(input_file, output_file)\u001b[0m\n\u001b[1;32m     75\u001b[0m combined_text \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28mstr\u001b[39m(row\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHistory of Present Illness\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;28mstr\u001b[39m(row\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPast Medical History\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28mstr\u001b[39m(row\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPhysical Exam\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m     79\u001b[0m )\n\u001b[1;32m     81\u001b[0m \u001b[38;5;66;03m# Extract diseases\u001b[39;00m\n\u001b[0;32m---> 82\u001b[0m diseases \u001b[38;5;241m=\u001b[39m extract_diseases_from_note(combined_text, nlp0, nlp1)\n\u001b[1;32m     84\u001b[0m \u001b[38;5;66;03m# Update tracking stats\u001b[39;00m\n\u001b[1;32m     85\u001b[0m disease_extraction_stats[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrows_processed\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "Cell \u001b[0;32mIn[9], line 20\u001b[0m, in \u001b[0;36mextract_diseases_from_note\u001b[0;34m(note, nlp0, nlp1)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;124;03mExtract diseases from a medical note using NER\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;124;03m\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;124;03m    list: List of unique disease entities\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Lemmatize the text\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m lemmatized_text \u001b[38;5;241m=\u001b[39m lemmatize(note, nlp0)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Process the note with NER\u001b[39;00m\n\u001b[1;32m     23\u001b[0m doc \u001b[38;5;241m=\u001b[39m nlp1(lemmatized_text)\n",
      "Cell \u001b[0;32mIn[9], line 32\u001b[0m, in \u001b[0;36mlemmatize\u001b[0;34m(note, nlp)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlemmatize\u001b[39m(note, nlp):\n\u001b[1;32m     31\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Lemmatize the input text\"\"\"\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m     doc \u001b[38;5;241m=\u001b[39m nlp(note)\n\u001b[1;32m     33\u001b[0m     lemNote \u001b[38;5;241m=\u001b[39m [wd\u001b[38;5;241m.\u001b[39mlemma_ \u001b[38;5;28;01mfor\u001b[39;00m wd \u001b[38;5;129;01min\u001b[39;00m doc]\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(lemNote)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/NLP_project/lib/python3.12/site-packages/spacy/language.py:1049\u001b[0m, in \u001b[0;36mLanguage.__call__\u001b[0;34m(self, text, disable, component_cfg)\u001b[0m\n\u001b[1;32m   1047\u001b[0m     error_handler \u001b[38;5;241m=\u001b[39m proc\u001b[38;5;241m.\u001b[39mget_error_handler()\n\u001b[1;32m   1048\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1049\u001b[0m     doc \u001b[38;5;241m=\u001b[39m proc(doc, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcomponent_cfg\u001b[38;5;241m.\u001b[39mget(name, {}))  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m   1050\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1051\u001b[0m     \u001b[38;5;66;03m# This typically happens if a component is not initialized\u001b[39;00m\n\u001b[1;32m   1052\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(Errors\u001b[38;5;241m.\u001b[39mE109\u001b[38;5;241m.\u001b[39mformat(name\u001b[38;5;241m=\u001b[39mname)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/NLP_project/lib/python3.12/site-packages/spacy/pipeline/trainable_pipe.pyx:52\u001b[0m, in \u001b[0;36mspacy.pipeline.trainable_pipe.TrainablePipe.__call__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/NLP_project/lib/python3.12/site-packages/spacy/pipeline/transition_parser.pyx:264\u001b[0m, in \u001b[0;36mspacy.pipeline.transition_parser.Parser.predict\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/NLP_project/lib/python3.12/site-packages/spacy/pipeline/transition_parser.pyx:285\u001b[0m, in \u001b[0;36mspacy.pipeline.transition_parser.Parser.greedy_parse\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/NLP_project/lib/python3.12/site-packages/thinc/model.py:334\u001b[0m, in \u001b[0;36mModel.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    330\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m OutT:\n\u001b[1;32m    331\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call the model's `forward` function with `is_train=False`, and return\u001b[39;00m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;124;03m    only the output, instead of the `(output, callback)` tuple.\u001b[39;00m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 334\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_func(\u001b[38;5;28mself\u001b[39m, X, is_train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m/opt/anaconda3/envs/NLP_project/lib/python3.12/site-packages/spacy/ml/tb_framework.py:34\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(model, X, is_train)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(model, X, is_train):\n\u001b[0;32m---> 34\u001b[0m     step_model \u001b[38;5;241m=\u001b[39m ParserStepModel(\n\u001b[1;32m     35\u001b[0m         X,\n\u001b[1;32m     36\u001b[0m         model\u001b[38;5;241m.\u001b[39mlayers,\n\u001b[1;32m     37\u001b[0m         unseen_classes\u001b[38;5;241m=\u001b[39mmodel\u001b[38;5;241m.\u001b[39mattrs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munseen_classes\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     38\u001b[0m         train\u001b[38;5;241m=\u001b[39mis_train,\n\u001b[1;32m     39\u001b[0m         has_upper\u001b[38;5;241m=\u001b[39mmodel\u001b[38;5;241m.\u001b[39mattrs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_upper\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     40\u001b[0m     )\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m step_model, step_model\u001b[38;5;241m.\u001b[39mfinish_steps\n",
      "File \u001b[0;32m/opt/anaconda3/envs/NLP_project/lib/python3.12/site-packages/spacy/ml/parser_model.pyx:257\u001b[0m, in \u001b[0;36mspacy.ml.parser_model.ParserStepModel.__init__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/NLP_project/lib/python3.12/site-packages/spacy/ml/parser_model.pyx:398\u001b[0m, in \u001b[0;36mspacy.ml.parser_model.precompute_hiddens.__init__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/NLP_project/lib/python3.12/site-packages/thinc/model.py:310\u001b[0m, in \u001b[0;36mModel.__call__\u001b[0;34m(self, X, is_train)\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[1;32m    308\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_func(\u001b[38;5;28mself\u001b[39m, X, is_train\u001b[38;5;241m=\u001b[39mis_train)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/NLP_project/lib/python3.12/site-packages/spacy/ml/_precomputable_affine.py:27\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(model, X, is_train)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Preallocate array for layer output, including padding.\u001b[39;00m\n\u001b[1;32m     26\u001b[0m Yf \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mops\u001b[38;5;241m.\u001b[39malloc2f(X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, nF \u001b[38;5;241m*\u001b[39m nO \u001b[38;5;241m*\u001b[39m nP, zeros\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m---> 27\u001b[0m model\u001b[38;5;241m.\u001b[39mops\u001b[38;5;241m.\u001b[39mgemm(X, W\u001b[38;5;241m.\u001b[39mreshape((nF \u001b[38;5;241m*\u001b[39m nO \u001b[38;5;241m*\u001b[39m nP, nI)), trans2\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, out\u001b[38;5;241m=\u001b[39mYf[\u001b[38;5;241m1\u001b[39m:])\n\u001b[1;32m     28\u001b[0m Yf \u001b[38;5;241m=\u001b[39m Yf\u001b[38;5;241m.\u001b[39mreshape((Yf\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], nF, nO, nP))\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# Set padding. Padding has shape (1, nF, nO, nP). Unfortunately, we cannot\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# change its shape to (nF, nO, nP) without breaking existing models. So\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# we'll squeeze the first dimension here.\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "import scispacy\n",
    "import os\n",
    "from tqdm import tqdm  # Added for progress tracking\n",
    "\n",
    "def extract_diseases_from_note(note, nlp0, nlp1):\n",
    "    \"\"\"\n",
    "    Extract diseases from a medical note using NER\n",
    "    \n",
    "    Args:\n",
    "        note (str): Medical note text\n",
    "        nlp0 (spacy.language.Language): Lemmatization model\n",
    "        nlp1 (spacy.language.Language): NER model\n",
    "    \n",
    "    Returns:\n",
    "        list: List of unique disease entities\n",
    "    \"\"\"\n",
    "    # Lemmatize the text\n",
    "    lemmatized_text = lemmatize(note, nlp0)\n",
    "    \n",
    "    # Process the note with NER\n",
    "    doc = nlp1(lemmatized_text)\n",
    "    \n",
    "    # Extract unique diseases\n",
    "    diseases = set(ent.text for ent in doc.ents if ent.label_ == 'DISEASE')\n",
    "    \n",
    "    return list(diseases)\n",
    "\n",
    "def lemmatize(note, nlp):\n",
    "    \"\"\"Lemmatize the input text\"\"\"\n",
    "    doc = nlp(note)\n",
    "    lemNote = [wd.lemma_ for wd in doc]\n",
    "    return \" \".join(lemNote)\n",
    "\n",
    "def process_csv_with_ner(input_file, output_file):\n",
    "    \"\"\"\n",
    "    Process entire CSV file and extract diseases for each row\n",
    "    \n",
    "    Args:\n",
    "        input_file (str): Path to input CSV\n",
    "        output_file (str): Path to output CSV\n",
    "    \"\"\"\n",
    "    # Load scispaCy models\n",
    "    try:\n",
    "        nlp0 = spacy.load(\"en_core_sci_sm\")\n",
    "        nlp1 = spacy.load(\"en_ner_bc5cdr_md\")\n",
    "    except OSError as e:\n",
    "        print(f\"Error loading spaCy models: {e}\")\n",
    "        print(\"Make sure you have installed the models using:\")\n",
    "        print(\"python -m spacy download en_core_sci_sm\")\n",
    "        print(\"python -m spacy download en_ner_bc5cdr_md\")\n",
    "        raise\n",
    "\n",
    "    # Load the CSV file\n",
    "    df = pd.read_csv(input_file)\n",
    "    \n",
    "    # Create a new column for diseases\n",
    "    df['extracted_diseases'] = None\n",
    "\n",
    "    # Prepare some logging and tracking\n",
    "    total_rows = len(df)\n",
    "    disease_extraction_stats = {\n",
    "        'total_rows': total_rows,\n",
    "        'rows_processed': 0,\n",
    "        'total_diseases_extracted': 0,\n",
    "        'rows_with_diseases': 0\n",
    "    }\n",
    "\n",
    "    # Process each row with a progress bar\n",
    "    print(f\"Processing {total_rows} rows...\")\n",
    "    for index, row in tqdm(df.iterrows(), total=total_rows):\n",
    "        try:\n",
    "            # Combine columns of interest\n",
    "            combined_text = (\n",
    "                str(row.get('History of Present Illness', '')) + ' ' +\n",
    "                str(row.get('Past Medical History', '')) + ' ' +\n",
    "                str(row.get('Physical Exam', ''))\n",
    "            )\n",
    "            \n",
    "            # Extract diseases\n",
    "            diseases = extract_diseases_from_note(combined_text, nlp0, nlp1)\n",
    "            \n",
    "            # Update tracking stats\n",
    "            disease_extraction_stats['rows_processed'] += 1\n",
    "            if diseases:\n",
    "                disease_extraction_stats['rows_with_diseases'] += 1\n",
    "                disease_extraction_stats['total_diseases_extracted'] += len(diseases)\n",
    "            \n",
    "            # Save diseases to the new column\n",
    "            df.at[index, 'extracted_diseases'] = '; '.join(diseases) if diseases else None\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing row {index}: {e}\")\n",
    "    \n",
    "    # Save the updated DataFrame\n",
    "    df.to_csv(output_file, index=False)\n",
    "    \n",
    "    # Print detailed stats\n",
    "    print(\"\\nDisease Extraction Statistics:\")\n",
    "    print(f\"Total Rows: {disease_extraction_stats['total_rows']}\")\n",
    "    print(f\"Rows Processed: {disease_extraction_stats['rows_processed']}\")\n",
    "    print(f\"Rows with Diseases: {disease_extraction_stats['rows_with_diseases']}\")\n",
    "    print(f\"Total Diseases Extracted: {disease_extraction_stats['total_diseases_extracted']}\")\n",
    "    print(f\"Percentage of Rows with Diseases: {disease_extraction_stats['rows_with_diseases'] / disease_extraction_stats['total_rows'] * 100:.2f}%\")\n",
    "    \n",
    "    print(f\"\\nProcessed CSV saved to: {output_file}\")\n",
    "    \n",
    "    return disease_extraction_stats\n",
    "\n",
    "def main():\n",
    "    try:\n",
    "        input_file = 'extracted_sections_drop_empty.csv'\n",
    "        output_file = 'extracted_sections_drop_empty_with_diseases.csv'\n",
    "        \n",
    "        process_csv_with_ner(input_file, output_file)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-12-08T09:03:56.834851Z",
     "iopub.status.idle": "2024-12-08T09:03:56.834983Z",
     "shell.execute_reply": "2024-12-08T09:03:56.834917Z",
     "shell.execute_reply.started": "2024-12-08T09:03:56.834911Z"
    },
    "id": "9dnTi4Y-aaCZ",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import medspacy\n",
    "import spacy\n",
    "from medspacy.ner import TargetMatcher, TargetRule\n",
    "import pandas as pd\n",
    "\n",
    "# Load the MedSpaCy NLP pipeline\n",
    "nlp = medspacy.load()\n",
    "\n",
    "# Get the existing TargetMatcher from the pipeline\n",
    "target_matcher = nlp.get_pipe(\"medspacy_target_matcher\")\n",
    "\n",
    "# Load the list of symptoms from the text file\n",
    "symptoms_file_path = \"symptoms.txt\"  \n",
    "with open(symptoms_file_path, 'r') as file:\n",
    "    symptoms = file.readlines()\n",
    "\n",
    "# Create TargetRule objects from the symptoms list\n",
    "target_patterns = [TargetRule(symptom.strip(), \"SYMPTOM\") for symptom in symptoms]\n",
    "\n",
    "# Add the rules to the TargetMatcher\n",
    "target_matcher.add(target_patterns)\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = 'extracted_sections_sampled.csv'  # Replace with your CSV file path\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Preprocess: Combine columns of interest into a single text field\n",
    "df['combined_text'] = (\n",
    "    df['History of Present Illness'].fillna('') + ' ' +\n",
    "    df['Past Medical History'].fillna('') + ' ' +\n",
    "    df['Physical Exam'].fillna('')\n",
    ")\n",
    "\n",
    "# Function to extract symptoms from text\n",
    "def extract_symptoms(text):\n",
    "    doc = nlp(text)\n",
    "    symptoms_list = [ent.text for ent in doc.ents if ent.label_ == \"SYMPTOM\"]\n",
    "    return symptoms_list\n",
    "\n",
    "# Apply the function to the combined_text column and save the extracted symptoms\n",
    "df['extracted_symptoms'] = df['combined_text'].apply(extract_symptoms)\n",
    "\n",
    "# Save the updated DataFrame to a new CSV file\n",
    "output_file_path = 'extracted_sections_with_symptoms.csv'\n",
    "df.to_csv(output_file_path, index=False)\n",
    "\n",
    "print(f\"Symptoms extracted and saved to {output_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ynagd-rkaaCZ",
    "outputId": "f2eeb72e-43d9-4bb8-c367-49e26aefb165",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     \\nName:  ___             Unit No:   ___\\n \\nAdmission Date:  ___              Discharge Date:   ___\\n \\nDate of Birth:  ___             Sex:   F\\n \\nService: MEDICINE\\n \\nAllergies: \\nNo Known Allergies / Adverse Drug Reactions\\n \\nAttending: ___.\\n \\nChief Complaint:\\nfever, nausea/vomiting, flank pain\\n \\nMajor Surgical or Invasive Procedure:\\nnone \\n\\n \\nHistory of Present Illness:\\nHISTORY OF PRESENT ILLNESS:  \\nMs. ___ is a ___ year old ___ speaking lady with DM2 and \\nHTN who was evaluated in the ED ___, diagnosed with UTI and \\ntreated with macrobid, who returned with bilateral flank pain \\nL>R, fevers, chills, sweats, nausea, vomiting, headache, \\ndysuria. Denied neck stiffness. She was evaluated in ED \\ninitially with dizziness, headache, fever, found ot have a UTI \\nand discharged home w macrobid, which she took, but felt worse \\ntoday. She endorses minimal urine output that is dark.  \\nIn the ED, initial vs were: ___ pain 99.3 97 151/53 16 96% \\nyest. Today initial vitals were ___ pain 101.2 94 123/46 18 96% \\nRA. Today ED physical exam significant for bilateral \\ncostovertebral angle tenderness as well as mild suprapubic \\ntenderness, no meningismus clear lungs, normal heart exam. Labs \\nin ED sig for leukocytosis to 19.0 and a lactate of 3.0 ___s a bump in her creatinine from 1.2-1.3. Given the patient's \\nongoing symptoms rising leukocytosis as well as elevated lactate \\nand bilateral flank pain, she was given 1500 cc NS, 1 gram \\nceftriaxone, 1g acetaminophen for pyelonpehritis/fever, \\nunderwent renal u/s to evaluate for renal abscesses or \\nhydronephrosis (negative).  \\nVitals on Transfer: ___ pain 98.0 65 106/50 16 100%  \\n \\nOn the floor, vs were as below. She endorsed feeling somewhat \\nbetter but continued suprapubic discomfort and flank pain L>R. \\n\\n \\nPast Medical History:\\nType 2 diabetes  \\nAsthma  \\nHyperlipidemia  \\nHypertension  \\n\\n \\nSocial History:\\n___\\nFamily History:\\nShe has a sister deceased with endometrial cancer. No history of \\novarian, breast or colon cancer. No history of hypertension or \\ndiabetes in the family.  \\n\\n \\nPhysical Exam:\\nADMISSION EXAM: \\nVitals: tmax 101.2, tc 98.___ fs 207  \\nGeneral: Alert, oriented, no acute distress, lying in bed with \\nfamily at bedside  \\nHEENT: Sclera anicteric, MM dry  \\nNeck: supple, no meningismus, JVP not elevated  \\nLungs: Clear to auscultation bilaterally, no wheezes, rales, \\nronchi  \\nCV: Regular rate and rhythm, normal S1 + S2, no murmurs, rubs, \\ngallops  \\nAbdomen: soft, mild tenderness to deep palp @ suprapubic area, \\nnon-distended, bowel sounds present, no rebound tenderness, no \\norganomegaly  \\nBack: + CVA tenderness, L > R (mild on R)  \\nExt: Warm, well perfused, no edema  \\nSkin: moist, no rashes, no petechiae  \\nNeuro: speech fluent, linear, appropriate, no meningismus, \\noriented x3, moving all 4 extremities, did not assess gait.  \\n.\\nDISCHARGE EXAM: \\nPHYSICAL EXAM:  \\nGeneral: Alert, oriented, no acute distress, lying on bed \\nAbdomen: soft, non-tender, obese, bowel sounds present, no \\nrebound tenderness, no organomegaly  \\nBack: CVA tenderness resolved  \\nExt: Warm, well perfused, no edema  \\n\\n \\nPertinent Results:\\nADMISSION LABS: \\n___ 10:39PM   LACTATE-1.6\\n___ 09:00PM URINE  BLOOD-SM  NITRITE-NEG PROTEIN-TR \\nGLUCOSE-NEG KETONE-NEG BILIRUBIN-NEG UROBILNGN-NEG PH-5.0 \\nLEUK-LG\\n___ 09:00PM URINE  RBC-21* WBC-34* BACTERIA-FEW YEAST-NONE \\nEPI-2 TRANS EPI-<1\\n___ 07:27PM   LACTATE-3.0*\\n___ 07:17PM   GLUCOSE-210* UREA N-21* CREAT-1.3* \\nSODIUM-130* POTASSIUM-4.0 CHLORIDE-94* TOTAL CO2-22 ANION GAP-18\\n___ 07:17PM   WBC-19.2* RBC-3.65* HGB-11.0* HCT-31.1* \\nMCV-85 MCH-30.1 MCHC-35.4* RDW-12.6\\n___ 07:17PM   NEUTS-84.8* LYMPHS-10.1* MONOS-4.4 EOS-0.4 \\nBASOS-0.3\\n___ 07:17PM   PLT COUNT-204\\n.\\nRELEVANT LABS: \\n.\\n___ blood cultures: ___ bottles: \\n___ 7:17 pm BLOOD CULTURE\\n\\n                            **FINAL REPORT ___\\n\\n   Blood Culture, Routine (Final ___: \\n      ESCHERICHIA COLI.    FINAL SENSITIVITIES. \\n         Cefazolin interpretative criteria are based on a dosage \\nregimen of\\n         2g every 8h. \\n\\n                              SENSITIVITIES: MIC expressed in \\nMCG/ML\\n                      \\n_________________________________________________________\\n                             ESCHERICHIA COLI\\n                             |   \\nAMPICILLIN------------     4 S\\nAMPICILLIN/SULBACTAM--     4 S\\nCEFAZOLIN-------------   <=4 S\\nCEFEPIME--------------   <=1 S\\nCEFTAZIDIME-----------   <=1 S\\nCEFTRIAXONE-----------   <=1 S\\nCIPROFLOXACIN---------<=0.25 S\\nGENTAMICIN------------   <=1 S\\nMEROPENEM-------------<=0.25 S\\nPIPERACILLIN/TAZO-----   <=4 S\\nTOBRAMYCIN------------   <=1 S\\nTRIMETHOPRIM/SULFA----   <=1 S\\n\\n   Anaerobic Bottle Gram Stain (Final ___: \\n      GRAM NEGATIVE ROD(S). \\n      Reported to and read back by ___. ___ ___ 08:13AM. \\n\\n   Aerobic Bottle Gram Stain (Final ___:    GRAM NEGATIVE \\nROD(S). \\n\\n.\\n.\\nsubsequent blood cultures negative.\\n.\\n.\\n\\n                        \\n   URINE CULTURE (Final ___: \\n      MIXED BACTERIAL FLORA ( >= 3 COLONY TYPES), CONSISTENT \\nWITH SKIN\\n      AND/OR GENITAL CONTAMINATION. \\n.\\nDISCHARGE LABS: \\n.\\n___ 10:50AM BLOOD WBC-6.1 RBC-2.82* Hgb-8.3* Hct-24.4* \\nMCV-87 MCH-29.5 MCHC-34.1 RDW-12.3 Plt ___\\n___ 10:50AM BLOOD Plt ___\\n___ 07:15AM BLOOD Glucose-177* UreaN-14 Creat-0.9 Na-138 \\nK-3.9 Cl-102 HCO3-26 AnGap-14\\n___ 10:50AM BLOOD LD(LDH)-125 TotBili-0.4\\n___ 10:50AM BLOOD Iron-21*\\n___ 07:15AM BLOOD Calcium-8.9 Phos-2.7 Mg-1.7\\n___ 10:50AM BLOOD calTIBC-215* Hapto-224* Ferritn-333* \\nTRF-165*\\n \\nBrief Hospital Course:\\n___ was admitted on ___ for fevers, flank pain, \\nnausea/vomiting and headache. She had been admitted ___ for \\nurinary tract infection and discharged on nitrofurantoin. She \\nrepresented on ___, found to be febrile, with urinalysis \\nconsistent with infection, and was started on IV ceftriaxone. \\nRenal ultrasound was preformed, showing only a 8mm simple cyst. \\nSubsequent blood cultures showed GNR. \\n.\\nACUTE ISSUES: \\n.\\n# Pyelonephritis and Sepsis: Fever, dysuria, flank pain. \\ntreating initially w/ iv ceftriaxone. Renal u/s w/o e/o abscess \\nor stone as nidus. Patient was started on IV ceftriaxone, and \\ntransitioned to PO cipro\\nplan ___: Likely in setting of volume depletion given insensible \\nlosses (fever), vomiting, poor PO intake, as evidence by \\nelevated lactate and creatinine.  \\n- Cr 1.3 on admission --> .9 on discharged, resolved with IV \\nfluids\\n.\\nAnemia: requires outpatient evaluation.  Iron studies and lysis \\nlabs above. \\n.\\nCHRONIC ISSUES:\\n.\\n# Type 2 DM: Given acute infection, held glipizide and \\nmetformin.  \\n- insulin humalgos sliding scale  \\n- qid fingersticks  \\n- restarted on metformin, glipizide on discharge. \\n. \\n# Hyponatremia: Improved with hydration.\\n.\\n# Asthma: asymptomatic, not wheezing, monitor.  \\n.\\n# Hyperlipidemia: Continue statin, aspirin  \\n.\\n# Hypertension: held indapamide during stay for low-normal BPs, \\ndid not restart indapamide, to be restarted at discretion of PCP\\n.\\nFollow-up: \\n.\\nTo follow up with PCP to ensure resolution of symptoms as well \\nas to follow up anemia. \\n.\\nTo follow up with renal as scheduled prior to this inpatient \\nstay.\\n\\n \\nMedications on Admission:\\nThe Preadmission Medication list is accurate and complete.\\n1. Nitrofurantoin Monohyd (MacroBID) 100 mg PO Q12H \\n2. Aspirin 81 mg PO DAILY \\n3. Simvastatin 40 mg PO HS \\n4. Lisinopril 20 mg PO DAILY \\nplease hold for SBP<100, HR<60 \\n5. GlipiZIDE 5 mg PO DAILY \\n6. MetFORMIN (Glucophage) 1000 mg PO BID \\n7. Indapamide 1.25 mg PO DAILY \\nplease hold for SBP<100 \\n\\n \\nDischarge Medications:\\n1. Aspirin 81 mg PO DAILY \\n2. Simvastatin 40 mg PO HS \\n3. Ciprofloxacin HCl 500 mg PO Q12H \\nRX *ciprofloxacin 500 mg 1 tablet(s) by mouth twice a day Disp \\n#*23 Tablet Refills:*0\\n4. Acetaminophen ___ mg PO Q6H:PRN pain,fever, headache \\nRX *acetaminophen 500 mg 1 tablet(s) by mouth q6hrs Disp #*60 \\nTablet Refills:*0\\n5. GlipiZIDE 5 mg PO DAILY \\n6. Lisinopril 20 mg PO DAILY \\n7. MetFORMIN (Glucophage) 1000 mg PO BID \\n\\n \\nDischarge Disposition:\\nHome\\n \\nDischarge Diagnosis:\\nPrimary Diagnosis:\\n# Sepsis, secondary to pyelonephritis\\n\\nSecondary Diagnosis: \\n# Diabetes Type II\\n# Hypertension\\n# Hyperlipidemia\\n# Asthma\\n\\n \\nDischarge Condition:\\nMental Status: Clear and coherent.\\nLevel of Consciousness: Alert and interactive.\\nActivity Status: Ambulatory - Independent.\\n\\n \\nDischarge Instructions:\\nIt was a pleasure taking part in your care at ___ \\n___.\\n\\n___ were admitted for an infection in your blood and in your \\nkidneys, after recently being diagnosed and treated for a \\nurinary tract infection. Your kidney and blood infection were \\ntreated with IV antibiotics. ___ also had temporary kidney \\ninjury resulting from dehydration, which improved with \\nintravenous fluids. An ultrasound was preformed to look at your \\nkidneys, and everything looked normal. \\n\\n___ did not have a fever on the day of discharge. PLease buy a \\nthermometer for home. ___ should take your temperature several \\ntimes a day for the next few days. If your temperature is \\ngreater than 102 degrees, ___ should return to the ED.\\n\\n___ are discharged on ciprofloxacin 500mg twice a day for 14 \\ndays, to be completed on ___.\\n\\n___ should follow up with your PCP, ___ week\\n\\n___ should follow up your kidney doctor on ___ as planned. \\n \\n \\nFollowup Instructions:\\n___\\n\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "df['text'].head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6sAZkXsUaaCZ",
    "outputId": "dca941e4-82b4-4d0a-9d1c-47c13ecfefd1",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   subject_id   hadm_id  pharmacy_id       poe_id            starttime  \\\n",
      "0    10000032  22595853     12775705  10000032-55  2180-05-08 08:00:00   \n",
      "1    10000032  22595853     18415984  10000032-42  2180-05-07 02:00:00   \n",
      "2    10000032  22595853     23637373  10000032-35  2180-05-07 01:00:00   \n",
      "3    10000032  22595853     26862314  10000032-41  2180-05-07 01:00:00   \n",
      "4    10000032  22595853     30740602  10000032-27  2180-05-07 00:00:00   \n",
      "\n",
      "              stoptime                   medication  proc_type  \\\n",
      "0  2180-05-07 22:00:00                   Furosemide  Unit Dose   \n",
      "1  2180-05-07 22:00:00      Ipratropium Bromide Neb  Unit Dose   \n",
      "2  2180-05-07 09:00:00                   Furosemide  Unit Dose   \n",
      "3  2180-05-07 01:00:00           Potassium Chloride  Unit Dose   \n",
      "4  2180-05-07 22:00:00  Sodium Chloride 0.9%  Flush  Unit Dose   \n",
      "\n",
      "                               status            entertime  ... basal_rate  \\\n",
      "0  Discontinued via patient discharge  2180-05-07 09:32:35  ...        NaN   \n",
      "1  Discontinued via patient discharge  2180-05-07 01:49:23  ...        NaN   \n",
      "2    Inactive (Due to a change order)  2180-05-07 00:09:24  ...        NaN   \n",
      "3                        Discontinued  2180-05-07 00:09:24  ...        NaN   \n",
      "4  Discontinued via patient discharge  2180-05-07 00:00:54  ...        NaN   \n",
      "\n",
      "  one_hr_max doses_per_24_hrs duration duration_interval expiration_value  \\\n",
      "0        NaN              1.0      NaN           Ongoing             36.0   \n",
      "1        NaN              4.0      NaN           Ongoing             36.0   \n",
      "2        NaN              1.0      NaN           Ongoing             36.0   \n",
      "3        NaN              1.0      1.0             Doses             36.0   \n",
      "4        NaN              3.0      NaN           Ongoing             36.0   \n",
      "\n",
      "  expiration_unit  expirationdate      dispensation  fill_quantity  \n",
      "0           Hours             NaN          Omnicell            NaN  \n",
      "1           Hours             NaN          Omnicell            NaN  \n",
      "2           Hours             NaN          Omnicell            NaN  \n",
      "3           Hours             NaN          Omnicell            NaN  \n",
      "4           Hours             NaN  Floor Stock Item            NaN  \n",
      "\n",
      "[5 rows x 27 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "# Specify the folder path\n",
    "df = pd.read_csv('/Users/benjamintan/Downloads/mimic-iv-3.1/hosp/pharmacy.csv', low_memory=False)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w7NWaSIAaaCZ",
    "outputId": "ba9f1499-0785-472d-d34c-904065cb7a25",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.46.3-py3-none-any.whl.metadata (44 kB)\n",
      "Requirement already satisfied: datasets in /opt/anaconda3/envs/NLP_project/lib/python3.12/site-packages (3.1.0)\n",
      "Collecting torch\n",
      "  Downloading torch-2.5.1-cp312-none-macosx_11_0_arm64.whl.metadata (28 kB)\n",
      "Requirement already satisfied: scikit-learn in /opt/anaconda3/envs/NLP_project/lib/python3.12/site-packages (1.5.2)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/envs/NLP_project/lib/python3.12/site-packages (from transformers) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/anaconda3/envs/NLP_project/lib/python3.12/site-packages (from transformers) (0.26.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/anaconda3/envs/NLP_project/lib/python3.12/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/envs/NLP_project/lib/python3.12/site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/envs/NLP_project/lib/python3.12/site-packages (from transformers) (6.0.2)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Downloading regex-2024.11.6-cp312-cp312-macosx_11_0_arm64.whl.metadata (40 kB)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/envs/NLP_project/lib/python3.12/site-packages (from transformers) (2.32.3)\n",
      "Collecting tokenizers<0.21,>=0.20 (from transformers)\n",
      "  Downloading tokenizers-0.20.3-cp312-cp312-macosx_11_0_arm64.whl.metadata (6.7 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers)\n",
      "  Downloading safetensors-0.4.5-cp312-cp312-macosx_11_0_arm64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/anaconda3/envs/NLP_project/lib/python3.12/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/anaconda3/envs/NLP_project/lib/python3.12/site-packages (from datasets) (18.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/anaconda3/envs/NLP_project/lib/python3.12/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/anaconda3/envs/NLP_project/lib/python3.12/site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: xxhash in /opt/anaconda3/envs/NLP_project/lib/python3.12/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /opt/anaconda3/envs/NLP_project/lib/python3.12/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /opt/anaconda3/envs/NLP_project/lib/python3.12/site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
      "Requirement already satisfied: aiohttp in /opt/anaconda3/envs/NLP_project/lib/python3.12/site-packages (from datasets) (3.11.7)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/anaconda3/envs/NLP_project/lib/python3.12/site-packages (from torch) (4.11.0)\n",
      "Collecting networkx (from torch)\n",
      "  Downloading networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/envs/NLP_project/lib/python3.12/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/envs/NLP_project/lib/python3.12/site-packages (from torch) (75.1.0)\n",
      "Collecting sympy==1.13.1 (from torch)\n",
      "  Downloading sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy==1.13.1->torch)\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /opt/anaconda3/envs/NLP_project/lib/python3.12/site-packages (from scikit-learn) (1.14.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/anaconda3/envs/NLP_project/lib/python3.12/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/anaconda3/envs/NLP_project/lib/python3.12/site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/anaconda3/envs/NLP_project/lib/python3.12/site-packages (from aiohttp->datasets) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/anaconda3/envs/NLP_project/lib/python3.12/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/anaconda3/envs/NLP_project/lib/python3.12/site-packages (from aiohttp->datasets) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/anaconda3/envs/NLP_project/lib/python3.12/site-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/anaconda3/envs/NLP_project/lib/python3.12/site-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/anaconda3/envs/NLP_project/lib/python3.12/site-packages (from aiohttp->datasets) (0.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/anaconda3/envs/NLP_project/lib/python3.12/site-packages (from aiohttp->datasets) (1.18.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/envs/NLP_project/lib/python3.12/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/envs/NLP_project/lib/python3.12/site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/envs/NLP_project/lib/python3.12/site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/envs/NLP_project/lib/python3.12/site-packages (from requests->transformers) (2024.8.30)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/envs/NLP_project/lib/python3.12/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/envs/NLP_project/lib/python3.12/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/envs/NLP_project/lib/python3.12/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/envs/NLP_project/lib/python3.12/site-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/envs/NLP_project/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Downloading transformers-4.46.3-py3-none-any.whl (10.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading torch-2.5.1-cp312-none-macosx_11_0_arm64.whl (63.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.9/63.9 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hDownloading sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading regex-2024.11.6-cp312-cp312-macosx_11_0_arm64.whl (284 kB)\n",
      "Downloading safetensors-0.4.5-cp312-cp312-macosx_11_0_arm64.whl (381 kB)\n",
      "Downloading tokenizers-0.20.3-cp312-cp312-macosx_11_0_arm64.whl (2.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0meta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m-:--:--\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: mpmath, sympy, safetensors, regex, networkx, torch, tokenizers, transformers\n",
      "Successfully installed mpmath-1.3.0 networkx-3.4.2 regex-2024.11.6 safetensors-0.4.5 sympy-1.13.1 tokenizers-0.20.3 torch-2.5.1 transformers-4.46.3\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers datasets torch scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "riFyKOP3aaCZ",
    "outputId": "f4c16015-de81-49bd-98bd-a0165cea066c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n",
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ClinicalBERTClassifier(\n",
       "  (base_model): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (classifier): Linear(in_features=768, out_features=50, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import AutoTokenizer, AutoModel, AdamW\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Load tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\")\n",
    "base_model = AutoModel.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\")\n",
    "\n",
    "# Define a custom model\n",
    "class ClinicalBERTClassifier(nn.Module):\n",
    "    def __init__(self, base_model, num_labels):\n",
    "        super(ClinicalBERTClassifier, self).__init__()\n",
    "        self.base_model = base_model\n",
    "        self.classifier = nn.Linear(base_model.config.hidden_size, num_labels)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.base_model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        cls_output = outputs.last_hidden_state[:, 0, :]  # Use [CLS] token representation\n",
    "        logits = self.classifier(cls_output)\n",
    "        return logits\n",
    "\n",
    "# Initialize the model\n",
    "num_labels = 50  # Adjust based on the number of ICD codes\n",
    "model = ClinicalBERTClassifier(base_model, num_labels)\n",
    "model.to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o9jOjW7maaCZ"
   },
   "outputs": [],
   "source": [
    "# Dataset preparation\n",
    "class ClinicalNotesDataset(Dataset):\n",
    "    def __init__(self, notes, labels, tokenizer, max_len):\n",
    "        self.notes = notes\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.notes)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        note = str(self.notes[index])\n",
    "        labels = torch.tensor(self.labels[index], dtype=torch.float32)\n",
    "        encoding = self.tokenizer(note, max_length=self.max_len, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n",
    "        return {\n",
    "            \"input_ids\": encoding[\"input_ids\"].squeeze(0),\n",
    "            \"attention_mask\": encoding[\"attention_mask\"].squeeze(0),\n",
    "            \"labels\": labels\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oOuUPOh3aaCZ"
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = pd.read_csv(\"mimic_data.csv\")  # Placeholder file path\n",
    "notes = df[\"notes\"]\n",
    "labels = df[\"icd_codes\"].apply(lambda x: list(map(int, x.split(\",\"))))  # Convert ICD codes to binary vectors\n",
    "\n",
    "# Split data\n",
    "train_size = 0.8\n",
    "train_len = int(train_size * len(notes))\n",
    "train_notes, val_notes = notes[:train_len], notes[train_len:]\n",
    "train_labels, val_labels = labels[:train_len], labels[train_len:]\n",
    "\n",
    "# Create datasets and dataloaders\n",
    "max_len = 128\n",
    "batch_size = 16\n",
    "train_dataset = ClinicalNotesDataset(train_notes, train_labels, tokenizer, max_len)\n",
    "val_dataset = ClinicalNotesDataset(val_notes, val_labels, tokenizer, max_len)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "# Training loop\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, epochs=5):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for batch in train_loader:\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(input_ids, attention_mask)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch {epoch+1}, Loss: {total_loss / len(train_loader)}\")\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                input_ids = batch[\"input_ids\"].to(device)\n",
    "                attention_mask = batch[\"attention_mask\"].to(device)\n",
    "                labels = batch[\"labels\"].to(device)\n",
    "                outputs = model(input_ids, attention_mask)\n",
    "                preds = torch.sigmoid(outputs).cpu().numpy() > 0.5\n",
    "                all_preds.extend(preds)\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "        f1 = f1_score(np.array(all_labels), np.array(all_preds), average=\"weighted\")\n",
    "        print(f\"Validation F1 Score: {f1}\")\n",
    "\n",
    "# Train the model\n",
    "train_model(model, train_loader, val_loader, criterion, optimizer)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
